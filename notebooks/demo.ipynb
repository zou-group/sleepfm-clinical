{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Details\n",
    "\n",
    "\n",
    "Before running this notebook, please preprocess your PSG files using the scripts provided in `sleepfm/preprocessing`. Note that PSG recordings may contain different sets of channels across datasets. The predefined channel–modality mappings used in this project are specified in `sleepfm/configs/channel_groups.json`.\n",
    "\n",
    "Although we have attempted to make this mapping as comprehensive as possible, we strongly recommend reviewing the channels present in your specific PSG data. In consultation with domain experts, you should group any additional or dataset-specific channels into the appropriate modality categories and update `channel_groups.json` accordingly. This step is critical to ensure that all channels are correctly aligned with their intended modalities during preprocessing and downstream modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../sleepfm\")\n",
    "from preprocessing.preprocessing import EDFToHDF5Converter\n",
    "from models.dataset import SetTransformerDataset, collate_fn\n",
    "from models.models import SetTransformer, SleepEventLSTMClassifier, DiagnosisFinetuneFullLSTMCOXPHWithDemo\n",
    "import h5py\n",
    "from utils import load_config, load_data, save_data, count_parameters\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 0: Preprocessing EDF files\n",
    "\n",
    "Note: This is just a demo notebook that preprocesses a single, specific file. run `sleepfm/preprocessing/preprocessing.sh` with appropriate folders to generate multiple preprocessed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_save_path = \"demo_data\"\n",
    "os.makedirs(base_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 15:58:54.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.preprocessing\u001b[0m:\u001b[36mread_edf\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mreading edf\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /oak/stanford/groups/mignot/psg/SSC_Stanford/all/SSC_2004_1006994706.EDF...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8937983  =      0.000 ... 34913.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 15:59:23.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.preprocessing\u001b[0m:\u001b[36mresample_signals\u001b[0m:\u001b[36m184\u001b[0m - \u001b[1mresampling signals\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 15:59:37.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.preprocessing\u001b[0m:\u001b[36msave_to_hdf5\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1msaving hdf5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/edf_root\"      # dummy root not used for a single file conversion\n",
    "target_dir = \"/note\"    # dummy target not used for a single file conversion\n",
    "\n",
    "#edf_path = \"/path/to/demo_psg.edf\"\n",
    "# edf_path = \"/oak/stanford/groups/mignot/psg/SSC_Stanford/ssc/2015/SSC_2015_0002.edf\"\n",
    "edf_path = \"/oak/stanford/groups/mignot/psg/SSC_Stanford/all/SSC_2004_1006994706.EDF\"\n",
    "hdf5_path = os.path.join(base_save_path, \"demo_psg.hdf5\")\n",
    "\n",
    "converter = EDFToHDF5Converter(\n",
    "    root_dir=root_dir,\n",
    "    target_dir=target_dir,\n",
    "    resample_rate=128\n",
    ")\n",
    "\n",
    "# run for single file conversion\n",
    "converter.convert(edf_path, hdf5_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Generating embeddings from SleepFM pretrained model\n",
    "\n",
    "Here we show generating embedding for 1 demno PSG. To see full script, please check `sleepfm/pipeline/generate_embeddings.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../sleepfm/checkpoints/model_base\"\n",
    "channel_groups_path = \"../sleepfm/configs/channel_groups.json\"\n",
    "config_path = os.path.join(model_path, \"config.json\")\n",
    "\n",
    "config = load_config(config_path)\n",
    "channel_groups = load_data(channel_groups_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_types = config[\"modality_types\"]\n",
    "in_channels = config[\"in_channels\"]\n",
    "patch_size = config[\"patch_size\"]\n",
    "embed_dim = config[\"embed_dim\"]\n",
    "num_heads = config[\"num_heads\"]\n",
    "num_layers = config[\"num_layers\"]\n",
    "pooling_head = config[\"pooling_head\"]\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 4.44 million\n",
      "Number of layers: 93\n"
     ]
    }
   ],
   "source": [
    "model_class = getattr(sys.modules[__name__], config['model'])\n",
    "model = model_class(in_channels, patch_size, embed_dim, num_heads, num_layers, pooling_head=pooling_head, dropout=dropout)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "if device.type == \"cuda\":\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "total_layers, total_params = count_parameters(model)\n",
    "print(f'Trainable parameters: {total_params / 1e6:.2f} million')\n",
    "print(f'Number of layers: {total_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): SetTransformer(\n",
       "    (patch_embedding): Tokenizer(\n",
       "      (tokenizer): Sequential(\n",
       "        (0): Conv1d(1, 4, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "        (3): LayerNorm((4, 320), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Conv1d(4, 8, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (5): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ELU(alpha=1.0)\n",
       "        (7): LayerNorm((8, 160), eps=1e-05, elementwise_affine=True)\n",
       "        (8): Conv1d(8, 16, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (10): ELU(alpha=1.0)\n",
       "        (11): LayerNorm((16, 80), eps=1e-05, elementwise_affine=True)\n",
       "        (12): Conv1d(16, 32, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (13): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (14): ELU(alpha=1.0)\n",
       "        (15): LayerNorm((32, 40), eps=1e-05, elementwise_affine=True)\n",
       "        (16): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (17): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (18): ELU(alpha=1.0)\n",
       "        (19): LayerNorm((64, 20), eps=1e-05, elementwise_affine=True)\n",
       "        (20): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (21): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (22): ELU(alpha=1.0)\n",
       "        (23): LayerNorm((128, 10), eps=1e-05, elementwise_affine=True)\n",
       "        (24): AdaptiveAvgPool1d(output_size=1)\n",
       "        (25): Flatten(start_dim=1, end_dim=-1)\n",
       "        (26): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (spatial_pooling): AttentionPooling(\n",
       "      (transformer_layer): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (positional_encoding): PositionalEncoding()\n",
       "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (temporal_pooling): AttentionPooling(\n",
       "      (transformer_layer): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(os.path.join(model_path, \"best.pt\"))\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'model': 'SetTransformer',\n",
       " 'in_channels': 1,\n",
       " 'batch_size': 128,\n",
       " 'epochs': 1,\n",
       " 'lr': 0.001,\n",
       " 'lr_step_period': 2,\n",
       " 'gamma': 0.1,\n",
       " 'temperature': 0.0,\n",
       " 'momentum': 0.9,\n",
       " 'num_workers': 16,\n",
       " 'embed_dim': 128,\n",
       " 'num_heads': 8,\n",
       " 'num_layers': 6,\n",
       " 'pooling_head': 8,\n",
       " 'dropout': 0.3,\n",
       " 'split_path': 'path_to_/dataset_split.json',\n",
       " 'save_path': 'path_to_/models',\n",
       " 'weight_decay': 0.0,\n",
       " 'mode': 'leave_one_out',\n",
       " 'save_iter': 5000,\n",
       " 'eval_iter': 5000,\n",
       " 'log_interval': 100,\n",
       " 'use_wandb': True,\n",
       " 'BAS_CHANNELS': 10,\n",
       " 'RESP_CHANNELS': 7,\n",
       " 'EKG_CHANNELS': 2,\n",
       " 'EMG_CHANNELS': 4,\n",
       " 'max_files': None,\n",
       " 'val_size': 100,\n",
       " 'sampling_duration': 5,\n",
       " 'sampling_freq': 128,\n",
       " 'patch_size': 640,\n",
       " 'modality_types': ['BAS', 'RESP', 'EKG', 'EMG']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing files: 100%|██████████| 1/1 [00:00<00:00, 25.79it/s]\n"
     ]
    }
   ],
   "source": [
    "hdf5_paths = [os.path.join(base_save_path, \"demo_psg.hdf5\")]\n",
    "dataset = SetTransformerDataset(config, channel_groups, hdf5_paths=hdf5_paths, split=\"test\")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                                            batch_size=16, \n",
    "                                            num_workers=1, \n",
    "                                            shuffle=False, \n",
    "                                            collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = os.path.join(base_save_path, \"demo_emb\")\n",
    "output_5min_agg = os.path.join(base_save_path, \"demo_5min_agg_emb\")\n",
    "os.makedirs(output, exist_ok=True)\n",
    "os.makedirs(output_5min_agg, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/home/groups/jamesz/rthapa84/anaconda3/envs/sleepfm_clinical/lib/python3.10/site-packages/torch/nn/modules/transformer.py:562: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "  return torch._transformer_encoder_layer_fwd(\n",
      "100%|██████████| 8/8 [00:14<00:00,  1.77s/it]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    with tqdm.tqdm(total=len(dataloader)) as pbar:\n",
    "        for batch in dataloader:\n",
    "            batch_data, mask_list, file_paths, dset_names_list, chunk_starts = batch\n",
    "            (bas, resp, ekg, emg) = batch_data\n",
    "            (mask_bas, mask_resp, mask_ekg, mask_emg) = mask_list\n",
    "\n",
    "            bas = bas.to(device, dtype=torch.float)\n",
    "            resp = resp.to(device, dtype=torch.float)\n",
    "            ekg = ekg.to(device, dtype=torch.float)\n",
    "            emg = emg.to(device, dtype=torch.float)\n",
    "\n",
    "            mask_bas = mask_bas.to(device, dtype=torch.bool)\n",
    "            mask_resp = mask_resp.to(device, dtype=torch.bool)\n",
    "            mask_ekg = mask_ekg.to(device, dtype=torch.bool)\n",
    "            mask_emg = mask_emg.to(device, dtype=torch.bool)\n",
    "\n",
    "            embeddings = [\n",
    "                model(bas, mask_bas),\n",
    "                model(resp, mask_resp),\n",
    "                model(ekg, mask_ekg),\n",
    "                model(emg, mask_emg),\n",
    "            ]\n",
    "\n",
    "            # Model gives two kinds of embeddings. Granular 5 second-level embeddings and aggregated 5 minute-level embeddings. We save both of them below. \n",
    "\n",
    "            embeddings_new = [e[0].unsqueeze(1) for e in embeddings]\n",
    "\n",
    "            for i in range(len(file_paths)):\n",
    "                file_path = file_paths[i]\n",
    "                chunk_start = chunk_starts[i]\n",
    "                subject_id = os.path.basename(file_path).split('.')[0]\n",
    "                output_path = os.path.join(output_5min_agg, f\"{subject_id}.hdf5\")\n",
    "\n",
    "                with h5py.File(output_path, 'a') as hdf5_file:\n",
    "                    for modality_idx, modality_type in enumerate(config[\"modality_types\"]):\n",
    "                        if modality_type in hdf5_file:\n",
    "                            dset = hdf5_file[modality_type]\n",
    "                            chunk_start_correct = chunk_start // (embed_dim * 5 * 60)\n",
    "                            chunk_end = chunk_start_correct + embeddings_new[modality_idx][i].shape[0]\n",
    "                            if dset.shape[0] < chunk_end:\n",
    "                                dset.resize((chunk_end,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "                            dset[chunk_start_correct:chunk_end] = embeddings_new[modality_idx][i].cpu().numpy()\n",
    "                        else:\n",
    "                            hdf5_file.create_dataset(modality_type, data=embeddings_new[modality_idx][i].cpu().numpy(), chunks=(embed_dim,) + embeddings_new[modality_idx][i].shape[1:], maxshape=(None,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "\n",
    "            embeddings_new = [e[1] for e in embeddings]\n",
    "\n",
    "            for i in range(len(file_paths)):\n",
    "                file_path = file_paths[i]\n",
    "                chunk_start = chunk_starts[i]\n",
    "                subject_id = os.path.basename(file_path).split('.')[0]\n",
    "                output_path = os.path.join(output, f\"{subject_id}.hdf5\")\n",
    "\n",
    "                with h5py.File(output_path, 'a') as hdf5_file:\n",
    "                    for modality_idx, modality_type in enumerate(config[\"modality_types\"]):\n",
    "                        if modality_type in hdf5_file:\n",
    "                            dset = hdf5_file[modality_type]\n",
    "                            chunk_start_correct = chunk_start // (embed_dim * 5)\n",
    "                            chunk_end = chunk_start_correct + embeddings_new[modality_idx][i].shape[0]\n",
    "                            if dset.shape[0] < chunk_end:\n",
    "                                dset.resize((chunk_end,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "                            dset[chunk_start_correct:chunk_end] = embeddings_new[modality_idx][i].cpu().numpy()\n",
    "                        else:\n",
    "                            hdf5_file.create_dataset(modality_type, data=embeddings_new[modality_idx][i].cpu().numpy(), chunks=(embed_dim,) + embeddings_new[modality_idx][i].shape[1:], maxshape=(None,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Sleep Staging\n",
    "\n",
    "Note that below, we are using our finetuned sleep staging model. It is always a good idea to finetune our model on your specific data, even if you only have a handful of sample, so that the model can adapt to your specific data distribution. Script to finetune your sleep staging model head is given in `sleepfm/pipeline/finetune_sleep_staging.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_staging_model_path = \"../sleepfm/checkpoints/model_sleep_staging\"\n",
    "sleep_staging_config = load_data(os.path.join(sleep_staging_model_path, \"config.json\"))\n",
    "\n",
    "sleep_staging_model_params = sleep_staging_config['model_params']\n",
    "sleep_staging_model_class = getattr(sys.modules[__name__], sleep_staging_config['model'])\n",
    "\n",
    "sleep_staging_model = sleep_staging_model_class(**sleep_staging_model_params).to(device)\n",
    "sleep_staging_model_name = type(sleep_staging_model).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPUs\n"
     ]
    }
   ],
   "source": [
    "sleep_staging_model = nn.DataParallel(sleep_staging_model)\n",
    "print(f\"Using {torch.cuda.device_count()} GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: SleepEventLSTMClassifier\n",
      "Trainable parameters: 1.19 million\n",
      "Number of layers: 20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model initialized: {sleep_staging_model_name}\")\n",
    "total_layers, total_params = count_parameters(sleep_staging_model)\n",
    "print(f'Trainable parameters: {total_params / 1e6:.2f} million')\n",
    "print(f'Number of layers: {total_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_staging_checkpoint_path = os.path.join(sleep_staging_model_path, \"best.pth\")\n",
    "sleep_staging_checkpoint = torch.load(sleep_staging_checkpoint_path)\n",
    "sleep_staging_model.load_state_dict(sleep_staging_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helper functions for loading data for sleep staging. You can find similar functions within `sleepfm/models/dataset.py`. You may need to modify it slightly based on your usecase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepEventClassificationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        channel_groups,\n",
    "        hdf5_paths,\n",
    "        label_files,\n",
    "        split=\"train\",\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.max_channels = self.config[\"max_channels\"]\n",
    "        self.context = int(self.config[\"context\"])\n",
    "        self.channel_like = self.config[\"channel_like\"]\n",
    "\n",
    "        self.max_seq_len = config[\"model_params\"][\"max_seq_length\"]\n",
    "\n",
    "        # --- Build label lookup: {study_id: label_csv_path} ---\n",
    "        # study_id = filename without extension, e.g. \"SSC_12345\"\n",
    "        labels_dict = {\n",
    "            os.path.basename(p).rsplit(\".\", 1)[0]: p\n",
    "            for p in label_files\n",
    "            if os.path.exists(p)\n",
    "        }\n",
    "\n",
    "        # --- Filter to HDF5s that exist and have a matching label file ---\n",
    "        hdf5_paths = [p for p in hdf5_paths if os.path.exists(p)]\n",
    "        hdf5_paths = [\n",
    "            p for p in hdf5_paths\n",
    "            if os.path.basename(p).rsplit(\".\", 1)[0] in labels_dict\n",
    "        ]\n",
    "\n",
    "        if config.get(\"max_files\"):\n",
    "            hdf5_paths = hdf5_paths[: config[\"max_files\"]]\n",
    "\n",
    "        self.hdf5_paths = hdf5_paths\n",
    "        self.labels_dict = labels_dict\n",
    "\n",
    "        # --- Build index map ---\n",
    "        # Each item is (hdf5_path, label_path, start_index)\n",
    "        if self.context == -1:\n",
    "            self.index_map = [\n",
    "                (p, labels_dict[os.path.basename(p).rsplit(\".\", 1)[0]], -1)\n",
    "                for p in self.hdf5_paths\n",
    "            ]\n",
    "        else:\n",
    "            self.index_map = []\n",
    "            loop = tqdm(self.hdf5_paths, total=len(self.hdf5_paths), desc=f\"Indexing {split} data\")\n",
    "            for hdf5_file_path in loop:\n",
    "                file_prefix = os.path.basename(hdf5_file_path).rsplit(\".\", 1)[0]\n",
    "                label_path = labels_dict[file_prefix]\n",
    "\n",
    "                with h5py.File(hdf5_file_path, \"r\") as hf:\n",
    "                    dset_names = list(hf.keys())\n",
    "                    if len(dset_names) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Use first dataset to define length (same as your original behavior)\n",
    "                    first_name = dset_names[0]\n",
    "                    dataset_length = hf[first_name].shape[0]\n",
    "\n",
    "                for i in range(0, dataset_length, self.context):\n",
    "                    self.index_map.append((hdf5_file_path, label_path, i))\n",
    "\n",
    "        # If you have logger, keep; otherwise you can remove these.\n",
    "        # logger.info(f\"Number of files in {split} set: {len(self.hdf5_paths)}\")\n",
    "        # logger.info(f\"Number of files to be processed in {split} set: {len(self.index_map)}\")\n",
    "\n",
    "        self.total_len = len(self.index_map)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def get_index_map(self):\n",
    "        return self.index_map\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hdf5_path, label_path, start_index = self.index_map[idx]\n",
    "\n",
    "        labels_df = pd.read_csv(label_path)\n",
    "        labels_df[\"StageNumber\"] = labels_df[\"StageNumber\"].replace(-1, 0)\n",
    "\n",
    "        y_data = labels_df[\"StageNumber\"].to_numpy()\n",
    "        if self.context != -1:\n",
    "            y_data = y_data[start_index : start_index + self.context]\n",
    "\n",
    "        x_data = []\n",
    "        with h5py.File(hdf5_path, \"r\") as hf:\n",
    "            dset_names = list(hf.keys())\n",
    "\n",
    "            for dataset_name in dset_names:\n",
    "                if dataset_name in self.channel_like:\n",
    "                    if self.context == -1:\n",
    "                        x_data.append(hf[dataset_name][:])\n",
    "                    else:\n",
    "                        x_data.append(hf[dataset_name][start_index : start_index + self.context])\n",
    "\n",
    "        if not x_data:\n",
    "            # Skip this data point if x_data is empty\n",
    "            return self.__getitem__((idx + 1) % self.total_len)\n",
    "\n",
    "        x_data = np.array(x_data)  # (C, T, F) assuming each channel returns (T, F)\n",
    "        x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "        y_data = torch.tensor(y_data, dtype=torch.float32)\n",
    "\n",
    "        min_length = min(x_data.shape[1], len(y_data))\n",
    "        x_data = x_data[:, :min_length, :]\n",
    "        y_data = y_data[:min_length]\n",
    "\n",
    "        return x_data, y_data, self.max_channels, self.max_seq_len, hdf5_path\n",
    "\n",
    "\n",
    "def sleep_event_finetune_full_collate_fn(batch):\n",
    "    x_data, y_data, max_channels_list, max_seq_len_list, hdf5_path_list = zip(*batch)\n",
    "\n",
    "    num_channels = max(max_channels_list)\n",
    "\n",
    "    max_seq_len_temp = max([item.size(1) for item in x_data])\n",
    "    # Determine the max sequence length for padding\n",
    "    if max_seq_len_list[0] is None:\n",
    "        max_seq_len = max_seq_len_temp\n",
    "    else:\n",
    "        max_seq_len = min(max_seq_len_temp, max_seq_len_list[0])\n",
    "\n",
    "    padded_x_data = []\n",
    "    padded_y_data = []\n",
    "    padded_mask = []\n",
    "\n",
    "    for x_item, y_item in zip(x_data, y_data):\n",
    "\n",
    "        # first non-zero index of y_data\n",
    "        #print(y_item.shape)\n",
    "\n",
    "\n",
    "        tgt_sleep_no_sleep = np.where(y_item > 0, 1, 0)\n",
    "        moving_avg_tgt_sleep_no_sleep = np.convolve(tgt_sleep_no_sleep, np.ones(1080)/1080, mode='valid')\n",
    "        try:\n",
    "            first_non_zero_index = np.where(moving_avg_tgt_sleep_no_sleep > 0.5)[0][0]\n",
    "        except IndexError:\n",
    "            first_non_zero_index = 0\n",
    "\n",
    "\n",
    "\n",
    "        #non_zero_indices = (y_item != 0).nonzero(as_tuple=True)[0]\n",
    "        #first_non_zero_index = non_zero_indices[0].item() - 20\n",
    "        if first_non_zero_index < 0:\n",
    "            first_non_zero_index = 0\n",
    "\n",
    "        #first_non_zero_index = 0\n",
    "\n",
    "        #print(f\"First non-zero index of y_data: {first_non_zero_index}\")\n",
    "        # Get the shape of x_item\n",
    "        c, s, e = x_item.size()\n",
    "        c = min(c, num_channels)\n",
    "        s = min(s, max_seq_len + first_non_zero_index)  # Ensure the sequence length doesn't exceed max_seq_len\n",
    "\n",
    "        # Create a padded tensor and a mask tensor for x_data\n",
    "        padded_x_item = torch.zeros((num_channels, max_seq_len, e))\n",
    "        mask = torch.ones((num_channels, max_seq_len))\n",
    "\n",
    "        # Copy the actual data to the padded tensor and set the mask for real data\n",
    "        #print(f\"Shape of x_item: {x_item[:c, first_non_zero_index:s, :e].shape}\")\n",
    "        padded_x_item[:c, :s-first_non_zero_index, :e] = x_item[:c, first_non_zero_index:s, :e]\n",
    "        mask[:c, :s-first_non_zero_index] = 0  # 0 for real data, 1 for padding\n",
    "\n",
    "        # Pad y_data with zeros to match max_seq_len\n",
    "        padded_y_item = torch.zeros(max_seq_len)\n",
    "        padded_y_item[:s-first_non_zero_index] = y_item[first_non_zero_index:s]\n",
    "\n",
    "        # Append padded items to lists\n",
    "        padded_x_data.append(padded_x_item)\n",
    "        padded_y_data.append(padded_y_item)\n",
    "        padded_mask.append(mask)\n",
    "\n",
    "    # Stack all tensors into a batch\n",
    "    x_data = torch.stack(padded_x_data)\n",
    "    y_data = torch.stack(padded_y_data)\n",
    "    padded_mask = torch.stack(padded_mask)\n",
    "\n",
    "    '''\n",
    "    for y_data_mini in y_data:\n",
    "        unique_labels = torch.unique(y_data_mini)\n",
    "        print(f\"Unique labels in batch: {unique_labels}\")\n",
    "    '''\n",
    "\n",
    "    return x_data, y_data, padded_mask, hdf5_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_paths = [os.path.join(base_save_path, \"demo_emb/demo_psg.hdf5\")]\n",
    "label_files = [os.path.join(base_save_path, \"demo_psg.csv\")]\n",
    "test_dataset = SleepEventClassificationDataset(sleep_staging_config, channel_groups, split=\"test\", hdf5_paths=hdf5_paths, label_files=label_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=1, collate_fn=sleep_event_finetune_full_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# Validation loop at the end of each epoch\n",
    "model.eval()\n",
    "all_targets = []\n",
    "all_logits = []\n",
    "all_outputs = []\n",
    "all_masks = []\n",
    "all_paths = []\n",
    "\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for (x_data, y_data, padded_matrix, hdf5_path_list) in tqdm.tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        x_data, y_data, padded_matrix, hdf5_path_list = x_data.to(device), y_data.to(device), padded_matrix.to(device), list(hdf5_path_list)\n",
    "        outputs, mask = sleep_staging_model(x_data, padded_matrix)\n",
    "        all_targets.append(y_data.cpu().numpy())\n",
    "        all_outputs.append(torch.softmax(outputs, dim=-1).cpu().numpy())\n",
    "        all_logits.append(outputs.cpu().numpy())\n",
    "        all_masks.append(mask.cpu().numpy())\n",
    "        all_paths.append(hdf5_path_list)\n",
    "\n",
    "\n",
    "save_path = os.path.join(base_save_path, \"demo_sleep_staging\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "targets_path = os.path.join(save_path, \"all_targets.pickle\")\n",
    "outputs_path = os.path.join(save_path, \"all_outputs.pickle\")\n",
    "logits_path = os.path.join(save_path, \"all_logits.pickle\")\n",
    "mask_path = os.path.join(save_path, \"all_masks.pickle\")\n",
    "file_paths = os.path.join(save_path, \"all_paths.pickle\")\n",
    "\n",
    "save_data(all_targets, targets_path)\n",
    "save_data(all_outputs, outputs_path)\n",
    "save_data(all_logits, logits_path)\n",
    "save_data(all_masks, mask_path)\n",
    "save_data(all_paths, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 6960, 5), (1, 6960))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs[0].shape, all_targets[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_logits), len(all_outputs), len(all_targets), len(all_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 6960, 5), (1, 6960, 5), (1, 6960), (1, 6960))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits[0].shape, all_outputs[0].shape, all_targets[0].shape, all_masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logits_flat = [logits.reshape(-1, logits.shape[-1]) for logits in all_logits]\n",
    "all_outputs_flat = [outputs.reshape(-1, outputs.shape[-1]) for outputs in all_outputs]\n",
    "all_targets_flat = [targets.reshape(-1) for targets in all_targets]\n",
    "all_masks_flat = [mask.reshape(-1) for mask in all_masks]\n",
    "\n",
    "# Convert lists of flattened arrays to single concatenated arrays if desired\n",
    "all_logits_flat = np.concatenate(all_logits_flat, axis=0)\n",
    "all_outputs_flat = np.concatenate(all_outputs_flat, axis=0)\n",
    "all_targets_flat = np.concatenate(all_targets_flat, axis=0)\n",
    "all_masks_flat = np.concatenate(all_masks_flat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6960, 5), (6960, 5), (6960,), (6960,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits_flat.shape, all_outputs_flat.shape, all_targets_flat.shape, all_masks_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filter = all_masks_flat == 0\n",
    "\n",
    "# Apply the mask to each flattened array\n",
    "all_logits_filtered = all_logits_flat[mask_filter]\n",
    "all_outputs_filtered = all_outputs_flat[mask_filter]\n",
    "all_targets_filtered = all_targets_flat[mask_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.26814031715521386,\n",
       " 1.0: 0.028351753964440174,\n",
       " 2.0: 0.2715040845747237,\n",
       " 3.0: 0.15281114848630467,\n",
       " 4.0: 0.27919269581931766}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter(all_targets_filtered)\n",
    "total = sum(counts.values())\n",
    "prevalence_dict = {cls: count / total for cls, count in counts.items()}\n",
    "prevalence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Wake\", \"Stage 1\", \"Stage 2\", \"Stage 3\", \"REM\"]\n",
    "# class_labels = [\"No-Apnea\", \"Apnea\"]\n",
    "class_mapping = {label: idx for idx, label in enumerate(class_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Wake: 0.958\n",
      "F1 Score for Stage 1: 0.396\n",
      "F1 Score for Stage 2: 0.634\n",
      "F1 Score for Stage 3: 0.694\n",
      "F1 Score for REM: 0.978\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjMAAAGGCAYAAACOvQCZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACML0lEQVR4nOzdd1gUxxvA8e8BciBViqIiRey9N+wNW2I39hajSdTEmKjRxKgpGpNfjDUaS6wxGjX23iv2hr1XBAEFpJfb3x/oxQuglIM74P3kuefJzc7svjse3Mvs7KxKURQFIYQQQogcysTQAQghhBBCZIYkM0IIIYTI0SSZEUIIIUSOJsmMEEIIIXI0SWaEEEIIkaNJMiOEEEKIHE2SGSGEEELkaJLMCCGEECJHk2RGCCGEEDmaJDNCCCGEyNEkmRFCCCFEhhw6dIh33nmHIkWKoFKp2LBhg852RVH45ptvKFy4MJaWljRv3pybN2/q1Hn27Bm9evXC1tYWe3t73n//fSIiItIVhyQzQgghhMiQyMhIKleuzJw5c1Lc/tNPPzFz5kzmzZvHiRMnsLKywsfHh5iYGG2dXr16cfnyZXbv3s2WLVs4dOgQgwcPTlccKnnQpBBCCCEyS6VSsX79ejp06AAkjcoUKVKEzz//nC+++AKAsLAwChUqxJIlS+jevTtXr16lXLlynDp1iho1agCwY8cO2rRpw6NHjyhSpEiaji0jM0IIIYTQu7t37xIQEEDz5s21ZXZ2dtSuXRtfX18AfH19sbe31yYyAM2bN8fExIQTJ06k+Vhm+gtbCCGEEDldbGwssbGxOmVqtRq1Wp2u/QQEBABQqFAhnfJChQpptwUEBFCwYEGd7WZmZjg4OGjrpEWeTGYsm/9o6BByDf9NowwdQq5hbiYDpfpiaqIydAi5hkxE0B/LfNl0nKrDMtV+THsnJk2apFM2YcIEJk6cmKn9ZqU8mcwIIYQQuZYqc38YjR07lpEjR+qUpXdUBsDFxQWAwMBAChcurC0PDAykSpUq2jpPnz7VaZeQkMCzZ8+07dNC/hQUQgghchOVKlMvtVqNra2tzisjyYynpycuLi7s3btXWxYeHs6JEyeoW7cuAHXr1iU0NJQzZ85o6+zbtw+NRkPt2rXTfCwZmRFCCCFyk0yOzKRHREQEt27d0r6/e/cu58+fx8HBATc3N0aMGMH3339PyZIl8fT0ZPz48RQpUkR7x1PZsmVp1aoVH3zwAfPmzSM+Pp5hw4bRvXv3NN/JBJLMCCGEELmLKvvmjJ0+fZomTZpo37+6PNWvXz+WLFnC6NGjiYyMZPDgwYSGhlK/fn127NiBhYWFts2ff/7JsGHDaNasGSYmJnTu3JmZM2emK448uc6MTADWH5kArD8yAVh/ZAKw/uS9b4isk20TgGuOfHulN4g+NU1PkWQfGZkRQgghcpNsvMxkLCSZEUIIIXKTbLzMZCwkmRFCCCFyExmZEUIIIUSOlgdHZnJE+hYWFkZiYqKhwxBCCCGEETLaZOb06dO0atWK/Pnz4+joyMGDBwEIDg6mffv2HDhwwLABCiGEEMZIZZK5Vw5klFEfO3aM+vXrc/PmTXr37o1Go9Fuc3JyIiwsjN9//92AEQohhBBGKpMrAOdERpnMjBs3jrJly3LlyhUmT56cbHuTJk3S9WhwIYQQIs+QkRnjcOrUKQYMGIBarUaVQpZYtGjRdD0aXAghhMgz8uDIjFHezZQvXz6dS0v/9fjxY6ytrbMxIiGEECKHyKGjK5lhlGdcp04d1q5dm+K2yMhIFi9eTKNGjbI5KiGEEEIYI6NMZiZNmsTp06dp27Yt27dvB+DChQssXLiQ6tWrExQUxPjx4w0cpRBCCGGE8uCcGaO8zFS7dm22bdvGRx99RN++fQH4/PPPAfDy8mLbtm1UqlTJkCEKIYQQxikPPmjVKJMZgKZNm3L9+nXOnz/PzZs30Wg0eHl5Ub16dVQqFbGxsajVakOHKYQQQhiXHDq6khlGecZjxozR/n+VKlXo2rUr7733HjVq1EClUvHixQtatWplwAiFEEIII5UH72YyymRm2rRpTJgwIcVtz58/p2nTppw7dy6boxJCCCGEMTLKy0wLFy5k4MCBWFhYMHbsWG15QEAALVq04MmTJ+zevduAEQohhBBGKg9eZjLKZKZfv37Exsby0UcfoVarGTlyJPfu3aNZs2ZER0dz4MABKlSoYOgw36hqyUJMHNiIOuWKolLBiSv+fLVgPxdvP9XWsVSb0denEu3qlaS8pzPWlvm47R/KH1vPs2jreTQa5a3HUeczZXiXmvRsXgH3QnaERsRw/PJjvl92hKv3g7PyFI3K4oXz+H3OTIp7lWDl2k1vrNuhTXMCnvinuM21mBtrN+3IihCNVlRUJEsXL+KS30Uu+/kRHh7GxO8m826HTmlqf+XyJeb9Nourly8TFRVFUVdXOnbuQrfuvTA1Nc3i6I1PXFwcc2bNYOvmjYSHh1OyVGmGfTKCuvW839o2MDCQ/02djO+xo2g0GmrWqs2oMeNwLVYsGyI3PnFxcfw2W7cvhw5/e1+2btmUJ/6PU9xWzM2dzdt2ZUW4xiOHXirKDKNMZgAGDx5MTEwMI0aMIDg4mOXLl2NmZsbhw4fx8vIydHhvVKVEIfZO782joBdMXn4UExMY/E41dk3rSYOhy7j56BkAnoXtmTasBfvP3WPWupOER8bRooYnMz/1oVbZInzw09a3HmvJuHdpW7cEf2y7wPmbARR2tGFI+2ocmNmHmh8s4sHT8Kw+XYN7GhjA0kULsLS0TFP9z0Z9SVRUlE5ZwBN/fp8zk9p13/6Fk9uEPn/Ognm/4VK4CKVKl+b0qZNpbnvl8iUG9OmBm7sH/QYOwsLCgmNHDvPzj5N59PAho778KgsjN07jx33Jnt076dWnL25uHmzauJ5hHw1mwR9LqVa9RqrtoiIjGTSgLxERL3j/gyGYmeVjxbIlDOzfm7/XbcDevkA2noVx+OarpL7s2bsvbu4ebNqwnuEfJ/Vl1Wqp9+WoMeOIjorUKfP392fOrOlpSipzPBmZMS6ffPIJsbGxjBkzhjJlyrBnzx6KFCli6LDe6psBDYiOTaDxJ8t4Fh4DwF97LnNxyWC+fb8RPSatByDwWSQ1PlikM4KyaOt55n3Rhn6tKjFlxVHu+IemepwijtZ0aFCaX/8+wbj5+7XlR/0esvOXnrRvUJpZ605lzUkakZnTfqZCpUokJmoIC33+1vqNmjRPVvbHgnkA+LRup/f4jJ2Tc0F27T+Mk5MzVy770bt71zS3XbdmNQALlyzHzs4egC7dujOof282b1yf55IZv4sX2bF9KyO/GE2/Ae8D8E77DnRu347p0/7Hsj9Xpdp29aqVPLh/jz9XraFCxaSlJ+o3aEDnDu+wbMliPhkxMlvOwVj4+SX15Wefv9aX73agS4d2/PrLm/uyabPkP+MLfv8NgDZt38magI2JjMwYxrvvvvvG7dbW1tjb2/Phhx9qy1QqFRs3bszq0DLEu0Ixdp++o01kAAKeRXL44kNa1/bCyiIfkTHxhIRHExIenaz9piM36NeqEmXcnN6YzFjnNwfg6XPdv0ACnkUAEB0br4ezMW7nzpxm/95dLP1rHb9M/SHD+9m1fQtFirpSqUpVPUaXM5ibm+Pk5JyhtpGRkajVamxsbHXKnZwLcv/ePT1El7Ps2bUDU1NTOnd9T1umVqvp2LkLM6dPI+DJE1wKF06x7e5dOylfoaI2kQHwLO5Frdp12bVje55LZlLryw6dujBrxpv7MiXbt26hqKsrVapWy4pwjYuMzBjGxYsXU3yg5CuOjo48efKEJ0+eaMveVN/Q1PlMiY5NSFYeHRuP2tyM8p7OnLya8pwNgEIOVgCEhEWlWgfgjn8oj56G80mXWtx4+IwLtwIp7GjND4ObcPdJKGv2X83ciRi5xMREfpn6A+926EyJkqUyvJ/r165w7+4d+g8aosfo8oYaNWuxa8c2fvh2Ar369tdeZtq3ZzcjPh9l6PCy3bVrV3F390j27LhXCcq1a1dT/ALWaDTcvHGdDh07J9tWoWJFfI8dITIyAiurvPNMumtX39yX16+n3Jcp7+sKd+7cZtDgD99eWeRIRpHM3Mtlf8HdePSMWmWLYGKi0k7izWdmQs0ySZfIijjZpNo2n5kJwzrV4O6TUE5ff5JqPYCERA09Jq1nybh3Wfd9F235metPaPLJcsIiY/VwNsZr/drVBDzxZ9a8RZnaz85tW4C8eYkpszp27srtWzdZt+Zv1q9bA4CpqSljxo2nS7fuBo4u+wUFBeHknHyU69XIV1DQ02TbAMLCQomLi0uxrfPLsqCnT7HyzDvJTHBwKn35Wn+k1bYtmwFo0/bNVwFyDSP+Yz+rGEUyk9vM33SWWSNaMe/zNkxbfRwTExVf9qqHi0PSLyIL89S7/dfhLSnn4UyHcX+TmIa7mZ5HxHDxdiD/HLrGyav+eBUpwBc96vDnNx1oO3oVsfGJejsvYxIWGsr8ubMY8MGHFHBwyPB+NBoNu3dup1SZsngWN+6J5cbI1NQU12Ju1PX2pkXLVpibq9m5fSs/TfkeR0cnmqQwdyE3i42NwdzcPFn5q9XKY2Nikm1LKk/6wyOltuYv28bE5O4/Tv4rNiaGfCn1pfnL/ohNuS//S6PRsGPHVsqULUdxI795RG/kMpPxefHiBWFhYWg0mmTb3Nzc3to+NjaW2FjdXwKKJgGVSdad+sIt53F1tuWzbrXp41MRSBotmfb3cb7s5U1kdFyK7T7rVov321Zh4uJD7Dx5563HsbVSs+fXXkz/+yQz1v57B8qZG0/YPa0XfVtVYsHm3Lm44Lw5M7C1taNbj16Z2s+5M6cIehpI91599RRZ3rJ44Xz++nM5G7buIH/+pMujLVu1ZvDAvvw4+VsaNGqMmZnR/5rRG7Xagri45D/fr34HqS0sUm5nkfQFnVLbuJdtLSzy1uNb1BYWxKfUl3Ev+0Odcl/+15nTJ3kaGEjvPv31GZ5xy4MjM0abvs2dO5eSJUtib2+Pu7s7np6eyV5pMWXKFOzs7HReCfcOZG3wwMTFh3DvOpNmI1ZQ44NF1B+6FJOXH7BXt2a/rnfLinw/qAnzN59l6p/H0nSMDg1K4+JgzRbfmzrlRy4+JCwyhrrli2b+RIzQg/v32PjPGrr16E1QUBD+/o/x939MXFwsCQkJ+Ps/JiwsNE372rFtCyYmJrRs1TZrg86l1qz+i5q1amsTmVcaNm5K0NOn+Key1kdu5ezsTHBQULLy4OCgl9sLptjOzs4ec3PzFNsGvSxzLphy29zKySmVvkxnf2zbshkTExNatclDP+N58KnZRhn1vHnzGDp0KCVKlOD7779HURRGjBjBl19+iYuLC5UrV2bRorTNkxg7dixhYWE6LzOPxll7Ai+FRsRy7NIjLt9N+uFrWs2DR0/Duf4wRKdeu3olmft5azYeuc6ImWlfzKlggfwAmKbwhFRTExPMTI3ynzfTgoKeotFomPbTZDq1baF9Xfa7yIP79+jUtgV/zJ/71v3ExcVxYO9uqtWomee+KPQlJCSYxBRGTRMSkibAJybkzsucqSldpgz3798jIiJCp9zv4gUAypQpm2I7ExMTSpYsxeXLl5Jt8/O7iGuxYnlq8i+8vS9Ll065L18XFxfHnj27qFGzFgULFsqSOIVxMMpvu1mzZuHj48P27dsZPHgwAG3btuWHH37gypUrvHjxgpCQkLfsJYlarcbW1lbnlZWXmFLTpXEZapQpwux/TqO8NhXGu2Ixln31LkcuPqT/lM06215nZmpCqWIOuDj8+xfwrUdJa6p0bVJOp267eiWxtjTnwq1AvZ+HMfDyKsnUaTOTvYp7lcDFpTBTp83knQ5Jd4UEPPHn3t2UL9kdO3KIFy/CZeJvGgUFPeXunTvEx/97y7+7uwcnfI8S+tr6PomJiezeuR0rK6s8t3Jt85atSExM1K6/A0lfqBvX/0PFSpW1d9888ffn7p3b/2nrw+VLfly+5Kctu3f3DqdOHKdFy7z3YN0WqfXlhv/05ZPkffnKkUMHeREenjfWlnldHhyZMcqL2bdv32bo0KEA5MuXD/j3WrKdnR2DBg3it99+4/PPPzdYjG/iXbEY4/p4s/f0XULCo6lVrgh9fSqx8+RtZv/z7yJ2bgVtWftdZxQF1h++RqeGZXT2c+nOUy69HNUp4mTDhcWDWb7Tj8E/J60MvNX3JpfvBjGutzduBW2TJgAXLcCH7avxJPgFS7ZfzL6Tzkb2BQqkuPDdqj+XA7qL4k0aP5ZzZ05x/NyVZPV3btuCubk5TZq1zLpgc4hVK1cQ8eKF9m6bQwf38zQwKRl+r2dvbGxsmD19Gps3bWDLjj0UKeoKQP/3B/P12FH07fkenbp0w0KtZsf2rVy9cpmPh4/Q/vzmFZUqVaalTytmTp/Gs5CQpKXzN67H3/8xE7/7dx2kr8eN4fSpk1y4fF1b9l6Pnvyzdg3DPh5Cv/4DMTMzY/nSJTg4OtK3/0BDnI5BVaxUmRY+rZg1YxrPnv3bl0/8HzPx29f6cuwYzpw+yflL15PtY9vWzZibm9OshU92hm54eXDOjFEmM3Z2dtphaltbW/Lnz8/Dhw+1221sbAgICDBUeG/lH/yCRI2GEd1qY5PfnHtPQpm0+BAz1p7UuUPJvbA99tZJk9hmfJL8h+37ZUe0yUxK4hM0NP9sBWN7e9OqthfdmpbjRVQcm4/e5Js/Dqa4IJ9IEhkRwbEjB6lXvxHWNqnfKp9XLF/6B0/8/137aN+e3ezbk/Qw1zbt3sEmlT5q0+4d7AvYs3jhfJYtWURkRATuHp6MGz8xT96aDfD9lJ+YM2s6WzZvIjw8jJKlSjNzzjyq16j5xnZWVtYsWrKcn6dOZsHvc9FoNNSoWZtRY8bikIk79nKy7ycn9eXWdPYlQEREBIcPHaBBw8apfn5zrRw6upIZKkVJ7cKG4TRr1gwPDw/tvJjmzZvz7NkzNm/ejEajoV27dpiYmHDuXMbu1LFs/qM+w83T/DflvYXRsoq5Wd77BZRVUppHJjLG+L4hci7LbBqotOwwP1PtozcM1lMk2ccoR2Z69+7NvHnziI2NRa1WM2nSJJo3b669FTtfvnysW7fOwFEKIYQQRigPjswYTTJTv359GjRogLe3Nx06dGDAgAHabd7e3ly6dInNmzdjZmZGy5YtKVUq48vXCyGEECL3MJpk5sGDB0ydOhWVSoVKpaJMmTLUr19f+/Ly8mLEiBGGDlMIIYQwbjIB2HAePHjAo0ePOHLkCEeOHOHYsWMsWrSI+fPno1KpKFKkCN7e3trkpnLlykb9sEkhhBDCEPLid6NRTgB+JSIigmPHjnH06FGOHj3KiRMniIpKepK0ra0tz58/f8seUiYTgPVHJgDrj0wA1h+ZAKw/xvsNkfNk1wRgqy6LM9U+cu2At1cyMkYzMpMSa2trWrZsScuWLXny5An79+9nzpw5+Pr6Eh4ebujwhBBCCOOTB3N5o01mLl26xJEjR7SjMvfv30etVlO1alU+//xzvL29DR2iEEIIIYyA0SQzBw8e5OjRoxw5coTjx48TGhpKoUKFqFevHkOHDqVevXpUr14d8xQeCS+EEEKIJHlxzozRJDNNmjQhX758dO3alVmzZlG3bl2KFy9u6LCEEEKIHEWSGQOqWLEily9f5q+//sLPz4969epRv3596tWrh6enp6HDE0IIIXIESWYM6MKFC7x48QJfX1/tPJkVK1YQFRVFwYIFqVevHt7e3trLTXntAXZCCCFEWuTFZMaob81OTEzk/PnzHD16VHuLtr+/P2q1mho1anDo0KEM7VduzdYfuTVbf+TWbP2RW7P1x3i/IXKe7Lo1267n8ky1D1vZR0+RZB+jGZlJiampKdWrV6d69eo0adKEw4cP8+eff2pHb4QQQgghjDKZiY2N5cSJE9rVgI8fP05YWBgAarWaBg0aUL9+fQNHKYQQQhifvHiZyWiSmY0bN2qTl3PnzhEfH4+iKDg6OmqTl/r161OjRg2ZLyOEEEKkQpIZA+rYsSMAnp6evPfee9rkpWzZsgaOTAghhMg5JJkxoNWrV1O/fn0KFy5s6FCEEEKIHEuSGQPq2rWroUMQQgghRA5kNMmMEEIIIfQg7w3MSDIjhBBC5CZymUkIIYQQOVpeTGZkyVEhhBAiF1GpVJl6pUdiYiLjx4/H09MTS0tLvLy8+O6773j94QKKovDNN99QuHBhLC0tad68OTdv3tTrOUsyI4QQQuQmqky+0mHq1KnMnTuX2bNnc/XqVaZOncpPP/3ErFmztHV++uknZs6cybx58zhx4gRWVlb4+PgQExOT2TPVkstMQgghhMiQY8eO0b59e9q2bQuAh4cHf/31FydPngSSRmWmT5/O119/Tfv27QFYtmwZhQoVYsOGDXTv3l0vccjIjBBCCJGLZPYyU2xsLOHh4Tqv2NjYFI9Vr1499u7dy40bNwC4cOECR44coXXr1gDcvXuXgIAAmjdvrm1jZ2dH7dq18fX11ds558mRmbvrPjd0CLnGtqtPDB1CrhEZn2joEHKNvjXcDR1CrnEvKNLQIeQaZYtYZctxMjsBeMqUKUyaNEmnbMKECUycODFZ3S+//JLw8HDKlCmDqakpiYmJ/PDDD/Tq1QuAgIAAAAoVKqTTrlChQtpt+pAjk5mHDx9y9+5dGjZsaOhQhBBCCKOS2WRm7NixjBw5UqdMrVanWPfvv//mzz//ZOXKlZQvX57z588zYsQIihQpQr9+/TIVR3rkyGRm2bJlfPPNNyQmyl+yQgghxOsym8yo1epUk5f/GjVqFF9++aV27kvFihW5f/8+U6ZMoV+/fri4uAAQGBio87iiwMBAqlSpkqk4XydzZoQQQgiRIVFRUZiY6KYSpqamaDQaIOnh0S4uLuzdu1e7PTw8nBMnTlC3bl29xWE0IzPffvttmusePHgwCyMRQgghcrBsXDPvnXfe4YcffsDNzY3y5ctz7tw5pk2bxsCBA5NCUakYMWIE33//PSVLlsTT05Px48dTpEgROnTooLc4jCaZmThxIiqVSmehnTfJiyscCiGEEG+Tnd+Ps2bNYvz48Xz88cc8ffqUIkWKMGTIEL755httndGjRxMZGcngwYMJDQ2lfv367NixAwsLC73FoVLSmj1kMRcXF6pVq8by5cvfWveXX35h6tSpGZ4zExAWn6F2Irm9twINHUKuIXcz6Y/czaQ/d5/K3Uz6kl13M7l+vCFT7R/91kEvcWQnoxmZqV27NqdPn8bR0fGtda2ssucDIYQQQuQ0efHKhdFMAK5VqxZPnjzhwYMHb63r7u4ut2ULIYQQKcnGxxkYC6NJZr766is0Gg1ubm5vrdu7d2/279+fDVEJIYQQwtgZzWUmIYQQQmReXrzMJMmMEEIIkYtIMiOEEEKIHE2SGSGEEELkaHkxmTGaCcBCCCGEEBkhIzNCCCFEbpL3BmYkmRFCCCFyE7nMZEQePHjAhx9+SOnSpXFwcODQoUMABAcH88knn3Du3DkDRyiEEEIYH5VKlalXTmSUIzNXrlyhQYMGaDQaateuza1bt0hISADAycmJI0eOEBkZyaJFiwwcqRBCCGFccmg+kilGmcyMHj0ae3t7jh8/jkqlomDBgjrb27Zty+rVqw0UnRBCCGG8curoSmYY5WWmQ4cO8dFHH+Hs7JziP4qbmxuPHz82QGRCCCGEMDZGOTKj0WjInz9/qtuDgoJQq9XZGJEQQgiRM+TBgRnjHJmpVq0aW7duTXFbQkICq1atok6dOtkclRBCCGH8ZAKwkRg7dizt2rXjo48+onv37gAEBgayZ88eJk+ezNWrV5k9e7aBo8yYRw/us+j3WfhdOEd4WBiFXArTzKcN3Xv3x8LCMtV2i+fPYcnCucnKzc3N2X3kbFaGbHBPH93j4NqlPLl7k4iwZ+QzV+Ps6k7dtt0oXb2ett7GeVO5cGhXsvaOhYsx9JclaTpWbHQUh9Yv5+qJQ7x4HkJ+G1tcS5ajw0dfkk9toa9TMpjgR/fw3bCcwHs3iQx7jpm5GscibtRs0xWvqnV16p7bvZHzezcRFhSApbUtpWs3wrtzP/KpU/+cvu7WWV98NywnxP8++W3sKd/Ah7rte2FiapoVp2Y04uLimDNrBls3byQ8PJySpUoz7JMR1K3n/da2gYGB/G/qZHyPHUWj0VCzVm1GjRmHa7Fi2RC54URHR7Fh1VJuXL3EzWuXiXgRzvAxE2nW6t1kdTUaDTs3r2Pn5nX4P7yP2sICD6+SDPz4CzxLlHrrcf5cNAffg3sJC3uOS+GitO3Ug9btu2bVqRlEDs1HMsUok5nWrVuzZMkSPv30U+bPnw9A7969URQFW1tbli1bRsOGDQ0cZfo9DXzCkAE9sLa2pmPXHtjY2nHZ7wKL58/hxrUrTP7frLfuY+SY8Vi+dgnOxCR3fzEAhAUFEhcTTeWGLbEp4Eh8bAxXTx1m9S/jafv+Z1Rv1k5b1zRfPt754HOd9mpLqzQdJyYqgqXfjSQ8JIhqTdvi4FKUqPBQHlz3IyE+PlckM+EhT4mLiaacdwusCziSEBfLjVOH2TB9Ai36f0qlJm0BOLR6Iae2/U2pmg2o1rIjIf73ObdnI8GP79Nl1JS3HufuhZNsnDmRYmUq0bT3UIIf3eXEppVEh4fSvP8nWXyWhjV+3Jfs2b2TXn364ubmwaaN6xn20WAW/LGUatVrpNouKjKSQQP6EhHxgvc/GIKZWT5WLFvCwP69+XvdBuztC2TjWWSv8LBQVi9bgHMhFzy8SnHp/OlU6876aRKH9mynccu2tO34HjHR0dy5dZ2w0GdvPEZiYiKTRg3l1o0rtGnfjcKubpw75cvv06cQ8SKcrr3f1/dpGYyJSd7LZowymQHo06cPnTp1YteuXdy6dQuNRoOXlxc+Pj7Y2NgYOrwM2bltMxEvwpk9fxmeXiUAeLdjVxSNhp3bNvEiPAwbW7s37qNRs5a5+pdaSkpWrU3JqrV1ymr6dGDBVx9xfNtanWTGxMSUSvVbZOg4+1YtIiwokA8mz6NAwcLacm96ZCxwI1S8ci2KV66lU1al+busmDCU0zvXUalJWyJCQzizcx3l6jWn9ZDR2noFCrmyb8Ucbp/zTTaK818HVy3AuZgnXUb9qB2JMbfIz4ktq6jasgOORdz0f3JGwO/iRXZs38rIL0bTb0DSl+M77TvQuX07pk/7H8v+XJVq29WrVvLg/j3+XLWGChUrAVC/QQM6d3iHZUsW88mIkdlyDobg4ODE4nW7KODgxK3rV/jiw94p1juyfxf7d27my2//R50GTdN1jOOH93Ht8gWGjfqG5m06ANC6fVemThjFmuULadG2I/YFHDJ7KsJAjHLOzCtWVlZ07NiRUaNGMWbMGLp06ZJjExlI+ssLoICjo065o5MzJiYmmOXL9/adKAqREREoipIVIeYYJiam2Do4ExMVkWybRpNIbFRkuvYXExnB+YM7qNasLQUKFiYxIZ6E+Dh9hWvUTExMsXFw1vbZk1tX0SQmUrpOY516r95fO3HgjfsLeXyfEP/7VGrcRueSUpVm74KicPPUYX2Gb1T27NqBqakpnbu+py1Tq9V07NyFC+fPEfDkSaptd+/aSfkKFbWJDIBncS9q1a7Lrh3bszRuQ8tnbk4BB6e31tu0ZgUly1SgToOmaDQaYqKj03yMKxeTFlpt0NRHp7xBUx/i4mI5efRAumI2ZipV5l45kVGOzDx48OCN21UqFRYWFjg5OeWoyUpVqtdk5bJF/PT9NwwYPBQ7OzsuXTzPxnWr6dytF5aWqd/B9Ur3jq2IjorC0tKS+o2a8vGno3BwfPsvgdwgLiaahLg4YqIjuXHmGLcunKR8nSY6deLjYpn6/rvEx8ZgYWVDhXpNaN5jMOZvmI8EvLyUFIdDoaKsmT6Ra6ePoigKriXL0ab/J7h4lMjKU8t28bHRxMfFERcVye1zvty9eIrStRsBkBAfD4CZublOm3zmSXcQBt67+cZ9P71/C4BCHrrzF6wLOGLt4MTTB7f1cg7G6Nq1q7i7e2Btba1T/ipBuXbtKi6FCydrp9FouHnjOh06dk62rULFivgeO0JkZARWVtbJtucVUZER3Lx2mdbtu7J8wSy2rl9NTHQUhQoXpc8Hw6nfpOUb28fHx2FiYprsj0bzl5ePb9+4mmWxZ7ec9L2oL0aZzHh4eKTpH8PCwoIGDRowfvx4vL3fPrnO0GrXrc/7Q4azYskCjh7ary3vM2Awgz568zwCG1tbOnbtSfmKlTE3N+fi+TOsX7OKq5cvMX/paqysc/8vud1/zuPM3i0AqFQmlKlZn9b9h2u3W9s7Uq/dexT2LImi0XD74ilO795E4P079Bs/7Y0TT58FJK1btHfVQgoUKkKHj74kNiqSg/8sY9kPX/DRT4uwKeCYavuc5sBf87m4P+mOQZXKhJI1vGnWZxgADoVdAfC/cRm3slW0bR7fuARAxPOQN+474uXcBSv75EP21naOb22fkwUFBeHk7Jys3MnJ+eX2pym2CwsLJS4uLsW2zi/Lgp4+xcoz9/+cpybA/xGKonB43y5MTU3pN+RT8ltZs2XdX/zy3VjyW1lRrVbq3wNFi3mg0SRy/Yof5SpW1ZZf9UsasQkJTvnfJifKg7mMcSYzixYtYubMmTx8+JBevXpRokTSX8U3b95k5cqVuLu7M2DAAG7dusWKFSto2rQpO3bsoEmTJm/Zs+G5FClC5arVadi0BXZ2dvgeOcSKJQtwcHSiU7eeqbbr0r2PzvtGTVtQplxFvv9mDBvWraJXv0FZHbrB1W7VmbK1GvLieQhXThxAUTQkJsZrtzfrrtsHFeo1xcHFlf1//8GVEwepUC/1a+xxMUnD1SqVir5f/U87kuPiUYI/Jgzn1O6NNO02MAvOyjCqtexIqZoNiHgewo2Th9BoNCS+fGRIIY+SFPYqw8ltf2NdwIliZSvzzP8Be5bNwsTUjIS42DfuOyE+aXtKl01N8+UjLiZK/ydkJGJjYzD/z4gWoF0XKzYmJuV2MUl9llJb85dtY2Le3O+5XXR00ufmRXgoP81ZSqlyFQGo5d2IIT3asWb5ojcmMw2bt2L1svnM/mkSgz/9ksKubpw/5cv2jWsAiIvNPf2bF0dmjHLOjL+/P3Fxcdy6dYsZM2YwfPhwhg8fzsyZM7lx4wbR0dFER0czffp0rl+/TuHChZk0aVKK+4qNjSU8PFznFWugD+3eXdv43+RJjPpqEu906ELDJi0YM/47fNq25/fZvxIWGpqu/bVo1RYHRyfOnDyeNQEbGaeibhSvWJ3KDVvSY9Rk4mKiWfXz12+cP1SnTRdUKhPuXnrz7etmLy+hlKpWV+eSlGvJctg7F+bRjcv6OQkj4VjEDffy1ShfvwUdR35HfEw0G379RtuX7wz7Budixdm56BcWftGX9dO/oVSthhR093rrJTuzfEl9+epy1esS4+O123MjtdqCuLjkc61e/c5RW6R8R5zaIqlPUmr76kvWwiL39ltaqF9eDipUuKg2kQGwtMxPzboNuXntEomJCam2L+DgxFc//Ep8fBwTR33MkB7tWPr7DD4YnjTJ3SINl/lziry4zoxRJjPz5s1j0KBB2NvbJ9vm4ODAoEGDtOvMODo6MnDgQM6cOZPivqZMmYKdnZ3Oa9a0qVkZfqo2rF1NydJlKFjIRafcu0FjYmKiuZmBa7YFC7kQHh6mrxBzlLK1GuJ/5zohTx6lWiefuRpLG1uiI1+8cV+vLiFZ2SW/U8zKzp6YyOQTjXOTUjUbEHD3Os8DkvrSxsGJHl//ysCpi3lv3C8M+XUljd77gBfPgihQyPWN+7J+eXkpMoVbZSPCQrDORZfr/svZ2ZngoKBk5cHBQS+3F0y2DcDOzh5zc/MU2wa9LHMumHLbvMLBMelyW0p3HNkVcCAhIeGtE4LLV67OvD83M23BX0yZ+QeL1uzQJkZFXHPnHXZ5hVFeZgoJCSEqKvWh6MjISO0POICLi0uqf52PHTuWkSN1b2l8HmOYHO75sxBsbG2Tlb96InhiYmK69qcoCgFP/ClZqoxe4stpXl3ueNOdS7HRUUS9CCO/zZtveS/smTRZ9cWz4GTbXjwPwalI7l607NWdW//tywIuRSngUhRIukspMvQZ5eu/eaKls5sXAIH3blDY69/PZsTzECKeBePcuLg+QzcqpcuU4dTJE0REROhMAva7eAGAMmXKptjOxMSEkiVLcfnypWTb/Pwu4lqsWJ6e/Avg4ORMAQcnQoKTJ3zPgoMwN1djmf/ta0qZmppSvERp7fsLZ04AULl67dSa5Dg5dHAlU4xyZKZmzZrMmDEDPz+/ZNsuXrzIrFmzqFXr37Uyrl69iqtryn8tqtVqbG1tdV6Geq6Tq5s7N69f5eH9ezrle3dtw8TEBK+Xq1cGBjzh/r07OnVCnyf/K3fDutWEPn9Grbr1syxmYxAZ9jxZWWJCAhcP78bs5WrACXFxxEYnT4APrV8OikKJ19ZWSUxIIPjxA168NhHVqUgxCrl7cf3MMaJeG+m6ffE04SFPKV6hup7PyjCiwlPuy8tHkvrSsah7iu0UjYZDqxdiZq6mctN2Om1D/B8QEfpaX7p64FC4GBcPbEOj+TdBv7BvM6hUlKqZ8xa8TKvmLVuRmJjIujWrtWVxcXFsXP8PFStV1t7J9MTfn7t3bv+nrQ+XL/lx+dK/v/fu3b3DqRPHadGyVfacgJHzbtKC4KcBnD/976X18LDnnDx2kIpVa2JikvSVlpAQz6MHd3kWkjzxeV1Y6HPWr1qCR/GSuSyZyXuXmYxyZGbWrFk0adKEqlWrUrduXe0E4Fu3buHr64utrS0zZ84EICYmhgMHDtClSxdDhpwmPXoP4KTvEYYP6UvHrj2xtbPH98hBThw7TNv2nXF6OQQ9eeJYzp89zcGT//6V1u3dljRp0YriXiUxV6vxO3+Wfbu3U6JUGd7tlLuW4v6vLYt+JTY6CvcylbBxcCQi9DmXju4l2P8BLXp9iLmFJaFBAcwfO4QK9Zri+HIU5fbF09w6fwKvyjV1Hnvw4nkwv40aQOWGLWn/4RhtecveH7FiymgWT/qU6s3aERMVyfHta3Es7EqNFsmXVc+Jdi+eQVxMFEVLVcS6gBNRYc+46ruPZ08e0ui1W9j3rfiNxPg4nN280CQmcO34fp7cuU7rD0Zh6/jv5Y6I58EsGTuI8vVb0OqDUdryht0/YMP0Caz7eSylazcm+NE9zu/ZRMWGrXLtgnkAlSpVpqVPK2ZOn8azkBCKubmzeeN6/P0fM/G7H7T1vh43htOnTnLh8nVt2Xs9evLP2jUM+3gI/foPxMzMjOVLl+Dg6Ejf/rln8nlqtq5fRWREBM9ejrycOnaIkJd3f7Xt+B5W1jZ06TmQowd2M3XCKN7t2gsrK2t2bF5HQkICvQcN0+4rJDiIYf0608TnHT798t/5lF99OojS5StRuGgxnj8LYdeWf4iJjuKryTO0iVBukEPzkUwxymSmUqVK+Pn58eOPP7Jz505OnToFgLu7Ox9//DGjR4/WjsRYWFhw7tw5Q4abZpWr1WDOwhUsXvAbG9auIjwslMJFXBn00Sf06PPmX1bNW7Xl8sXzHNq/m7jYWAoVLkKPPgPpM2DwG5/plBuUr9OYcwe2c3rPJqIjwjG3yE9hz5I06/GBNkmxyG9NyWp1uON3hguHd6HRJOJQqChN33ufum27oUrDLyrP8lXpNeZH9q9ZzL7Vi8inVlOmujfNe759nZqconTtRvgd2sGF/VuIedmXBT1K0KDbIEpU+3dV34LuJTi76x+u+u5DpTLBpXhpuo6ZqnOr9pt4VanDu8O/wXfDCvatmIOljR213+lOnfYpr+yam3w/5SfmzJrOls2bCA8Po2Sp0sycM4/qNWq+sZ2VlTWLlizn56mTWfD7XDQaDTVq1mbUmLE4OOT+lWk3rF5OUOC/iwoeP7yP44f3AdCoRRusrG2wd3Bkysw/WDLvVzavXUlCQgKly1Xks3Hfv/W5TABepcpy9OAengU9Jb+VFZWr16HnwI9wKfLmeWA5TU4dXckMlZIHl5INCEt+l4XImL23Ag0dQq4RGZ++OVMidX1rpHy5TKTf3afpW01bpK5skbQ9Jy6zqn+3/+2V3uDMeONf5uS/jHJkRgghhBAZkwcHZow3mYmJiWHdunWcPXuWsLAwNBqNznaVSsWiRYsMFJ0QQghhnPLiZSajTGbu379PkyZNuHfvHvb29oSFheHg4EBoaCiJiYk4OTkle/aJEEIIIfLmyIxRTt8eNWoUYWFhHD9+nBs3bqAoCqtXryYiIoKpU6diaWnJzp07DR2mEEIIYXTy4q3ZRpnM7Nu3j48//phatWppb5dTFAW1Ws2oUaNo1qwZI0aMMGyQQgghhBFSqTL3yomMMpmJiorCw8MDAFtbW1QqFWFh/y5kVrduXY4cOWKg6IQQQghhTIwymXFzc+PRo6RnxJiZmVG0aFGOH/93xccrV65gkcoD24QQQoi8LC9eZjLKCcBNmzZl48aNTJgwAYD+/fszZcoUnj9/jkajYfny5fTt29fAUQohhBDGJ4fmI5lilMnMl19+yalTp4iNjUWtVjNu3Dj8/f1Zu3Ytpqam9OzZk19++cXQYQohhBBGJ6eOrmSGUSYzbm5uuLn9+/wWCwsLFi5cyMKFCw0YlRBCCGH88mAuY5xzZgYOHMiJEydS3X7y5EkGDsz9D14TQgghxNvpNZm5c+cOV69ezfR+lixZwu3bt1PdfvfuXZYuXZrp4wghhBC5TV6cAJyhZGbmzJl0795dp2zAgAGULFmSChUqUKNGDZ4+faqXAFPi7++PpWXueIqxEEIIoU95MZnJ0JyZhQsX0qTJv0/V3LlzJ0uXLmXIkCFUrFiRr7/+mkmTJjFnzpw073Pjxo1s3LhR+37+/Pns2bMnWb3Q0FD27NlDzZo1MxK6EEIIkavl0HwkUzKUzNy/f5+yZctq3//99994enoyd+5cAAICAli+fHm69nnlyhXWrFkDJGWVJ06c4MyZMzp1VCoVVlZWNGzYkGnTpmUkdCGEECJXy6mjK5mRoWRGURSd97t27aJ9+/ba9x4eHgQEBKRrn2PHjmXs2LEAmJiYsGjRInr27JmR8IQQQgiRh2RozkypUqVYv349kHSJyd/fn9atW2u3P3r0CHt7+wwHpdFoJJERQgghMiAvPpspQyMzX3zxBT179qRAgQJERkZStmxZfHx8tNv37dtHlSpV9BUj165dY82aNTx58oTSpUszYMAAbG1t9bZ/IYQQIreQy0xp1L17dxwdHdm2bRv29vZ8/PHHmJkl7erZs2c4ODjQp0+fdO1z9uzZzJw5k2PHjuHk5KQt37x5M127diUuLk5bNmvWLI4fP65TTwghhBA5d3QlMzK8AnCLFi1o0aJFsnIHBwf++eefdO9v06ZNeHl56SQoCQkJDBo0CFNTUxYvXkyNGjXYunUrX331FT/88AO//vprRsMXQgghciWTPJjNGM0KwFeuXKFOnTo6Zfv37ycoKIjPPvuMfv36Ub58eUaPHk23bt3Ytm2bgSIVQgghjJfMmUmFp6dnuq/BqVSqN67i+18hISEUK1ZMp2zv3r2oVCo6duyoU+7t7Z2h0R8hhBBC6Nfjx48ZM2YM27dvJyoqihIlSmivpkDSHdATJkxgwYIFhIaG4u3tzdy5cylZsqTeYkhTMtOoUaMsn1BUqFChZLdzHz58mPz581O5cmWdcnNzc8zNzbM0HiGEECInys4JwM+fP8fb25smTZqwfft2nJ2duXnzJgUKFNDW+emnn5g5cyZLly7F09OT8ePH4+Pjw5UrV7CwsNBLHGlKZpYsWaKXg71JjRo1WLp0KcOHD8fGxobLly9z8uRJ2rdvr51c/Mq1a9dwdXXN8piEEEKInMYkGy8VTZ06lWLFirF48WJtmaenp/b/FUVh+vTpfP3119r16JYtW0ahQoXYsGFDskcjZZTRzJmZMGEC9+/fp2TJkjRr1gxvb29UKpV2Ib3XrV+/nnr16hkgSiGEEMK4ZeezmTZt2kSNGjXo2rUrBQsWpGrVqixYsEC7/e7duwQEBNC8eXNtmZ2dHbVr18bX11dv55zhZCY8PJwff/wRHx8fqlatysmTJ4GkW7OnTZvGrVu30rW/ihUrsm/fPqpXr46/vz916tRh27ZtVK9eXafegQMHyJ8/P127ds1o6EIIIUSuldkJwLGxsYSHh+u8YmNjUzzWnTt3tPNfdu7cyUcffcQnn3zC0qVLAbTTRwoVKqTTLqWpJZk6Z+W/zyZIg0ePHtGoUSMePnxIyZIluXbtGrt376Zp06YAlC5dmlatWjFjxgy9BapPMQmGjkCI5EZtvmroEIRI5ud3yr69kkgTiwwvhpI+bX8/man2NZ9sY9KkSTplEyZMYOLEicnqmpubU6NGDY4dO6Yt++STTzh16hS+vr4cO3YMb29v/P39KVy4sLZOt27dUKlUrF69OlOxvpKhkZlRo0bx4sULzp8/z8GDB5M9q6lDhw4pPvFaX6Kjo3nw4EGW7V8IIYTIqVSZ/G/s2LGEhYXpvFKa8gFQuHBhypUrp1NWtmxZ7Xe0i4sLAIGBgTp1AgMDtdv0IUPJzK5du/jkk08oV65citfXihcvzsOHD9O933379tGwYUOcnZ0pW7YskyZNIioqKlm9f/75R2eCkRBCCCGSmKgy91Kr1dja2uq81Gp1isfy9vbm+vXrOmU3btzA3d0dSJoM7OLiwt69e7Xbw8PDOXHiBHXr1tXfOWekUXR0NM7Ozqluf/HiRbr3eebMGXx8fLh+/TqNGjXC0dGRb7/9lipVqnD1qgy/CyGEEGmRnROAP/vsM44fP87kyZO5desWK1euZP78+QwdOlQby4gRI/j+++/ZtGkTfn5+9O3blyJFitChQwe9nXOGkply5cpx6NChVLdv2LCBqlWrpmufEyZMwNPTk6tXr7J27VqOHDnCgQMHiI6OxtvbmyNHjmQkVCGEECJPyc4VgGvWrMn69ev566+/qFChAt999x3Tp0+nV69e2jqjR49m+PDhDB48mJo1axIREcGOHTv0tsYMZPDZTCNGjKBfv35UqlRJe1eRRqPh1q1bTJo0CV9fX9atW5eufZ49e5bPP/8cBwcHbVmDBg04e/Ysbdu2pWXLlvz111/a+9SFEEIIkVx2P5upXbt2tGvXLtXtKpWKb7/9lm+//TbLYshQMtO7d2/u37/P119/zVdffQVAq1atUBQFExMTJk+enO7ho4iICOzs7JKVOzs7c+DAATp27EjXrl2ZO3euXrM5IYQQQuRsGb5R7KuvvqJPnz6sW7eOW7duodFo8PLyolOnThQvXjzd+/Py8uLkyZMMGjQo2bb8+fOzZcsW+vTpw+DBg/U6aUgIIYTITXLqwyIzI1N3vbu5ufHZZ5/pJZAWLVqwaNEipk+fTv78+ZNtz5cvH3/99ReOjo7MnTs3W589IYQQQuQUefH7MVPJzKVLl9i2bRv37t0Dkm7BatWqFRUrVkz3vt5//30UReH69eupTh5WqVTMmTOHkiVLcuHChcyELoQQQuRKeTCXydgKwLGxsQwZMoTly5dr58lA0iRglUpFr169WLhwodE+2VpWABbGSFYAFsZIVgDWn+xaAfi9pecy1X51v/TdjWwMMnRr9pgxY1i2bBkfffQRV69eJSYmhtjYWK5evcqHH37IihUrGD16tL5jFUIIIYRIJkN54ooVK+jTpw+zZ8/WKS9dujRz5swhPDycFStWMH36dH3EKIQQQog0yoNXmTI2MhMfH0+dOnVS3V6vXj0SEuRajhBCCJHdsnMFYGORoWTGx8eHnTt3prp9x44dtGzZMsNBCSGEECJjMvtsppwoTZeZnj17pvP+u+++o1u3bnTq1ImhQ4dSokQJAG7evMmcOXO4f/++3h7rLYQQQoi0y6mjK5mRpmTGyckpWecoioKfnx8bN25MVg5Qvnx5udQkhBBCZLM8mMukLZn55ptvsj3Te/DgAZMnT2b//v0EBQWxYcMGGjZsSHBwMN9++y0DBgxI98MshRBCCJH7pCmZmThxYhaHoevKlSs0aNAAjUZD7dq1uXXrlnaUx8nJiSNHjhAZGcmiRYuyNS4hhBDC2MllJiMxevRo7O3tOX78OCqVioIFC+psb9u2rczJEUIIIVKQUyfxZkamkpmjR49y9uxZwsLC0Gg0OttUKhXjx4/P0H4PHTrEN998g7OzMyEhIcm2u7m58fjx4wztWwghhMjNZGQmjZ49e0bbtm05efIkiqKgUqm0E39f/X9mkhmNRpPiwyZfCQoKQq1WZ2jfQgghRG6W91KZDK4zM2rUKC5evMjKlSu5c+cOiqKwc+dObty4wYcffkiVKlXw9/fPcFDVqlVj69atKW5LSEhg1apVb1y0TwghhBB5R4ZGZrZt28aQIUN47733tJeBTExMKFGiBHPmzKFTp06MGDGCv/76K0NBjR07lnbt2vHRRx/RvXt3AAIDA9mzZw+TJ0/m6tWryR6lkFPExcUxZ9YMtm7eSHh4OCVLlWbYJyOoW8/7rW0DAwP539TJ+B47ikajoWat2owaMw7XYsWyIXLjI32ZeS1LOfJO+YL4h8cwZe9dbbmJCnxKO1HLzQ47CzPCYhI4fj+U3TdC0KTh0bQ2alPeLV+Q8i7WqM1MCHwRx67rwZz3f5GFZ2NYWdGXtd3s6F29SKrbl556zOlH4fo6BaOTmZ/x1w0ZNIDjvsd4r0cvxn39TRZFazxM5DJT2oSGhlK+fHkArK2tAYiIiNBub9myJePGjctwUK1bt2bJkiV8+umnzJ8/H4DevXujKAq2trYsW7aMhg0bZnj/hjR+3Jfs2b2TXn364ubmwaaN6xn20WAW/LGUatVrpNouKjKSQQP6EhHxgvc/GIKZWT5WLFvCwP69+XvdBuztC2TjWRgH6cvMsbcwo2VpJ2ITNMm29atRlCpFbTh+P4wHz6PxdLCkXbmCFLDMx6rzAW/cr4WZCSMaemCjNuXg7eeExyRQ1dWG92u7suTUY87kwi/frOrLW8FRLD2dfH5gEy8HitpZcD0oUm/nYIwy+jP+uj27d3Hh/PmsDdTI5MFcJmPJTJEiRQgISPohVKvVFCxYkAsXLtC+fXsAHj9+nOkJSH369KFTp07s2rWLW7duodFo8PLywsfHBxsbm0zt21D8Ll5kx/atjPxiNP0GvA/AO+070Ll9O6ZP+x/L/lyVatvVq1by4P49/ly1hgoVKwFQv0EDOnd4h2VLFvPJiJHZcg7GQvoy8zpULMi9Z9GYqMBKbaotd7O3oJqrLduvBbHtajAAR++FEhGXSJMSDhy68xz/8NhU9+vtaU9Ba3NmHb7PjeAoAI7cfc7njTzoWLEQ5x+Hk5iG0Z2cJKv6MiQqnpCoeJ2yfCYqulV24UZQJC9iE7PmhIxAZn7GX4mNjeWXn39kwPuD+G32zKwO2WjkxQnAGZoz07BhQ3bv3q19/9577/HTTz/xww8/8N133zF9+nSaNGmS6eCsrKzo2LEjo0aNYsyYMXTp0iXHJjIAe3btwNTUlM5d39OWqdVqOnbuwoXz5wh48iTVtrt37aR8hYraL18Az+Je1Kpdl107tmdp3MZI+jJzvBwtqVLElnV+gcm3OSVNvj/7nxGUM4/CMVGpqOZq+5Z95+dFbII2kQFQgLOPw7GzMKOEk1XmT8CIZGVfpqRCYWss85nm6stLkLmf8VcWL1qAolG0yVBeoVJl7pUTZWhkZuTIkezevZvY2FjUajUTJ07k8uXL2ruXGjZsyMyZGc+CHzx48MbtKpUKCwuLFB+zYMyuXbuKu7uH9tLcK6++VK9du4pL4cLJ2mk0Gm7euE6Hjp2TbatQsSK+x44QGRmBlZV1su25lfRlxqmArpVd8L0fypMURgXMXi5SEf+f4ZP4xKRLKMXsLd64fzMTVbK2r+/PrUDuuTyS1X2ZkhrF7IhL0HAhF88/goz/jL/yxN+fxYsWMPG7yVhYpL+fczKZM5NGFStWpGLFitr3BQoUYM+ePYSGhmJqaprp0RMPD480JSkWFhY0aNCA8ePH4+2dvglhhhAUFISTs3Oycicn55fbn6bYLiwslLi4uBTbOr8sC3r6FCvP3PsF/F/SlxlX37MABSzzMftKyn80PI2IA8DT0VLnEoeXY9Iog73Fm39tBEbEUbqgFQUszXge/e/z2bwcLQGwe0v7nCSr+/K/8uczoWxBK/yeRKQ4Pyc3yejP+Cu//PwjZcqUpXWbtlkSnzAuev2tYm9vD8DKlStZsmQJu3btytB+Fi1axMyZM3n48CG9evXSeSr3ypUrcXd3Z8CAAdy6dYsVK1bQtGlTduzYoZdLW1kpNjYGc3PzZOWv1syJjYlJuV1M0l98KbU1f9k2Jib16+65kfRlxuQ3N6VtOSd2Xg8mIi7l+RaXAyIIiYyjY4VCxCcqPHgejYeDJe3KOZOoUchn+uar0773QqnvWYCBtVz5xy+QF7EJVC1qS6UiSX/kvK19TpEdfflfVYraks/UhFMPw/RxCkYtoz/jACdPHGfP7l2s+OvvLIvPmOXBgZmseZzB3bt32bt3b4bb+/v7ExcXx61bt7QJ0isTJ06kfv36REdHM336dMaPH0/16tWZNGlSislMbGwssbG6X06Kqdogi+6p1RbExcUlK38VnzqVoVC1RVKsKbWNe9nWwiJvLSIofZkx7co6Exmn4eDtZ6nWSdAozPN9yMBargyq7QokXRbZeOlpqnfsvM4/PJalpx7zXhUXRjbyACAsJoF1FwPpXrVwrhlRyI6+/K8axWyJjEvgSmDE2yvncBn9GU9ISGDqlB9o9057nXlxeUlOmn6hL0Y53jtv3jxGjhyZLJEBcHBwYNCgQcyYMYNRo0bh6OjIwIED+fnnn1Pc15QpU5g0aZJO2VfjJ/D1NxOzIPI3c3Z25mlg8kmCwcFBL7cXTLYNwM7OHnNzc4KDgpJtC3pZ5lww5ba5lfRl+jlb5cPb0551FwOxs8ynLTczNcFUpcIhfz5i4hOJitcQ8CKOyXvv4GJjTn5zUwLCY4lPVOhUqRC3XpvYm5rz/i/we/KConYWmKjgYWgMJZ2TJv4GRST/gsppsrMvXylgaYaXY36O3QtN01o/OV1Gf8Y3b9rAvbt3GT9hEo8fP9LZFhUZyePHj3BwcMTS0lL/QRuJ3DH2mT5GmcyEhIQQFZX6D3lkZKT2iwfAxcVF+ziF/xo7diwjR+reaquYGuYv79JlynDq5AkiIiJ0JrX5XbwAQJkyZVNsZ2JiQsmSpbh8+VKybX5+F3EtVixXT1hNifRl+tlZ5sNEpaJrZRe6Vk6+fZJPCfbfesY/r92VE/Di38SjXCErTFSqNE/eTVTgQei/lwJKv0xmruWCyb/Z3ZcA1V3tMFGpOJ0HLjFBxn/GA548ISEhnn69eyTbtnnTBjZv2sCvM+fQtFnzrAncCMjIjJGoWbMmM2bM4N1339WZaAxw8eJFZs2aRa1atbRlV69exdXVNcV9qdXJLynFJKRYNcs1b9mKpYv/YN2a1dpbBePi4ti4/h8qVqqsnZn/xN+fmJhoPIt7vdbWhxm//sLlS36Ur5DUJ/fu3uHUieP07T8w+0/GwKQv0+9JeCwLjj9MVt62nDMWZqasuxhAUGR8Ci2T1jZpW9aZsOh4nUXv8pmqcLDMR0RcIpGpzBuBf0cy/J68yBUjM4boyxrFbHkWFc/tkGj9nYgRy+jPeKvWbSidQqLz2SdDadCwEZ26dKNipbx5+Sk3M8pkZtasWTRp0oSqVatSt25d7QTgW7du4evri62trfbW75iYGA4cOECXLl0MGXKaVKpUmZY+rZg5fRrPQkIo5ubO5o3r8fd/zMTvftDW+3rcGE6fOsmFy9e1Ze/16Mk/a9cw7OMh9Os/EDMzM5YvXYKDo2Ou/gJOjfRl+kXGJXLxSfK5Fo29HAB0tg2oWZSwmAQCXsRiYWZCHXd7nKzyMc/3oc48D/cClnzawJ1tV4PYfi1YWz6uWXHOPw7nWXQ8jvnNaVDcnqi4RFa/ZcXbnCI7+xKgsI2aonYW7LquW56bZfRn3LO4l84fL68rUtQ1V4/IvGKS9wZm0p7MVEpHJvv06ZtvmUvLsfz8/Pjxxx/ZuXMnp06dAsDd3Z2PP/6Y0aNHa0diLCwsOHfuXKaOl52+n/ITc2ZNZ8vmTYSHh1GyVGlmzplH9Ro139jOysqaRUuW8/PUySz4fS4ajYYaNWszasxYHBwcsil64yJ9mXUehEZTx90eb0974hMVbockLav/OCxtd3r5h8VQ290eG7UpkXGJnH30gm1Xg1K96yc3y2xfQtKoDJDrF8r7r4z+jOd1eTGZUSmpTTb5j8aNG6f7Otz+/fszFFRWM9RlJiHeZNTmq4YOQYhkfn4n5bkpIv2ya4mlzzdff3ulN/jlndJ6iiT7pLlrDxw4kIVhCCGEEEIf8uLIjFHOmYGkuTDr1q3j7NmzhIWFodHorsegUqlYtGiRgaITQgghjFMevJnJOJOZ+/fv06RJE+7du4e9vT1hYWE4ODgQGhpKYmIiTk5OyZ7XIYQQQoi8ySjX1hk1ahRhYWEcP36cGzduoCgKq1evJiIigqlTp2JpacnOnTsNHaYQQghhdExUqky9ciKjTGb27dvHxx9/TK1atTAxSQpRURTUajWjRo2iWbNmjBgxwrBBCiGEEEbIJJOvnMgo446KisLDwwMAW1tbVCoVYWH/rnpZt25djhw5YqDohBBCCOOlUmXulRMZZTLj5ubGo0dJz9QwMzOjaNGiHD9+XLv9ypUrWKTykDEhhBAiL8uLl5kyNQH48ePHHDp0iKdPn9K5c2dcXV1JTEwkLCwMOzs7TE1NM7Tfpk2bsnHjRiZMmABA//79mTJlCs+fP0ej0bB8+XL69u2bmdCFEEIIkUtkKJlRFIXPP/+c2bNnk5CQgEqlomLFiri6uhIREYGHhwfffvtthue1fPnll5w6dYrY2FjUajXjxo3D39+ftWvXYmpqSs+ePfnll18ytG8hhBAiN8uhgyuZkqHLTD///DMzZszgiy++YPfu3TpPrLazs6NTp06sW7cuw0G5ubnRuXNn7QMiLSwsWLhwIc+fPyc4OJglS5ZgZ2eX4f0LIYQQuZWJKnOvnChDycyCBQvo27cvkydPpkqVKsm2V6pUiRs3bmQ4qIEDB3LixIlUt588eZKBA3PvAwGFEEKIjMqLc2YylMw8fPiQevXqpbrdysqK8PCMPxBtyZIl3L59O9Xtd+/eZenSpRnevxBCCJFb5cW7mTI0Z6ZgwYI8fPgw1e1nzpzBzc0tw0G9jb+/P5aWllm2fyGEECKnyqmXijIjQ8lMp06dmDdvHv3799fOXXn1RO1du3axZMkSRo8ena59bty4kY0bN2rfz58/nz179iSrFxoayp49e6hZUx4BL4QQQogMJjOTJk1i//79VKlShQYNGqBSqZg6dSrjx4/H19eXqlWrMm7cuHTt88qVK6xZswZISoxOnDjBmTNndOqoVCqsrKxo2LAh06ZNy0joQgghRK6mIu8NzWRozoydnR3Hjx9n9OjRPH78GAsLCw4ePEhoaCgTJkzg8OHD5M+fP137HDt2LC9evODFixcoisKiRYu071+9wsPDefLkCVu2bKFUqVIZCV0IIYTI1fLi3UwZXjTP0tKSr7/+mq+//lqf8QCg0Wj0vk8hhBAiL8ipCUlmZGoF4Oxy7do11qxZw5MnTyhdujQDBgzA1tbW0GEJIYQQRkeVU29JyoQMJTNpWeNFpVKxaNGiNO9z9uzZzJw5k2PHjuHk5KQt37x5M127diUuLk5bNmvWLI4fP65TTwghhBB5U4aSmX379iXL/BITE3ny5AmJiYk4OztjZWWVrn1u2rQJLy8vnQQlISGBQYMGYWpqyuLFi6lRowZbt27lq6++4ocffuDXX3/NSPhCCCFEriWXmdLo3r17KZbHx8fz+++/M336dHbv3p2ufV65coUPPvhAp2z//v0EBQUxbtw4+vXrB0D58uW5cOEC27Ztk2RGCCGE+I88eJUpY3czpSZfvnwMGzaMli1bMmzYsHS1DQkJoVixYjple/fuRaVS0bFjR51yb29vHjx4kOl4hRBCiNzGUI8z+PHHH1GpVDoPmY6JiWHo0KE4OjpibW1N586dCQwM1MNZ6tJrMvNK5cqVOXToULraFCpUiICAAJ2yV7d4V65cWafc3Nwcc3PzTMcphBBC5DaGuDX71KlT/P7771SqVEmn/LPPPmPz5s2sWbOGgwcP4u/vT6dOnfRwlrqyJJnZvXt3uteZqVGjBkuXLuXFixcAXL58mZMnT+Lj44OZme7VsGvXruHq6qq3eIUQQojcIrufzRQREUGvXr1YsGABBQoU0JaHhYWxaNEipk2bRtOmTalevTqLFy/m2LFjHD9+XI9nnME5M99++22K5aGhoRw6dIizZ8/y5ZdfpmufEyZMoGbNmpQsWZLy5ctz5swZVCoVY8eOTVZ3/fr1NG3aNCOhCyGEEOINYmNjiY2N1SlTq9Wo1eoU6w8dOpS2bdvSvHlzvv/+e235mTNniI+Pp3nz5tqyMmXK4Obmhq+vL3Xq1NFbzBlKZiZOnJhieYECBfDy8mLevHnJJvO+TcWKFdm3bx8//PADd+7coU6dOnzxxRdUr15dp96BAwfInz8/Xbt2zUjoQhitn98pa+gQco0CNdM3Z0+k7ud3Zhs6BJFOJpl8nMGUKVOYNGmSTtmECRNS/O5ftWoVZ8+e5dSpU8m2BQQEYG5ujr29vU55StNKMitDyUxWrdBbr149tm7d+sY6jRs3xs/PL0uOL4QQQuR0mb2baezYsYwcOVKnLKVRmYcPH/Lpp5+ye/duLCwsMnfQTEr3nJno6GhGjhzJ5s2bsyIeFEVJNrwVGxvL7t27Wbt2LXfu3MmS4wohhBC5QWYnAKvVamxtbXVeKSUzZ86c4enTp1SrVg0zMzPMzMw4ePAgM2fOxMzMjEKFChEXF0doaKhOu8DAQFxcXPR7zultYGlpye+//54lt1Z9/fXX2NnZaZ+M/fjxY27evEmpUqVo1aoV3bp1o1SpUnz22Wd6P7YQQgiRG2TXrdnNmjXDz8+P8+fPa181atSgV69e2v/Ply8fe/fu1ba5fv06Dx48oG7duno95wxdZqpevTqXLl3SayDLli1j8uTJtGvXDnd3d5YsWcKAAQMAaNWqFV26dCE6OpqFCxcyc+ZMqlWrRp8+ffQagxBCCCHSxsbGhgoVKuiUWVlZ4ejoqC1///33GTlyJA4ODtja2jJ8+HDq1q2r18m/kMFkZvr06bRp04YKFSrQv3//ZLdOZ8ScOXNo374969evB5Ju1R4wYAC9evXi999/19Z79913qV27NgsWLJBkRgghhPgPY1oB+Ndff8XExITOnTsTGxuLj48Pv/32m96Pk+Ys5NChQ5QtWxZnZ2f69euHiYkJQ4YM4ZNPPqFo0aJYWlrq1FepVFy4cCHNgdy4cUP7yAJImugL0K5du2R1O3fuzOTJk9O8byGEECKvyMwqvpl14MABnfcWFhbMmTOHOXPmZOlx05zMNGnShBUrVtCjRw8cHR1xcnKidOnSegskMTGRfPnyad9bW1sD4OzsnKyug4MDMTExeju2EEIIkVsY08hMdklzMqMoCoqiAMkzL30oUqSIzvOWrKysmDJlCiVLlkxW98GDBykmOUIIIURelyVL+xu5zE920ZMaNWpw9OhR7XsLCwvGjBmTYt0dO3ZQrVq17ApNCCGEyDFUeXBoJl3JTFZ20M8//0xwcPBb6wUHB+Pt7Z3iXBohhBBC5D0q5dW1o7cwMTFJVzKjUqlISEjIcGBZKcY4wxJC6Ik8zkB/np+Sxxnoi0U2XQtZdvphptr3rVFMT5Fkn3R1bfPmzSlVqlRWxSKEEEKITDLk3UyGkq5kpl+/fvTs2TOrYhFCCCFEJuW9VMaIJgALIYQQIvPy4MBMnryDSwghhBC5iIzMCCGEELmI3Jr9BhqNJivjEEIIIYQe5MVLLkZ7zg8ePODDDz+kdOnSODg4cOjQISBpnZlPPvmEc+fOGThCIYQQwvioVKpMvXIio7zMdOXKFRo0aIBGo6F27drcunVLu2aNk5MTR44cITIykkWLFhk4UiGEEMK45Mx0JHOMMpkZPXo09vb2HD9+HJVKRcGCBXW2t23bltWrVxsoOiGEEMJ45dTRlcwwystMhw4d4qOPPsLZ2TnFfxQ3NzceP35sgMiEEEIIYWyMcmRGo9GQP3/+VLcHBQWhVquzMSIhhBAiZzDKUYosZpTnXK1aNbZu3ZritoSEBFatWkWdOnWyOSohhBDC+OXFCcBGmcyMHTuWHTt28NFHH3Hp0iUAAgMD2bNnDy1btuTq1at8+eWXBo4yY+Li4vj1l59p3rg+tapVolf3rvgeO5qmtoGBgYwa+Sn169SgXq1qfDrsIx49zNwDxXIy6Uv9kb58MytLc77+sA0bZ3/M4wNTiT43m97v1E6xbmnPQmyc/TFBR3/h8YGpLPquL04FrJPVU6lUjOzXnKtbJvL8+K+cXD2Wbq2qpzkmO2tLZn/dgwf7phB87Bd2zP+EKmVcM3yOxkg+lxmjyuQrJ0rzU7Oz2/Lly/n0008JCwtDURRUKhWKomBra8vcuXPp0aNHhvdtyKdmj/liJHt276RXn764uXmwaeN6Ll/yY8EfS6lWvUaq7aIiI3mvayciIl7Qt98AzMzysWLZEhQU/l63AXv7Atl4FsZB+lJ/cltf6vup2W6FHbi+7VsePHnG3UfBNKpZig++Wc6KzSd06hUtaI/vqjGEv4jht1UHsLJUM6JvMx4GPKdB75+JT0jU1v12+LuMGtiSReuOcubyfdo1rkSbhhXo++Vi1uw888Z4VCoVe/8YQcVSrvy6dA8hoZEM7tYA10L21Ov1E7cfBOnt3A351Ozc9rnMrqdmb/QLyFT79hVd9BRJ9jHaZAYgMjKSXbt2cevWLTQaDV5eXvj4+GBjY5Op/RoqmfG7eJHePboy8ovR9BvwPgCxsbF0bt8OB0dHlv25KtW2ixctYPq0//HnqjVUqFgJgLt3btO5wzv0HziIT0aMzJZzMBbSl/qTG/tS38mMeT4zCthaEhjygmrl3Dj65+gUk5npY7vR5506VOn0HQ8DngPQpHZpts0bztDv/uKPf5JGFYo423F16yT+WHeUz6au0bbfvWgEHkUcKd32GzSa1H81d25RlRU/vU/PUQtZv+c8AE4FrLm44Rt2Hb1C/3FL9HbuhkpmcuPnUpKZrGOUl5lesbKyomPHjowaNYoxY8bQpUuXTCcyhrRn1w5MTU3p3PU9bZlaraZj5y5cOH+OgCdPUm27e9dOyleoqP3BBPAs7kWt2nXZtWN7lsZtjKQv9Uf68u3i4hMIDHnx1nodmlVh++FL2kQGYP+J69y4F0jnllW1Ze0aV8I8nxm/rzms037BmsO4uhSgTiXPNx6nY/OqBASHs2HvBW1Z8PMI1u06S7vGFTHPZ5T3dqSLfC4zzgRVpl45kVEmMw8ePHjj6+HDhwQFBWHEg0opunbtKu7uHlhb614/f/UDd+3a1RTbaTQabt64TvnyFZJtq1CxIg8fPiAyMkL/ARsx6Uv9kb7UjyLOdhRytOXslQfJtp2+dJ/KpYtp31cu40pEVCzX7uj+BX3q0v2X24vxJpXLuHL+2sNkvwNPX76PlaWaku4FU2mZc8jnMuNUqsy9ciKjTN89PDzSNKPawsKCBg0aMH78eLy9vbMhsswJCgrCydk5WbmTk/PL7U9TbBcWFkpcXFyKbZ1flgU9fYqVZ/JJhrmV9KX+SF/qh4uzHQBPgsOSbQsIDsPR3grzfGbExSfg4mTH05DwFOsBFH65r1SP5WTHkbO33tj+8i3/dJ+DMZHPZcapcujoSmYYZTKzaNEiZs6cycOHD+nVqxclSpQA4ObNm6xcuRJ3d3cGDBjArVu3WLFiBU2bNmXHjh00adLEwJG/WWxsDObm5snKX62ZExsTk3K7mFiAFNuav2wb87JOXiF9qT/Sl/phqc4HQFxc8kl5MS/LLNX5iItPwFKdj9j4FOrF/lvvbceKTek4aWyfE8jnMuNy6uhKZhhlMuPv709cXBy3bt3C3t5eZ9vEiROpX78+0dHRTJ8+nfHjx1O9enUmTZqUYjITGxtLbKzuB1cxVRtk0T212oK4uLhk5a/iU1tYpNzOIinWlNrGvWxrYZG3FhGUvtQf6Uv9iI6NB8DcPPmvVYuXZa/qRMfGo05hXouFWrfem46lTuk4aWyfE8jnUqSHUc6ZmTdvHoMGDUqWyAA4ODgwaNAgZs9OmmHv6OjIwIEDOXMm5VsZp0yZgp2dnc7r56lTsjL8VDk7OxMclPyWyeDgoJfbU77ObWdnj7m5eYptg16WORfM+dfI00P6Un+kL/UjIOjlJR6n5JeIXJzsCAmNJO7laExAcBiFnGxTrAfwJCj5pSqdYwWHaetmpH1OIJ/LjJMJwEYiJCSEqKioVLdHRkZqP5QALi4uqU4GHjt2LGFhYTqvUWPG6j3mtChdpgz3798jIkJ38pnfxaQ7EsqUKZtiOxMTE0qWLMXly5eSbfPzu4hrsWJYWeXe678pkb7UH+lL/fAPCuPps6Rbt/+rRgV3Ll5/pH1/8fpjrCzVlCmuewtsrQoeL7c/4k0uXn9ElTLFks0trFnBg8joWG7eT3k+SU4in8uMy4sTgI0ymalZsyYzZszAz88v2baLFy8ya9YsatWqpS27evUqrq4pr3ypVquxtbXVeRnquU7NW7YiMTGRdWv+feJ3XFwcG9f/Q8VKlXEpXBiAJ/7+3L1z+z9tfbh8yY/Ll/7tk3t373DqxHFatGyVPSdgRKQv9Uf6Un827D1P6wYVcC1kry1rXKsUpTwK8c+ec9qyLQcuEhefwJCuDXTaD+pan8eBz/G9cEdb5uJkSymPQpiZ/fvrev2e87g42dKhWWVtmaO9FZ1aVGXboUvaEaCcTD6XGZcXkxmjXDTv4sWLNGnShLCwMOrWraudAHzr1i18fX2xtbXlwIEDVKpUiZiYGOrWrUvbtm35/vvv07R/Q64APGrkp+zbu4feffpRzM2dzRvXc+mSH/MXLaF6jZoAvN+/D6dPneTC5evadpGREbzXuSORUZH06z8QMzMzli9dQqImkb/XbcTBwcFQp2Qw0pf6k9v6Ut+L5gF8+F5D7GwsKexsx5BuDdmw9zznryUtjz931UHCI2JwLWSP719fEvYimjl/HcAqv5rP+jbjcWAo9Xv/rJNk/PBpe0b2b8HCtUc4c+U+7zSuTJuGFeg/dgmrd5zW1ps/qTd93q1D6Tbf8ODJMwBMTFTsWzyScl6F+XXZHkKeJ60AXMylAPV7/6zXkRlDrgCc2z6X2bVo3u6rwZlq36Ksk54iyT5GmcxA0iTgH3/8kZ07d3L/ftLaC+7u7vj4+DB69OhUR2LSwpDJTGxsLHNmTWfr5s2Eh4dRslRphg7/FO/6//6FltIPJ0BgQAA/T52M77GjaDQaatSszagxY3Fzd8/u0zAK0pf6k9v6MiuSmWtbJ+FexDHFba8nGmWLuzD1887Uq1qcuPhEdhy+xJfT1vP0me6ieyqVis8HtGBQZ29cnGy59SCI//2xi1XbT+vUSymZAbC3sWTyZx15p3ElLC3ycebyA8b+uj7FdW4yw5DJTG77XGZXMrP3WuaSmWZlJJnJEQyZzAghsl5WJDN5lSGTmdxGkpmsY5S3ZgshhBAiY2TRPCMSExPDunXrOHv2LGFhYWg0Gp3tKpWKRYsWGSg6IYQQwjjl1Em8mWGUycz9+/dp0qQJ9+7dw97enrCwMBwcHAgNDSUxMREnJ6dkz+sQQgghRN4cmTHKW7NHjRpFWFgYx48f58aNGyiKwurVq4mIiGDq1KlYWlqyc+dOQ4cphBBCGB0TVeZeOZFRJjP79u3j448/platWpiYJIWoKApqtZpRo0bRrFkzRowYYdgghRBCCGEUjDKZiYqKwsPDAwBbW1tUKhVhYf8uz123bl2OHDlioOiEEEII46XK5H85kVEmM25ubjx6lLSct5mZGUWLFuX48ePa7VeuXMEilYeMCSGEEHlZXlwB2CgnADdt2pSNGzcyYcIEAPr378+UKVN4/vw5Go2G5cuX07dvXwNHKYQQQhifHJqPZIpRJjNffvklp06dIjY2FrVazbhx4/D392ft2rWYmprSs2dPfvnlF0OHKYQQQhgdk5w6vJIJsgKwECLXkRWA9UdWANaf7FoB+Pit0Ey1r1PCXi9xZCejnDMzcOBATpw4ker2kydPMnDgwGyMSAghhBDGyiiTmSVLlnD79u1Ut9+9e5elS5dmY0RCCCFEDqHK5CsHMso5M2/j7++PpaWlocMQQgghjE5Ovb06M4wmmdm4cSMbN27Uvp8/fz579uxJVi80NJQ9e/ZQs2bN7AxPCCGEyBHy4Pxf40lmrly5wpo1a4Ckh0ieOHGCM2fO6NRRqVRYWVnRsGFDpk2bZogwhRBCCKOWB3MZ47ybycTEhBUrVtCzZ88s2b/czSRE7iZ3M+mP3M2kP9l1N9OpO2Fvr/QGNYvb6SmS7GM0IzOv02g0hg5BCCGEyJny4NCMUSYz/3Xt2jXWrFnDkydPKF26NAMGDMDW1tbQYQkhhBBGRyYAG9Ds2bOZOXMmx44dw8nJSVu+efNmunbtSlxcnLZs1qxZHD9+XKeeEEIIIfLmBGCjWWdm06ZNeHl56SQoCQkJDBo0CFNTUxYvXoyfnx8//vgj9+/f54cffjBgtEIIIYRxyoPLzBhPMnPlyhXq1KmjU7Z//36CgoL47LPP6NevH+XLl2f06NF069aNbdu2GShSIYQQwojlwWzGaJKZkJAQihUrplO2d+9eVCoVHTt21Cn39vbmwYMH2RmeEEIIIf5jypQp1KxZExsbGwoWLEiHDh24fv26Tp2YmBiGDh2Ko6Mj1tbWdO7cmcDAQL3GYTTJTKFChQgICNApO3z4MPnz56dy5co65ebm5pibm2dneEIIIUSOoMrkf+lx8OBBhg4dyvHjx9m9ezfx8fG0bNmSyMhIbZ3PPvuMzZs3s2bNGg4ePIi/vz+dOnXS6zkbzQTgGjVqsHTpUoYPH46NjQ2XL1/m5MmTtG/fHjMz3TCvXbuGq6urgSIVQgghjFd2TgDesWOHzvslS5ZQsGBBzpw5Q8OGDQkLC2PRokWsXLmSpk2bArB48WLKli3L8ePHk00vySijGZmZMGEC9+/fp2TJkjRr1gxvb29UKhVjx45NVnf9+vXUq1fPAFEKIYQQxi2zU2ZiY2MJDw/XecXGxqbp2GFhSQv2OTg4AHDmzBni4+Np3ry5tk6ZMmVwc3PD19c38yf7ktGMzFSsWJF9+/bxww8/cOfOHerUqcMXX3xB9erVdeodOHCA/Pnz07VrVwNFKkTWSNQY3WLcOZasWqs/BeqONHQIuUb0qWx6DE8mR2amTJnCpEmTdMomTJjAxIkT39hOo9EwYsQIvL29qVChAgABAQGYm5tjb2+vUzelqSWZYTTJDEC9evXYunXrG+s0btwYPz+/bIpICCGEyFvGjh3LyJG6SaxarX5ru6FDh3Lp0iWOHDmSVaGlyqiSGSGEEEJkTmZXAFar1WlKXl43bNgwtmzZwqFDh3TmtLq4uBAXF0doaKjO6ExgYCAuLi6ZivN1RjNnRgghhBCZp1Jl7pUeiqIwbNgw1q9fz759+/D09NTZXr16dfLly8fevXu1ZdevX+fBgwfUrVtXH6cLyMiMEEIIkatk57p3Q4cOZeXKlWzcuBEbGxvtPBg7OzssLS2xs7Pj/fffZ+TIkTg4OGBra8vw4cOpW7eu3u5kAklmhBBCiNwlG7OZuXPnAknzWV+3ePFi+vfvD8Cvv/6KiYkJnTt3JjY2Fh8fH3777Te9xqFSFCXP3UIRk2DoCIRITu5m0h9Tkxy6JrsRkruZ9Ce77ma6/Djy7ZXeoHxRKz1Fkn1kzowQQgghcjS5zCSEEELkItm5ArCxkGRGCCGEyEXyYC4jyYwQQgiRq+TBbEaSGSGEECIXyeyieTmRTAAWQgghRI4mIzNCCCFELiITgIUQQgiRo+XBXEaSGSGEECJXyYPZjCQzQgghRC6SFycASzIjhBBC5CIyZ8bA3n333XTVV6lUbNy4MYuiEUIIIUROYFTJzJYtW7CwsMDFxYW0PP9SlRfTTyGEEOIN8uI3o1ElM0WLFuXx48c4OTnRs2dPunfvjouLi6HDEkIIIXKOPJjNGNWieQ8fPmT//v1UrVqV7777jmLFitG8eXMWL17MixcvDB2eEEIIYfRUmfwvJzKqZAagUaNG/P777wQEBLB27VocHR0ZNmwYBQsWpFOnTqxdu5bY2FhDhymEEEIYJZUqc6+cSKWkZXKKgUVERPDPP/8wb948Tpw4wcSJExk/fnyG9xeToMfg0ikuLo45s2awdfNGwsPDKVmqNMM+GUHdet5vbRsYGMj/pk7G99hRNBoNNWvVZtSYcbgWK5YNkRuf3NaXiRrD/ChGRUWydPEiLvld5LKfH+HhYUz8bjLvduj01rYfDOjDmdOnUtxmZmbGyXOX9B1umpiaGO43cm77XBaoOzLLj1G1jCsTP25DnYoeqFRwwu8+X83azMUb/jr1VCoV73esw6DO9fBydSIyOo7z1x/x46LdHL94743HsFDn49dRnahZwQ3XQvaYmphw51EIyzaf4Pc1R0lI1GThGSaJPjUty48BcDc4JlPtPZ0s9BRJ9jH6ZCY2NpYtW7awcuVKtm3bhomJCfPmzaNPnz4Z3qchk5kxX4xkz+6d9OrTFzc3DzZtXM/lS34s+GMp1arXSLVdVGQk73XtRETEC/r2G4CZWT5WLFuCgsLf6zZgb18gG8/COOS2vjRUMuP/+BHtWjXHpXARXF1dOX3qZJqTmePHjhISEqJTFh0dxeTvJlK/QSNm/vZ7VoX9RoZMZnLb5zKrk5kqpYuyb+EnPAp8zqL1vpioTBjcpR4F7PLToP90bt4P0tb9ccS7fNqrMSu3nebo+TvYW1vyfqe6FHMpQNP3Z3H6yoPUz8M2Pxumf8CRc7e5/+QZGo1CnUoe9GhdnTW7ztN//IosPU/IvmTmXiaTGY8cmMwY1QTgVzQaDbt37+avv/5iw4YNREVF0bx5cxYsWEDHjh2xsrIydIgZ4nfxIju2b2XkF6PpN+B9AN5p34HO7dsxfdr/WPbnqlTbrl61kgf37/HnqjVUqFgJgPoNGtC5wzssW7KYT0Zk/V9PxkT6Un+cnAuya/9hnJycuXLZj97du6a5bZ0URhu2bt4EQOu27fQWY04hn8v0++bD1kTHxtP4/Zk8C4sC4K/tp7m4bizfftyWHmOWAGBqasIHnevxz57zvD9hpbb9ur0XuLbxa7q3rvbGZOZ5eBSNBs7QKVv4jy/hETF89F4DxkzfSGBILpmbmUMvFWWGUc2ZOXbsGMOGDaNw4cK0bduWW7duMXnyZPz9/dm2bRu9e/fOsYkMwJ5dOzA1NaVz1/e0ZWq1mo6du3Dh/DkCnjxJte3uXTspX6Gi9pccgGdxL2rVrsuuHduzNG5jJH2pP+bm5jg5Oettfzu2bcHSMj+NmzTT2z5zCvlcpp93leLsP3lDm8gABIS84PDZ27SuXw4rS3MA8pmZkt/CnKfPInTaBz2LIDFRQ3RsfIaOf//JMwDsrC0zeAbGJy9OADaqkZn69etjaWlJmzZt6NGjBx4eHgA8ePCABw9SzrirVauWjRFmzrVrV3F398Da2lqn/NUvr2vXruJSuHCydhqNhps3rtOhY+dk2ypUrIjvsSNERkZgZWWdbHtuJX1pnJ4/e8aJ48do4dMay/z5DR1OtpPPZfqpzc1STESiY+JRm5tR3qswJy/dJyY2npN+9+ndriYn/O5x9Nwd7GwsGft+C56/iGLRet80HS+fmSm2VhZYWuSjWtlifNq7Cff9n3H7UbC+T81gcuok3swwqmQGIDo6mnXr1vHPP/+8sZ6iKKhUKhITE7MpsswLCgrCyTn5X8Cv/ioOCnqaYruwsFDi4uJSbOv8sizo6VOsPHPfL7rUSF8ap507tpGQkECbtu8YOhSDkM9l+t24/5RaFd0xMVGheTlvLJ+ZKTUruAFQxNlOW3fAN3+yfHIfFn/XW1t251EwTQfN4t7jZ2k6XocmFVk2ua/2/ZkrDxjy7WoSs2ECcHbJg7mMcSUzixcvNnQIWSo2NgZzc/Nk5Wq1Oml7TMqTtmJjkm5FT6mt+cu2MTF563Z16UvjtGPbFgo4OFC7bj1Dh2IQ8rlMv/lrjzJrbFfmjX+Pacv2Y2Ki4suBLXBxsgXAwiKftm5EVAxX7wRw0u8++0/dpJCjDV/0a8rfPw+k+QezCQmLfOvxDp65RZuhc7G3tqRxzZJUKlVEeylL5FxGlcz069dP7/uMjY1Nti6NYqrW/nLJTmq1BXFxccnKX8Wntkh5BrnaIinWlNrGvWxrYZH952NI0pfG59HDh1y8cJ73evTCzMyofrVkG/lcpt/Cf3xxLWTPZ32a0KddLSBptGTasv18+X4LIqOSzt/U1IStcz7i8JlbjPzfem37fSdvcHb1aD7r04SvZ2956/GePovg6cmbAKzfd5FR/ZuxZfYQKnaekmsmAOfFy0xGNQE4K0yZMgU7Ozud189TpxgkFmdnZ4KDgpKVBwcHvdxeMMV2dnb2mJubp9g26GWZc8GU2+ZW0pfGZ8e2pC+S1nn0EhPI5zKjJs7djrvPBJoNmkWN7j9Tv990TF7eXn/zQdL5169anAolCrPl0GWdtrcfBnPt7lPqVvbI0LHX77uIjZUF7RpWyNQ5GBdVJl85j1ElM+XKlWPr1q3a91FRUXz88cfcuHEjWd0///wTU1PTt+5z7NixhIWF6bxGjRmr17jTqnSZMty/f4+ICN3Z+H4XLwBQpkzZFNuZmJhQsmQpLl9OvgCZn99FXIsVy5UTA99E+tL4bN+2BddiblSqXMXQoRiMfC4zLvRFNMcu3OXy7aQ7vprWKsWjwOdcv5c0z6iQgw2QNELzX/nMTDBLw/dBSizVSZex7Kxz3toqqcmLKwAbVTJz7do1wsLCtO+jo6P5/fffefToUYb3qVarsbW11XkZ4hITQPOWrUhMTGTdmtXasri4ODau/4eKlSpr73J44u/P3Tu3/9PWh8uX/Lh8yU9bdu/uHU6dOE6Llq2y5wSMiPRl9gsKesrdO3eIj09+58m1q1e4e+c2rdvkvbVlXiefS/3o0qIKNcq7MfuvQ7xa1/XVCE3XllV06lYpXZRS7gU5f/3f7wlLdT5KuRfE0e7fpTxe///XDWhfG4AzVx/q8xQMKu+NyxjZnJmUGPkCxelSqVJlWvq0Yub0aTwLCaGYmzubN67H3/8xE7/7QVvv63FjOH3qJBcuX9eWvdejJ/+sXcOwj4fQr/9AzMzMWL50CQ6OjvTtP9AQp2NQ0pf6tWrlCiJevNDebXPo4H6eBgYC8F7P3tjY2DB7+jQ2b9rAlh17KFLUVaf99q2bgby5UN7r5HOZft5VizNuUEv2Hr9OSFgUtSq607ddTXYeu8rsVYe19c5de8Se49fp064WtlYW7Dl+HRcnWz7q1oDo2HhmrzqkrVujvBu7fh/K9/N38sOCnQD0aFOdQZ3qsvngJe4+DsEmv5rmdcrQvE5pthy6xMHTt7L93IX+GH0yk9t8P+Un5syazpbNmwgPD6NkqdLMnDOP6jVqvrGdlZU1i5Ys5+epk1nw+1w0Gg01atZm1JixODg4ZFP0xkX6Un+WL/2DJ/7/Pgdn357d7NuzG4A27d7BxsYm1bYajYad27dRpmw5PDyLZ3msxk4+l+nj/zSMxEQNI/o0wSa/mnv+z5g0bzsz/jyY7Hbprl/8wYjejenasiot6pYhLj6Ro+fv8O287TqPPUjJsfN3qFPRg24tq1LQwYaERA037j9l9LQN/Pb3kaw8xWyXUy8VZYZRPZvJxMSEFStW0LNnTwBCQkJwdnZmz549NG3aVKfun3/+Sd++fTO0zowhn80kRGoM9Wym3MiQz2bKbbLjQZN5RXY9mykgLGOrIb/iYpfv7ZWMjNGNzKhSSClTKhNCCCFECvLgV6bRjcwUK1YMO7ukFR8TExO5evUqnp6eyZ7JFBYWxqNHj2RkRuQaMjKjPzIyoz8yMqM/2TUyExieuZGZQrYyMpMpDRs2TDYKUzCVtRUcHR0pXlyuzwshhBCvy4sXM4wqmTlw4EC66hvRoJIQQgghDMSo1plJq7i4OObPn0+ZMmUMHYoQQghhVFSZ/C8nMqqRGUhKVDZt2sTt27cpUKAA7dq1o0iRIkDSisCzZ89m+vTpBAQE4OXlZeBohRBCCCOTM/ORTDGqZMbf35/GjRtz+/Zt7SUkS0tLNm3ahLm5OT179uTx48fUqlWLWbNm0alTJwNHLIQQQhiXPJjLGFcy89VXX3H37l1Gjx5NgwYNuHv3Lt9++y2DBw8mODiY8uXLs2LFCho1amToUIUQQgijJBOADWz37t0MGDCAKVP+faq1i4sLXbt2pW3btmzcuBETkxw5zUcIIYQQWcSokpnAwEDq1KmjU/bq/cCBAyWREUIIId4ip07izQyjSmYSExOxsNB9DPur968W0hNCCCFE6uQykxG4d+8eZ8+e1b4PCwsD4ObNm9jb2yerX61atewKTQghhBBGyOgeZ5DSc5gURUlW/qpMHmcgcgt5nIH+yOMM9EceZ6A/2fU4g9Do9H8vvs7e0lRPkWQfoxqZWbx4saFDEEIIIXI0mTNjYP369TN0CEIIIYTIYYwqmRFCCCFE5sgEYCGEEELkaHkwl5FkRgghhMhV8mA2I8mMEEIIkYvkxQnAsqSuEEIIIXI0GZkRQgghcpG8OAFYRmaEEEKIXESVyVd6zZkzBw8PDywsLKhduzYnT57M/EmkkyQzQgghRG6SjdnM6tWrGTlyJBMmTODs2bNUrlwZHx8fnj59qqeTSRtJZoQQQohcRJXJ/9Jj2rRpfPDBBwwYMIBy5coxb9488ufPzx9//JFFZ5cySWaEEEKIXESlytwrreLi4jhz5gzNmzfXlpmYmNC8eXN8fX2z4MxSJxOAhRBCCKEVGxtLbGysTplarUatVuuUBQcHk5iYSKFChXTKCxUqxLVr17I8ztflyWTGIgecdWxsLFOmTGHs2LHJPkAifXJOXxr/LQg5py+NX07py+x60nNm5JS+zC6Z/Y6b+P0UJk2apFM2YcIEJk6cmLkdZyGVoiiKoYMQyYWHh2NnZ0dYWBi2traGDidHk77UH+lL/ZG+1B/pS/1K68hMXFwc+fPnZ+3atXTo0EFb3q9fP0JDQ9m4cWN2hAvInBkhhBBCvEatVmNra6vzSmnEy9zcnOrVq7N3715tmUajYe/evdStWzc7Q86bl5mEEEIIkXkjR46kX79+1KhRg1q1ajF9+nQiIyMZMGBAtsYhyYwQQgghMuS9994jKCiIb775hoCAAKpUqcKOHTuSTQrOapLMGCm1Ws2ECRNkMpseSF/qj/Sl/khf6o/0pWENGzaMYcOGGTQGmQAshBBCiBxNJgALIYQQIkeTZEYIIYQQOZokMzmIh4cH7dq1M3QYQgghhFGRZEYP/v77b1QqFevXr0+2rXLlyqhUKvbv359sm5ubG/Xq1cuOEI2Gn58fXbp0wd3dHQsLC4oWLUqLFi2YNWuWTr3JkyezYcMGwwSZTj/88APvvvsuhQoVQqVSZdsqmbmtL69du8bo0aOpUqUKNjY2FC5cmLZt23L69OksP3Zu60t/f3969+5N6dKlsbGxwd7enlq1arF06VKMcZrkkiVLUKlU2peZmRlFixalf//+PH78WKdu48aNdeq+/ipTpkyK+zxy5EiyYyqKQrFixVCpVPJHYi4gdzPpQf369QE4cuQIHTt21JaHh4dz6dIlzMzMOHr0KE2aNNFue/jwIQ8fPqR79+7ZHq+hHDt2jCZNmuDm5sYHH3yAi4sLDx8+5Pjx48yYMYPhw4dr606ePJkuXbrorCpprL7++mtcXFyoWrUqO3fuzJZj5sa+XLhwIYsWLaJz5858/PHHhIWF8fvvv1OnTh127Nih8zA7fcqNfRkcHMyjR4/o0qULbm5uxMfHs3v3bvr378/169eZPHmyoUNM0bfffounpycxMTEcP36cJUuWcOTIES5duoSFhYW2nqurK1OmTEnW3s7OLlmZhYUFK1eu1P6efuXgwYM8evRI7oDKLRShF56enkqtWrV0ynbs2KGoVCqlR48eio+Pj862lStXKoCycePGNB/D3d1dadu2rV7iNYQ2bdoozs7OyvPnz5NtCwwM1HlvZWWl9OvXL3sCy6S7d+8qiqIoQUFBCqBMmDAhy4+ZG/vy9OnTyosXL3TKgoODFWdnZ8Xb2zvLjpsb+zI17dq1U6ysrJSEhARDh6Jj8eLFCqCcOnVKp3zMmDEKoKxevVpb1qhRI6V8+fJp3menTp0UJycnJT4+Xmf7Bx98oFSvXj3H/14VSeQyk57Ur1+fc+fOER0drS07evQo5cuXp3Xr1hw/fhyNRqOzTaVS4e3tzeLFi2natCkFCxZErVZTrlw55s6dm6bjLl26FDMzM0aNGqUtO3HiBK1atcLOzo78+fPTqFEjjh49qr+TzaDbt29Tvnx57O3tk20rWLCg9v9VKhWRkZEsXbpUO0zcv39/AO7fv8/HH39M6dKlsbS0xNHRka5du3Lv3r1k+7x48SKNGjXC0tISV1dXvv/+exYvXoxKpUpWf/v27TRo0AArKytsbGxo27Ytly9fTtN5eXh4pLEH9Cc39mX16tWxtrbWKXN0dKRBgwZcvXr1re0zKjf2ZWo8PDyIiooiLi4uw/vITg0aNACS/o0yqkePHoSEhLB7925tWVxcHGvXrqVnz56ZjlEYB7nMpCf169dn+fLlnDhxgsaNGwNJCUu9evWoV68eYWFhXLp0iUqVKmm3lSlTBkdHR+bOnUv58uV59913MTMzY/PmzXz88cdoNBqGDh2a6jHnz5/Phx9+yLhx4/j+++8B2LdvH61bt6Z69epMmDABExMTbbJ0+PBhatWqleV9kRp3d3d8fX25dOkSFSpUSLXe8uXLGTRoELVq1WLw4MEAeHl5AXDq1CmOHTtG9+7dcXV15d69e8ydO5fGjRtz5coV8ufPD8Djx49p0qQJKpWKsWPHYmVlxcKFC1McUl6+fDn9+vXDx8eHqVOnEhUVxdy5c7UJqiGSlbfJS30ZEBCAk5NTutulVW7uy+joaCIjI4mIiODgwYMsXryYunXrYmlpmYGeyn6vkrsCBQrolCcmJhIcHJysvqWlJVZWVjplHh4e1K1bl7/++ovWrVsDSUliWFgY3bt3Z+bMmVkTvMhehh4ayi0uX76sAMp3332nKIqixMfHK1ZWVsrSpUsVRVGUQoUKKXPmzFEURVHCw8MVU1NT5YMPPlAURVGioqKS7c/Hx0cpXry4Ttnrw6EzZsxQVCqV9niKoigajUYpWbKk4uPjo2g0Gm15VFSU4unpqbRo0UKPZ5x+u3btUkxNTRVTU1Olbt26yujRo5WdO3cqcXFxyeqmNpyfUl/5+voqgLJs2TJt2fDhwxWVSqWcO3dOWxYSEqI4ODgogPbS0IsXLxR7e3vtv8UrAQEBip2dXbLyN8nOy0y5vS9fOXTokKJSqZTx48enu21a5ea+nDJligJoX82aNVMePHiQprbZ6dUloT179ihBQUHKw4cPlbVr1yrOzs6KWq1WHj58qK3bqFEjnXN6/TVkyJBk+zx16pQye/ZsxcbGRvvv1LVrV6VJkyaKouT8y/ciiSQzeqLRaBRHR0ft3JjTp08rgHLz5k1FURSlY8eOSs+ePRVFUZSdO3cqgDbReV1oaKgSFBSkTJ48WQGU0NBQ7bZXP3RTp05VAOWnn37SaXv27FntfoOCgnRegwYNUtRqtZKYmJhVXZAmJ0+eVDp27Kjkz59f+wvI2dk52dyhtMxNiIuLU4KDg5WgoCDF3t5eGTFihHZbyZIllXr16iVrM3z4cJ0vjX/++UcBlH379iXrs5YtWyolSpRI87llZzKjKLm7LxUlab6Kq6urUrx48WRzafQtt/blvXv3lN27dysrV65UevbsqTRr1ky5fv16mtpmp1eJx39fHh4eys6dO3XqNmrUSPHw8FB2796d7HX16tVk+zx16pTy9OlTxczMTPn777+V8PBwxdLSUlmwYIGiKJLM5BZymUlPVCoV9erV49ChQ2g0Go4ePUrBggUpUaIEAPXq1WP27NkA2vkrr2bXHz16lAkTJuDr60tUVJTOfsPCwnRm6B88eJCtW7cyZswYnXkyADdv3gSgX79+qcYZFhaWbMg2O9WsWZN//vmHuLg4Lly4wPr16/n111/p0qUL58+fp1y5cm9sHx0dzZQpU1i8eDGPHz/Wuc00LCxM+//3799P8RH0r/49XnnVZ02bNk3xeLa2tmk+t+yWm/syMjKSdu3a8eLFC44cOZJsLo2+5da+dHd3x93dHUiaOzJ48GCaN2/O9evXjfJS05w5cyhVqhRhYWH88ccfHDp0KMVLcFZWVum6u83Z2ZnmzZuzcuVKoqKiSExMpEuXLvoMXRiYJDN6VL9+fTZv3oyfn592vswr9erVY9SoUTx+/JgjR45QpEgRihcvzu3bt2nWrBllypRh2rRpFCtWDHNzc7Zt28avv/6qM2kYoHz58oSGhrJ8+XKGDBmCp6endturuj///DNVqlRJMcas/lJIK3Nzc2rWrEnNmjUpVaoUAwYMYM2aNUyYMOGN7YYPH87ixYsZMWIEdevWxc7ODpVKRffu3ZP1VVq8arN8+XJcXFySbTczM/4fkdzWl3FxcXTq1ImLFy+yc+fON85j0bfc1pf/1aVLFxYsWMChQ4fw8fHJ0D6yUq1atahRowYAHTp0oH79+vTs2ZPr169n+ndXz549+eCDDwgICKB169YpTvgWOZfx/6bOQV5fb+bo0aOMGDFCu6169eqo1WoOHDjAiRMnaNOmDQCbN28mNjaWTZs24ebmpq2f0iJ7AE5OTqxdu5b69evTrFkzbWIE/05GtLW1zbI1ObLCq19eT5480ZapVKoU665du5Z+/frxyy+/aMtiYmIIDQ3Vqefu7s6tW7eStf9v2as+K1iwYI7qs9Tk9L7UaDT07duXvXv38vfff9OoUaMM7UcfcnpfpuTV3ZavjxYZK1NTU6ZMmUKTJk2YPXs2X375Zab217FjR4YMGcLx48dZvXq1nqIUxkJuzdajGjVqYGFhwZ9//snjx491RmbUajXVqlVjzpw5REZGahMfU1NTgGTD0osXL071OK6uruzZs4fo6GhatGhBSEgIkJQweXl58b///Y+IiIhk7YKCgvRynhm1f//+FFcf3bZtGwClS5fWlllZWSX7IoCk/vrvPmbNmkViYqJOmY+PD76+vpw/f15b9uzZM/78889k9WxtbZk8eTLx8fHJjmfoPktNbu3L4cOHs3r1an777Tc6der01vr6kBv7MrXtixYtQqVSUa1atTe2NxaNGzemVq1aTJ8+nZiYmEzty9ramrlz5zJx4kTeeecdPUUojIWMzOjRqyHqw4cPo1arqV69us72evXqaf9ye5XMtGzZEnNzc9555x2GDBlCREQECxYsoGDBgjp/Ef5XiRIl2LVrF40bN8bHx4d9+/Zha2vLwoULad26NeXLl2fAgAEULVqUx48fs3//fmxtbdm8eXPWdcBbDB8+nKioKDp27EiZMmWIi4vj2LFjrF69Gg8PDwYMGKCtW716dfbs2cO0adMoUqQInp6e1K5dm3bt2rF8+XLs7OwoV64cvr6+7NmzB0dHR51jjR49mhUrVtCiRQuGDx+uvQXWzc2NZ8+eaf/CtrW1Ze7cufTp04dq1arRvXt3nJ2defDgAVu3bsXb21s71yk1y5cv5/79+9r5TocOHdLeKt+nTx/tnAV9yo19OX36dH777Tfq1q1L/vz5WbFihc72jh07JrvtVh9yY1/+8MMPHD16lFatWmn3vW7dOk6dOsXw4cOTzdExZqNGjaJr164sWbKEDz/8EEj6g++/n49Xevfuneq+3jSfUORwhpp5nFuNHTtWAVK8Y+HVHQo2NjY6K3Bu2rRJqVSpkmJhYaF4eHgoU6dOVf744w+duxsUJeVZ9ydOnFBsbGyUhg0bam87PHfunNKpUyfF0dFRUavViru7u9KtWzdl7969WXPSabR9+3Zl4MCBSpkyZRRra2vF3NxcKVGihDJ8+PBkK61eu3ZNadiwoWJpaakA2jtInj9/rgwYMEBxcnJSrK2tFR8fH+XatWuKu7t7srtMzp07pzRo0EBRq9WKq6urMmXKFGXmzJkKoAQEBOjU3b9/v+Lj46PY2dkpFhYWipeXl9K/f3/l9OnTbz2vN90qun///sx0WapyY1/269cv1X7878+CPuXGvty1a5fSrl07pUiRIkq+fPkUGxsbxdvbW1m8eLHOsg3GIrUVgBVFURITExUvLy/Fy8tLSUhIeOPP2+tfaW/a5+vkbqbcQaUoRvjUMSGyyIgRI/j999+JiIjQXuITGSN9qT/Sl0JkjsyZEbnW64+WAAgJCWH58uXUr19fvjDSSfpSf6QvhdA/mTMjcq26devSuHFjypYtS2BgIIsWLSI8PJzx48cbOrQcR/pSf6QvhdA/SWZErtWmTRvWrl3L/PnztXdwLFq0iIYNGxo6tBxH+lJ/pC+F0D+ZMyOEEEKIHE3mzAghhBAiR5NkRgghhBA5miQzQgghhMjRJJkRQgghRI4myYwQQgghcjRJZoTIATw8POjfv7/2/YEDB1CpVBw4cMBgMf3Xf2PMDo0bN6ZChQp63achzkMIkTmSzAjxFkuWLEGlUmlfFhYWlCpVimHDhhEYGGjo8NJl27ZtTJw40aAxqFQqhg0bZtAYhBC5iyyaJ0Qaffvtt3h6ehITE8ORI0eYO3cu27Zt49KlS+TPnz9bY2nYsCHR0dGYm5unq922bduYM2eOwRMaIYTQJ0lmhEij1q1bU6NGDQAGDRqEo6Mj06ZNY+PGjfTo0SPFNpGRkVhZWek9FhMTEywsLPS+XyGEyInkMpMQGdS0aVMA7t69C0D//v2xtrbm9u3btGnTBhsbG3r16gWARqNh+vTplC9fHgsLCwoVKsSQIUN4/vy5zj4VReH777/H1dWV/Pnz06RJEy5fvpzs2KnNmTlx4gRt2rShQIECWFlZUalSJWbMmKGNb86cOQA6l81e0XeMmbFx40batm1LkSJFUKvVeHl58d1335GYmJhi/TNnzlCvXj0sLS3x9PRk3rx5yerExsYyYcIESpQogVqtplixYowePZrY2Ng3xhIfH8+kSZMoWbIkFhYWODo6Ur9+fXbv3q2XcxVCZJ6MzAiRQbdv3wbA0dFRW5aQkICPjw/169fnf//7n/by05AhQ1iyZAkDBgzgk08+4e7du8yePZtz585x9OhR8uXLB8A333zD999/T5s2bWjTpg1nz56lZcuWxMXFvTWe3bt3065dOwoXLsynn36Ki4sLV69eZcuWLXz66acMGTIEf39/du/ezfLly5O1z44Y02rJkiVYW1szcuRIrK2t2bdvH9988w3h4eH8/PPPOnWfP39OmzZt6NatGz169ODvv//mo48+wtzcnIEDBwJJidq7777LkSNHGDx4MGXLlsXPz49ff/2VGzdusGHDhlRjmThxIlOmTGHQoEHUqlWL8PBwTp8+zdmzZ2nRooXezlkIkQmKEOKNFi9erADKnj17lKCgIOXhw4fKqlWrFEdHR8XS0lJ59OiRoiiK0q9fPwVQvvzyS532hw8fVgDlzz//1CnfsWOHTvnTp08Vc3NzpW3btopGo9HWGzdunAIo/fr105bt379fAZT9+/criqIoCQkJiqenp+Lu7q48f/5c5ziv72vo0KFKSj/2WRFjagBl6NChb6wTFRWVrGzIkCFK/vz5lZiYGG1Zo0aNFED55ZdftGWxsbFKlSpVlIIFCypxcXGKoijK8uXLFRMTE+Xw4cM6+5w3b54CKEePHtWWubu765xH5cqVlbZt2771vIQQhiOXmYRIo+bNm+Ps7EyxYsXo3r071tbWrF+/nqJFi+rU++ijj3Ter1mzBjs7O1q0aEFwcLD2Vb16daytrdm/fz8Ae/bsIS4ujuHDh+tc/hkxYsRbYzt37hx3795lxIgR2Nvb62x7fV+pyY4Y08PS0lL7/y9evCA4OJgGDRoQFRXFtWvXdOqamZkxZMgQ7Xtzc3OGDBnC06dPOXPmjPb8ypYtS5kyZXTO79WlwlfnlxJ7e3suX77MzZs39XmKQgg9kstMQqTRnDlzKFWqFGZmZhQqVIjSpUtjYqL794CZmRmurq46ZTdv3iQsLIyCBQumuN+nT58CcP/+fQBKliyps93Z2ZkCBQq8MbZXl7wyuuZKdsSYHpcvX+brr79m3759hIeH62wLCwvTeV+kSJFkk6xLlSoFwL1796hTpw43b97k6tWrODs7p3i8V+eXkm+//Zb27dtTqlQpKlSoQKtWrejTpw+VKlXKyKkJIbKAJDNCpFGtWrW0dzOlRq1WJ0twNBoNBQsW5M8//0yxTWpfsNnJmGIMDQ2lUaNG2Nra8u233+Ll5YWFhQVnz55lzJgxaDSadO9To9FQsWJFpk2bluL2YsWKpdq2YcOG3L59m40bN7Jr1y4WLlzIr7/+yrx58xg0aFC6YxFC6J8kM0JkMS8vL/bs2YO3t7fO5ZP/cnd3B5JGSYoXL64tDwoKSnZHUUrHALh06RLNmzdPtV5ql5yyI8a0OnDgACEhIfzzzz80bNhQW/7qrrH/8vf3T3YL/I0bN4Ck1Xwh6fwuXLhAs2bN0nTZ7b8cHBwYMGAAAwYMICIigoYNGzJx4kRJZoQwEjJnRogs1q1bNxITE/nuu++SbUtISCA0NBRImpOTL18+Zs2ahaIo2jrTp09/6zGqVauGp6cn06dP1+7vldf39eoL/791siPGtDI1NU0Wd1xcHL/99luK9RMSEvj999916v7+++84OztTvXp1IOn8Hj9+zIIFC5K1j46OJjIyMtV4QkJCdN5bW1tTokSJt97SLYTIPjIyI0QWa9SoEUOGDGHKlCmcP3+eli1bki9fPm7evMmaNWuYMWMGXbp0wdnZmS+++IIpU6bQrl072rRpw7lz59i+fTtOTk5vPIaJiQlz587lnXfeoUqVKgwYMIDChQtz7do1Ll++zM6dOwG0X+6ffPIJPj4+mJqa0r1792yJ8XWnT5/m+++/T1beuHFj6tWrR4ECBejXrx+ffPIJKpWK5cuX6yQ3rytSpAhTp07l3r17lCpVitWrV3P+/Hnmz5+vvZ28T58+/P3333z44Yfs378fb29vEhMTuXbtGn///Tc7d+5M9RJiuXLlaNy4MdWrV8fBwYHTp0+z9v/t3aGqwmAYh3GX9GMMNBi0WIWhZSCaXPE6vALr+lCDWZPX4A3YNWncNaxbxfE/yQXHTjrgeeH5wdL3wfa1Z7CXnU78kgH4T746SwUY8B7Nvt1uv+5bLpfyfb92/Xg8KooiOecUBIFGo5GSJFGe5+WeoiiUpql6vZ6cc4rjWFmWVcaFP0ez3y6XixaLhYIgkO/7Go/H2u/35frr9dJqtVK325XneZUx7b98xjqNRqP2Wq/XkqTr9arpdCrnnPr9vpIk0fl8rpx5Pp8rDEPd73fNZjO1Wi0NBgMdDofKfZ/Pp3a7ncIwVLPZVKfTURRFStNUj8ej3Pd5js1mo8lkona7LeechsOhttttOfYN4Ps8qeZ1BwAAwAC+mQEAAKYRMwAAwDRiBgAAmEbMAAAA04gZAABgGjEDAABMI2YAAIBpxAwAADCNmAEAAKYRMwAAwDRiBgAAmEbMAAAA04gZAABg2g+/Rb2tCLL6DgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Get predicted labels (argmax on probabilities)\n",
    "predicted_labels = np.argmax(all_outputs_filtered, axis=1)\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "# Step 2: Compute F1 score for each class\n",
    "f1_scores = f1_score(all_targets_filtered, predicted_labels, average=None, labels=range(len(class_labels)))\n",
    "for idx, label in enumerate(class_labels):\n",
    "    print(f\"F1 Score for {label}: {f1_scores[idx]:.3f}\")\n",
    "\n",
    "# Step 3: Create a confusion matrix and normalize it by row to get percentages\n",
    "conf_matrix = confusion_matrix(all_targets_filtered, predicted_labels, labels=range(len(class_labels)))\n",
    "conf_matrix_percent = conf_matrix / conf_matrix.sum(axis=1, keepdims=True) * 100\n",
    "\n",
    "# Plotting the confusion matrix with percentages\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    conf_matrix_percent,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_labels,\n",
    "    yticklabels=class_labels,\n",
    "    annot_kws={\"size\": fontsize},  # Font size for numbers inside the heatmap\n",
    "    cbar_kws={\"shrink\": 1},  # Adjust colorbar size\n",
    ")\n",
    "\n",
    "# Customizing axis labels and ticks\n",
    "plt.xlabel(\"Predicted Labels\", fontsize=fontsize)\n",
    "plt.ylabel(\"True Labels\", fontsize=fontsize)\n",
    "plt.xticks(fontsize=12, ha=\"center\")  # Font size for x-axis tick labels with rotation\n",
    "plt.yticks(fontsize=12)  # Font size for y-axis tick labels\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Disease Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_model_path = \"../sleepfm/checkpoints/model_diagnosis\"\n",
    "config = load_data(os.path.join(disease_model_path, \"config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"model_params\"][\"dropout\"] = 0.0\n",
    "model_params = config['model_params']\n",
    "model_class = getattr(sys.modules[__name__], config['model'])\n",
    "model = model_class(**model_params).to(device)\n",
    "model_name = type(model).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: DiagnosisFinetuneFullLSTMCOXPHWithDemo\n",
      "Trainable parameters: 0.91 million\n",
      "Number of layers: 15\n"
     ]
    }
   ],
   "source": [
    "model = nn.DataParallel(model)\n",
    "print(f\"Model initialized: {model_name}\")\n",
    "total_layers, total_params = count_parameters(model)\n",
    "print(f'Trainable parameters: {total_params / 1e6:.2f} million')\n",
    "print(f'Number of layers: {total_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(disease_model_path, \"best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisFinetuneFullCOXPHWithDemoDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 config,\n",
    "                 channel_groups,\n",
    "                 hdf5_paths=None,\n",
    "                 demo_labels_path=None,\n",
    "                 split=\"train\"):\n",
    "\n",
    "        self.config = config\n",
    "        self.channel_groups = channel_groups\n",
    "        self.max_channels = self.config[\"max_channels\"]\n",
    "\n",
    "        # --- Load demographic features ---\n",
    "        if not demo_labels_path:\n",
    "            demo_labels_path = config[\"demo_labels_path\"]\n",
    "\n",
    "        demo_labels_df = pd.read_csv(demo_labels_path)\n",
    "        demo_labels_df = demo_labels_df.set_index(\"Study ID\")\n",
    "        study_ids = set(demo_labels_df.index)\n",
    "\n",
    "        is_event_df = pd.read_csv(os.path.join(self.config[\"labels_path\"], \"is_event.csv\"))\n",
    "        event_time_df = pd.read_csv(os.path.join(self.config[\"labels_path\"], \"time_to_event.csv\"))\n",
    "\n",
    "        is_event_df = is_event_df.set_index('Study ID')\n",
    "        event_time_df = event_time_df.set_index('Study ID')\n",
    "\n",
    "        # --- Resolve HDF5 paths (explicit precedence) ---\n",
    "        if hdf5_paths:\n",
    "            # Use provided paths directly\n",
    "            hdf5_paths = [f for f in hdf5_paths if os.path.exists(f)]\n",
    "        else:\n",
    "            # Load from split file\n",
    "            split_paths = load_data(config[\"split_path\"])[split]\n",
    "            hdf5_paths = [f for f in split_paths if os.path.exists(f)]\n",
    "\n",
    "        # Filter by available demo labels\n",
    "        hdf5_paths = [\n",
    "            f for f in hdf5_paths\n",
    "            if os.path.basename(f).split(\".\")[0] in study_ids\n",
    "        ]\n",
    "\n",
    "        # Optional truncation\n",
    "        if config.get(\"max_files\"):\n",
    "            hdf5_paths = hdf5_paths[:config[\"max_files\"]]\n",
    "\n",
    "        labels_dict = {}\n",
    "        # Loop over each study_id\n",
    "        for study_id in tqdm.tqdm(study_ids):\n",
    "            # Extract the row as a whole for both dataframes (faster than iterating over columns)\n",
    "            is_event_row = list(is_event_df.loc[study_id].values)\n",
    "            event_time_row = list(event_time_df.loc[study_id].values)\n",
    "            demo_feats = list(demo_labels_df.loc[study_id].values)\n",
    "\n",
    "            # values = [[event_time, is_event] for is_event, event_time in zip(is_event_row, event_time_row)]\n",
    "            labels_dict[study_id] = {\n",
    "                \"is_event\": is_event_row,\n",
    "                \"event_time\": event_time_row, \n",
    "                \"demo_feats\": demo_feats\n",
    "            }\n",
    "\n",
    "        # --- Build index map ---\n",
    "        self.index_map = [\n",
    "            (path, labels_dict[os.path.basename(path).split(\".\")[0]])\n",
    "            for path in hdf5_paths\n",
    "        ]\n",
    "\n",
    "        print(f\"Number of files in {split} set: {len(hdf5_paths)}\")\n",
    "        print(f\"Number of files to be processed in {split} set: {len(self.index_map)}\")\n",
    "\n",
    "        self.total_len = len(self.index_map)\n",
    "        self.max_seq_len = config[\"model_params\"][\"max_seq_length\"]\n",
    "\n",
    "        if self.total_len == 0:\n",
    "            raise ValueError(f\"No valid HDF5 files found for split='{split}'.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hdf5_path, tte_event = self.index_map[idx]\n",
    "\n",
    "        event_time = tte_event[\"event_time\"]\n",
    "        is_event = tte_event[\"is_event\"]\n",
    "        demo_feats = tte_event[\"demo_feats\"]\n",
    "\n",
    "        x_data = []\n",
    "        with h5py.File(hdf5_path, 'r') as hf:\n",
    "            dset_names = []\n",
    "            for dset_name in hf.keys():\n",
    "                if isinstance(hf[dset_name], h5py.Dataset) and dset_name in self.config[\"modality_types\"]:\n",
    "                    dset_names.append(dset_name)\n",
    "            \n",
    "            random.shuffle(dset_names)\n",
    "            for dataset_name in dset_names:\n",
    "                x_data.append(hf[dataset_name][:])\n",
    "\n",
    "        if not x_data:\n",
    "            # Skip this data point if x_data is empty\n",
    "            return self.__getitem__((idx + 1) % self.total_len)\n",
    "\n",
    "        # Convert x_data list to a single numpy array\n",
    "        x_data = np.array(x_data)\n",
    "\n",
    "        # Convert x_data to tensor\n",
    "        x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "\n",
    "        event_time = torch.tensor(event_time, dtype=torch.float32)\n",
    "        is_event = torch.tensor(is_event) \n",
    "\n",
    "        demo_feats = torch.tensor(demo_feats, dtype=torch.float32)\n",
    "\n",
    "        return x_data, event_time, is_event, demo_feats, self.max_channels, self.max_seq_len, hdf5_path\n",
    "\n",
    "\n",
    "def diagnosis_finetune_full_coxph_with_demo_collate_fn(batch):\n",
    "    x_data, event_time, is_event, demo_feats, max_channels_list, max_seq_len_list, hdf5_path_list = zip(*batch)\n",
    "\n",
    "    num_channels = max(max_channels_list)\n",
    "\n",
    "    if max_seq_len_list[0] == None:\n",
    "        max_seq_len = max([item.size(1) for item in x_data])\n",
    "    else:\n",
    "        max_seq_len = max_seq_len_list[0]\n",
    "\n",
    "    padded_x_data = []\n",
    "    padded_mask = []\n",
    "    for item in x_data:\n",
    "        c, s, e = item.size()\n",
    "        c = min(c, num_channels)\n",
    "        s = min(s, max_seq_len)  # Ensure the sequence length doesn't exceed max_seq_len\n",
    "\n",
    "        # Create a padded tensor and a mask tensor\n",
    "        padded_item = torch.zeros((num_channels, max_seq_len, e))\n",
    "        mask = torch.ones((num_channels, max_seq_len))\n",
    "\n",
    "        # Copy the actual data to the padded tensor and set the mask for real data\n",
    "        padded_item[:c, :s, :e] = item[:c, :s, :e]\n",
    "        mask[:c, :s] = 0  # 0 for real data, 1 for padding\n",
    "\n",
    "        padded_x_data.append(padded_item)\n",
    "        padded_mask.append(mask)\n",
    "    \n",
    "    # Stack all tensors into a batch\n",
    "    x_data = torch.stack(padded_x_data)\n",
    "    event_time = torch.stack(event_time)\n",
    "    is_event = torch.stack(is_event)\n",
    "    demo_feats = torch.stack(demo_feats)\n",
    "    padded_mask = torch.stack(padded_mask)\n",
    "    \n",
    "    return x_data, event_time, is_event, demo_feats, padded_mask, hdf5_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(base_save_path, \"demo_diagnosis\")\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2003.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in test set: 1\n",
      "Number of files to be processed in test set: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hdf5_paths = [os.path.join(base_save_path, \"demo_emb/demo_psg.hdf5\")]\n",
    "demo_labels_path = os.path.join(base_save_path, \"demo_age_gender.csv\")\n",
    "config[\"labels_path\"] = base_save_path\n",
    "\n",
    "test_dataset = DiagnosisFinetuneFullCOXPHWithDemoDataset(config, channel_groups, split=\"test\", hdf5_paths=hdf5_paths, demo_labels_path=demo_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=1, collate_fn=diagnosis_finetune_full_coxph_with_demo_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]/home/groups/jamesz/rthapa84/anaconda3/envs/sleepfm_clinical/lib/python3.10/site-packages/torch/nn/modules/transformer.py:562: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n",
      "  return torch._transformer_encoder_layer_fwd(\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_event_times = []\n",
    "all_is_event = []\n",
    "all_outputs = []\n",
    "all_paths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for item in tqdm.tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        x_data, event_times, is_event, demo_feats, padded_matrix, hdf5_path_list = item\n",
    "        x_data, event_times, is_event, demo_feats, padded_matrix, hdf5_path_list = x_data.to(device), event_times.to(device), is_event.to(device), demo_feats.to(device), padded_matrix.to(device), list(hdf5_path_list)\n",
    "        outputs = model(x_data, padded_matrix, demo_feats)\n",
    "    \n",
    "        logits = outputs.cpu().numpy()\n",
    "        all_outputs.append(logits)\n",
    "        all_event_times.append(event_times.cpu().numpy())\n",
    "        all_is_event.append(is_event.cpu().numpy())\n",
    "        all_paths.append(hdf5_path_list)\n",
    "\n",
    "all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "all_event_times = np.concatenate(all_event_times, axis=0)\n",
    "all_is_event = np.concatenate(all_is_event, axis=0)\n",
    "all_paths = np.concatenate(all_paths)\n",
    "\n",
    "outputs_path = os.path.join(save_path, \"all_outputs.pickle\")\n",
    "event_times_path = os.path.join(save_path, \"all_event_times.pickle\")\n",
    "is_event_path = os.path.join(save_path, \"all_is_event.pickle\")\n",
    "file_paths = os.path.join(save_path, \"all_paths.pickle\")\n",
    "\n",
    "save_data(all_outputs, outputs_path)\n",
    "save_data(all_event_times, event_times_path)\n",
    "save_data(all_is_event, is_event_path)\n",
    "save_data(all_paths, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1065), (1, 1065), (1, 1065))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs.shape, all_event_times.shape, all_is_event.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you get the model outputs, which you can then use to look for specific disease diagnosis. Nope that the shape of the output above is 1065, meaning, this model gives logprobs for 1065 conditions. We provide information about each disease index and its corresponding phecode here `sleepfm/configs/label_mapping.csv`. You can map it as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"../sleepfm/configs/label_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[\"output\"] = all_outputs[0]\n",
    "labels_df[\"is_event\"] = all_is_event[0]\n",
    "labels_df[\"event_time\"] = all_event_times[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_idx</th>\n",
       "      <th>phecode</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>output</th>\n",
       "      <th>is_event</th>\n",
       "      <th>event_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Intestinal infection</td>\n",
       "      <td>1.839084</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Bacterial enteritis</td>\n",
       "      <td>2.606029</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Viral Enteritis</td>\n",
       "      <td>1.971437</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Septicemia</td>\n",
       "      <td>4.495075</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>38.3</td>\n",
       "      <td>Bacteremia</td>\n",
       "      <td>4.594680</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_idx phecode             phenotype    output  is_event  event_time\n",
       "0          0     8.0  Intestinal infection  1.839084         0      3845.0\n",
       "1          1     8.5   Bacterial enteritis  2.606029         0      3845.0\n",
       "2          2     8.6       Viral Enteritis  1.971437         0      3845.0\n",
       "3          3    38.0            Septicemia  4.495075         0      3845.0\n",
       "4          4    38.3            Bacteremia  4.594680         0      3845.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you get the output hazards from our model, and also your labels for is_event and event_times. Is_event is an indicator for if the event occured and event_time is the time to event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleepfm_clinical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
