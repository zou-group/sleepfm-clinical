{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Details\n",
    "\n",
    "\n",
    "Before running this notebook, please preprocess your PSG files using the scripts provided in `sleepfm/preprocessing`. Note that PSG recordings may contain different sets of channels across datasets. The predefined channel–modality mappings used in this project are specified in `sleepfm/configs/channel_groups.json`.\n",
    "\n",
    "Although we have attempted to make this mapping as comprehensive as possible, we strongly recommend reviewing the channels present in your specific PSG data. In consultation with domain experts, you should group any additional or dataset-specific channels into the appropriate modality categories and update `channel_groups.json` accordingly. This step is critical to ensure that all channels are correctly aligned with their intended modalities during preprocessing and downstream modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../sleepfm\")\n",
    "from preprocessing.preprocessing import EDFToHDF5Converter\n",
    "from models.dataset import SetTransformerDataset, collate_fn\n",
    "from models.models import SetTransformer, SleepEventLSTMClassifier, DiagnosisFinetuneFullLSTMCOXPHWithDemo\n",
    "import h5py\n",
    "from utils import load_config, load_data, save_data, count_parameters\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 0: Preprocessing EDF files\n",
    "\n",
    "Note: This is just a demo notebook that preprocesses a single, specific file. run `sleepfm/preprocessing/preprocessing.sh` with appropriate folders to generate multiple preprocessed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_save_path = \"demo_data\"\n",
    "os.makedirs(base_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 22:53:59.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.preprocessing\u001b[0m:\u001b[36mread_edf\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mreading edf\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /oak/stanford/groups/jamesz/magnusrk/sleepFMofficialGithub/notebooks/demo_data/demo_psg.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 2234623  =      0.000 ...  8728.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 22:53:59.476\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.preprocessing\u001b[0m:\u001b[36mresample_signals\u001b[0m:\u001b[36m184\u001b[0m - \u001b[1mresampling signals\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering signal\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 22:53:59.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.preprocessing\u001b[0m:\u001b[36msave_to_hdf5\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1msaving hdf5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/edf_root\"      # dummy root not used for a single file conversion\n",
    "target_dir = \"/note\"    # dummy target not used for a single file conversion\n",
    "\n",
    "edf_path = \"demo_data/demo_psg.edf\"\n",
    "hdf5_path = os.path.join(base_save_path, \"demo_psg.hdf5\")\n",
    "\n",
    "converter = EDFToHDF5Converter(\n",
    "    root_dir=root_dir,\n",
    "    target_dir=target_dir,\n",
    "    resample_rate=128\n",
    ")\n",
    "\n",
    "# run for single file conversion\n",
    "converter.convert(edf_path, hdf5_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Generating embeddings from SleepFM pretrained model\n",
    "\n",
    "Here we show generating embedding for 1 demno PSG. To see full script, please check `sleepfm/pipeline/generate_embeddings.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../sleepfm/checkpoints/model_base\"\n",
    "channel_groups_path = \"../sleepfm/configs/channel_groups.json\"\n",
    "config_path = os.path.join(model_path, \"config.json\")\n",
    "\n",
    "config = load_config(config_path)\n",
    "channel_groups = load_data(channel_groups_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_types = config[\"modality_types\"]\n",
    "in_channels = config[\"in_channels\"]\n",
    "patch_size = config[\"patch_size\"]\n",
    "embed_dim = config[\"embed_dim\"]\n",
    "num_heads = config[\"num_heads\"]\n",
    "num_layers = config[\"num_layers\"]\n",
    "pooling_head = config[\"pooling_head\"]\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 4.44 million\n",
      "Number of layers: 93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/mignot/magnusrk/miniconda3/miniconda3/envs/psg_fm/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_class = getattr(sys.modules[__name__], config['model'])\n",
    "model = model_class(in_channels, patch_size, embed_dim, num_heads, num_layers, pooling_head=pooling_head, dropout=dropout)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "if device.type == \"cuda\":\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "total_layers, total_params = count_parameters(model)\n",
    "print(f'Trainable parameters: {total_params / 1e6:.2f} million')\n",
    "print(f'Number of layers: {total_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): SetTransformer(\n",
       "    (patch_embedding): Tokenizer(\n",
       "      (tokenizer): Sequential(\n",
       "        (0): Conv1d(1, 4, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "        (3): LayerNorm((4, 320), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Conv1d(4, 8, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (5): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ELU(alpha=1.0)\n",
       "        (7): LayerNorm((8, 160), eps=1e-05, elementwise_affine=True)\n",
       "        (8): Conv1d(8, 16, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (10): ELU(alpha=1.0)\n",
       "        (11): LayerNorm((16, 80), eps=1e-05, elementwise_affine=True)\n",
       "        (12): Conv1d(16, 32, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (13): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (14): ELU(alpha=1.0)\n",
       "        (15): LayerNorm((32, 40), eps=1e-05, elementwise_affine=True)\n",
       "        (16): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (17): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (18): ELU(alpha=1.0)\n",
       "        (19): LayerNorm((64, 20), eps=1e-05, elementwise_affine=True)\n",
       "        (20): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (21): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (22): ELU(alpha=1.0)\n",
       "        (23): LayerNorm((128, 10), eps=1e-05, elementwise_affine=True)\n",
       "        (24): AdaptiveAvgPool1d(output_size=1)\n",
       "        (25): Flatten(start_dim=1, end_dim=-1)\n",
       "        (26): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (spatial_pooling): AttentionPooling(\n",
       "      (transformer_layer): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (positional_encoding): PositionalEncoding()\n",
       "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (temporal_pooling): AttentionPooling(\n",
       "      (transformer_layer): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(os.path.join(model_path, \"best.pt\"))\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'model': 'SetTransformer',\n",
       " 'in_channels': 1,\n",
       " 'batch_size': 128,\n",
       " 'epochs': 1,\n",
       " 'lr': 0.001,\n",
       " 'lr_step_period': 2,\n",
       " 'gamma': 0.1,\n",
       " 'temperature': 0.0,\n",
       " 'momentum': 0.9,\n",
       " 'num_workers': 16,\n",
       " 'embed_dim': 128,\n",
       " 'num_heads': 8,\n",
       " 'num_layers': 6,\n",
       " 'pooling_head': 8,\n",
       " 'dropout': 0.3,\n",
       " 'split_path': 'path_to_/dataset_split.json',\n",
       " 'save_path': 'path_to_/models',\n",
       " 'weight_decay': 0.0,\n",
       " 'mode': 'leave_one_out',\n",
       " 'save_iter': 5000,\n",
       " 'eval_iter': 5000,\n",
       " 'log_interval': 100,\n",
       " 'use_wandb': True,\n",
       " 'BAS_CHANNELS': 10,\n",
       " 'RESP_CHANNELS': 7,\n",
       " 'EKG_CHANNELS': 2,\n",
       " 'EMG_CHANNELS': 4,\n",
       " 'max_files': None,\n",
       " 'val_size': 100,\n",
       " 'sampling_duration': 5,\n",
       " 'sampling_freq': 128,\n",
       " 'patch_size': 640,\n",
       " 'modality_types': ['BAS', 'RESP', 'EKG', 'EMG']}"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing files: 100%|██████████| 1/1 [00:00<00:00, 456.45it/s]\n"
     ]
    }
   ],
   "source": [
    "hdf5_paths = [os.path.join(base_save_path, \"demo_psg.hdf5\")]\n",
    "dataset = SetTransformerDataset(config, channel_groups, hdf5_paths=hdf5_paths, split=\"test\")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                                            batch_size=16, \n",
    "                                            num_workers=1, \n",
    "                                            shuffle=False, \n",
    "                                            collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = os.path.join(base_save_path, \"demo_emb\")\n",
    "output_5min_agg = os.path.join(base_save_path, \"demo_5min_agg_emb\")\n",
    "os.makedirs(output, exist_ok=True)\n",
    "os.makedirs(output_5min_agg, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    with tqdm.tqdm(total=len(dataloader)) as pbar:\n",
    "        for batch in dataloader:\n",
    "            batch_data, mask_list, file_paths, dset_names_list, chunk_starts = batch\n",
    "            (bas, resp, ekg, emg) = batch_data\n",
    "            (mask_bas, mask_resp, mask_ekg, mask_emg) = mask_list\n",
    "\n",
    "            bas = bas.to(device, dtype=torch.float)\n",
    "            resp = resp.to(device, dtype=torch.float)\n",
    "            ekg = ekg.to(device, dtype=torch.float)\n",
    "            emg = emg.to(device, dtype=torch.float)\n",
    "\n",
    "            mask_bas = mask_bas.to(device, dtype=torch.bool)\n",
    "            mask_resp = mask_resp.to(device, dtype=torch.bool)\n",
    "            mask_ekg = mask_ekg.to(device, dtype=torch.bool)\n",
    "            mask_emg = mask_emg.to(device, dtype=torch.bool)\n",
    "\n",
    "            embeddings = [\n",
    "                model(bas, mask_bas),\n",
    "                model(resp, mask_resp),\n",
    "                model(ekg, mask_ekg),\n",
    "                model(emg, mask_emg),\n",
    "            ]\n",
    "\n",
    "            # Model gives two kinds of embeddings. Granular 5 second-level embeddings and aggregated 5 minute-level embeddings. We save both of them below. \n",
    "\n",
    "            embeddings_new = [e[0].unsqueeze(1) for e in embeddings]\n",
    "\n",
    "            for i in range(len(file_paths)):\n",
    "                file_path = file_paths[i]\n",
    "                chunk_start = chunk_starts[i]\n",
    "                subject_id = os.path.basename(file_path).split('.')[0]\n",
    "                output_path = os.path.join(output_5min_agg, f\"{subject_id}.hdf5\")\n",
    "\n",
    "                with h5py.File(output_path, 'a') as hdf5_file:\n",
    "                    for modality_idx, modality_type in enumerate(config[\"modality_types\"]):\n",
    "                        if modality_type in hdf5_file:\n",
    "                            dset = hdf5_file[modality_type]\n",
    "                            chunk_start_correct = chunk_start // (embed_dim * 5 * 60)\n",
    "                            chunk_end = chunk_start_correct + embeddings_new[modality_idx][i].shape[0]\n",
    "                            if dset.shape[0] < chunk_end:\n",
    "                                dset.resize((chunk_end,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "                            dset[chunk_start_correct:chunk_end] = embeddings_new[modality_idx][i].cpu().numpy()\n",
    "                        else:\n",
    "                            hdf5_file.create_dataset(modality_type, data=embeddings_new[modality_idx][i].cpu().numpy(), chunks=(embed_dim,) + embeddings_new[modality_idx][i].shape[1:], maxshape=(None,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "\n",
    "            embeddings_new = [e[1] for e in embeddings]\n",
    "\n",
    "            for i in range(len(file_paths)):\n",
    "                file_path = file_paths[i]\n",
    "                chunk_start = chunk_starts[i]\n",
    "                subject_id = os.path.basename(file_path).split('.')[0]\n",
    "                output_path = os.path.join(output, f\"{subject_id}.hdf5\")\n",
    "\n",
    "                with h5py.File(output_path, 'a') as hdf5_file:\n",
    "                    for modality_idx, modality_type in enumerate(config[\"modality_types\"]):\n",
    "                        if modality_type in hdf5_file:\n",
    "                            dset = hdf5_file[modality_type]\n",
    "                            chunk_start_correct = chunk_start // (embed_dim * 5)\n",
    "                            chunk_end = chunk_start_correct + embeddings_new[modality_idx][i].shape[0]\n",
    "                            if dset.shape[0] < chunk_end:\n",
    "                                dset.resize((chunk_end,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "                            dset[chunk_start_correct:chunk_end] = embeddings_new[modality_idx][i].cpu().numpy()\n",
    "                        else:\n",
    "                            hdf5_file.create_dataset(modality_type, data=embeddings_new[modality_idx][i].cpu().numpy(), chunks=(embed_dim,) + embeddings_new[modality_idx][i].shape[1:], maxshape=(None,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Sleep Staging\n",
    "\n",
    "Note that below, we are using our finetuned sleep staging model. It is always a good idea to finetune our model on your specific data, even if you only have a handful of sample, so that the model can adapt to your specific data distribution. Script to finetune your sleep staging model head is given in `sleepfm/pipeline/finetune_sleep_staging.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_staging_model_path = \"../sleepfm/checkpoints/model_sleep_staging\"\n",
    "sleep_staging_config = load_data(os.path.join(sleep_staging_model_path, \"config.json\"))\n",
    "\n",
    "sleep_staging_model_params = sleep_staging_config['model_params']\n",
    "sleep_staging_model_class = getattr(sys.modules[__name__], sleep_staging_config['model'])\n",
    "\n",
    "sleep_staging_model = sleep_staging_model_class(**sleep_staging_model_params).to(device)\n",
    "sleep_staging_model_name = type(sleep_staging_model).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPUs\n"
     ]
    }
   ],
   "source": [
    "sleep_staging_model = nn.DataParallel(sleep_staging_model)\n",
    "print(f\"Using {torch.cuda.device_count()} GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: SleepEventLSTMClassifier\n",
      "Trainable parameters: 1.19 million\n",
      "Number of layers: 20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model initialized: {sleep_staging_model_name}\")\n",
    "total_layers, total_params = count_parameters(sleep_staging_model)\n",
    "print(f'Trainable parameters: {total_params / 1e6:.2f} million')\n",
    "print(f'Number of layers: {total_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_staging_checkpoint_path = os.path.join(sleep_staging_model_path, \"best.pth\")\n",
    "sleep_staging_checkpoint = torch.load(sleep_staging_checkpoint_path)\n",
    "sleep_staging_model.load_state_dict(sleep_staging_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helper functions for loading data for sleep staging. You can find similar functions within `sleepfm/models/dataset.py`. You may need to modify it slightly based on your usecase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepEventClassificationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        channel_groups,\n",
    "        hdf5_paths,\n",
    "        label_files,\n",
    "        split=\"train\",\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.max_channels = self.config[\"max_channels\"]\n",
    "        self.context = int(self.config[\"context\"])\n",
    "        self.channel_like = self.config[\"channel_like\"]\n",
    "\n",
    "        self.max_seq_len = config[\"model_params\"][\"max_seq_length\"]\n",
    "\n",
    "        # --- Build label lookup: {study_id: label_csv_path} ---\n",
    "        # study_id = filename without extension, e.g. \"SSC_12345\"\n",
    "        labels_dict = {\n",
    "            os.path.basename(p).rsplit(\".\", 1)[0]: p\n",
    "            for p in label_files\n",
    "            if os.path.exists(p)\n",
    "        }\n",
    "\n",
    "        # --- Filter to HDF5s that exist and have a matching label file ---\n",
    "        hdf5_paths = [p for p in hdf5_paths if os.path.exists(p)]\n",
    "        hdf5_paths = [\n",
    "            p for p in hdf5_paths\n",
    "            if os.path.basename(p).rsplit(\".\", 1)[0] in labels_dict\n",
    "        ]\n",
    "\n",
    "        if config.get(\"max_files\"):\n",
    "            hdf5_paths = hdf5_paths[: config[\"max_files\"]]\n",
    "\n",
    "        self.hdf5_paths = hdf5_paths\n",
    "        self.labels_dict = labels_dict\n",
    "\n",
    "        # --- Build index map ---\n",
    "        # Each item is (hdf5_path, label_path, start_index)\n",
    "        if self.context == -1:\n",
    "            self.index_map = [\n",
    "                (p, labels_dict[os.path.basename(p).rsplit(\".\", 1)[0]], -1)\n",
    "                for p in self.hdf5_paths\n",
    "            ]\n",
    "        else:\n",
    "            self.index_map = []\n",
    "            loop = tqdm(self.hdf5_paths, total=len(self.hdf5_paths), desc=f\"Indexing {split} data\")\n",
    "            for hdf5_file_path in loop:\n",
    "                file_prefix = os.path.basename(hdf5_file_path).rsplit(\".\", 1)[0]\n",
    "                label_path = labels_dict[file_prefix]\n",
    "\n",
    "                with h5py.File(hdf5_file_path, \"r\") as hf:\n",
    "                    dset_names = list(hf.keys())\n",
    "                    if len(dset_names) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Use first dataset to define length (same as your original behavior)\n",
    "                    first_name = dset_names[0]\n",
    "                    dataset_length = hf[first_name].shape[0]\n",
    "\n",
    "                for i in range(0, dataset_length, self.context):\n",
    "                    self.index_map.append((hdf5_file_path, label_path, i))\n",
    "\n",
    "        # If you have logger, keep; otherwise you can remove these.\n",
    "        # logger.info(f\"Number of files in {split} set: {len(self.hdf5_paths)}\")\n",
    "        # logger.info(f\"Number of files to be processed in {split} set: {len(self.index_map)}\")\n",
    "\n",
    "        self.total_len = len(self.index_map)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def get_index_map(self):\n",
    "        return self.index_map\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hdf5_path, label_path, start_index = self.index_map[idx]\n",
    "\n",
    "        labels_df = pd.read_csv(label_path)\n",
    "        labels_df[\"StageNumber\"] = labels_df[\"StageNumber\"].replace(-1, 0)\n",
    "\n",
    "        y_data = labels_df[\"StageNumber\"].to_numpy()\n",
    "        if self.context != -1:\n",
    "            y_data = y_data[start_index : start_index + self.context]\n",
    "\n",
    "        x_data = []\n",
    "        with h5py.File(hdf5_path, \"r\") as hf:\n",
    "            dset_names = list(hf.keys())\n",
    "\n",
    "            for dataset_name in dset_names:\n",
    "                if dataset_name in self.channel_like:\n",
    "                    if self.context == -1:\n",
    "                        x_data.append(hf[dataset_name][:])\n",
    "                    else:\n",
    "                        x_data.append(hf[dataset_name][start_index : start_index + self.context])\n",
    "\n",
    "        if not x_data:\n",
    "            # Skip this data point if x_data is empty\n",
    "            return self.__getitem__((idx + 1) % self.total_len)\n",
    "\n",
    "        x_data = np.array(x_data)  # (C, T, F) assuming each channel returns (T, F)\n",
    "        x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "        y_data = torch.tensor(y_data, dtype=torch.float32)\n",
    "\n",
    "        min_length = min(x_data.shape[1], len(y_data))\n",
    "        x_data = x_data[:, :min_length, :]\n",
    "        y_data = y_data[:min_length]\n",
    "\n",
    "        return x_data, y_data, self.max_channels, self.max_seq_len, hdf5_path\n",
    "\n",
    "\n",
    "def sleep_event_finetune_full_collate_fn(batch):\n",
    "    x_data, y_data, max_channels_list, max_seq_len_list, hdf5_path_list = zip(*batch)\n",
    "\n",
    "    num_channels = max(max_channels_list)\n",
    "\n",
    "    max_seq_len_temp = max([item.size(1) for item in x_data])\n",
    "    # Determine the max sequence length for padding\n",
    "    if max_seq_len_list[0] is None:\n",
    "        max_seq_len = max_seq_len_temp\n",
    "    else:\n",
    "        max_seq_len = min(max_seq_len_temp, max_seq_len_list[0])\n",
    "\n",
    "    padded_x_data = []\n",
    "    padded_y_data = []\n",
    "    padded_mask = []\n",
    "\n",
    "    for x_item, y_item in zip(x_data, y_data):\n",
    "\n",
    "        # first non-zero index of y_data\n",
    "        #print(y_item.shape)\n",
    "\n",
    "\n",
    "        tgt_sleep_no_sleep = np.where(y_item > 0, 1, 0)\n",
    "        moving_avg_tgt_sleep_no_sleep = np.convolve(tgt_sleep_no_sleep, np.ones(1080)/1080, mode='valid')\n",
    "        try:\n",
    "            first_non_zero_index = np.where(moving_avg_tgt_sleep_no_sleep > 0.5)[0][0]\n",
    "        except IndexError:\n",
    "            first_non_zero_index = 0\n",
    "\n",
    "\n",
    "\n",
    "        #non_zero_indices = (y_item != 0).nonzero(as_tuple=True)[0]\n",
    "        #first_non_zero_index = non_zero_indices[0].item() - 20\n",
    "        if first_non_zero_index < 0:\n",
    "            first_non_zero_index = 0\n",
    "\n",
    "        #first_non_zero_index = 0\n",
    "\n",
    "        #print(f\"First non-zero index of y_data: {first_non_zero_index}\")\n",
    "        # Get the shape of x_item\n",
    "        c, s, e = x_item.size()\n",
    "        c = min(c, num_channels)\n",
    "        s = min(s, max_seq_len + first_non_zero_index)  # Ensure the sequence length doesn't exceed max_seq_len\n",
    "\n",
    "        # Create a padded tensor and a mask tensor for x_data\n",
    "        padded_x_item = torch.zeros((num_channels, max_seq_len, e))\n",
    "        mask = torch.ones((num_channels, max_seq_len))\n",
    "\n",
    "        # Copy the actual data to the padded tensor and set the mask for real data\n",
    "        #print(f\"Shape of x_item: {x_item[:c, first_non_zero_index:s, :e].shape}\")\n",
    "        padded_x_item[:c, :s-first_non_zero_index, :e] = x_item[:c, first_non_zero_index:s, :e]\n",
    "        mask[:c, :s-first_non_zero_index] = 0  # 0 for real data, 1 for padding\n",
    "\n",
    "        # Pad y_data with zeros to match max_seq_len\n",
    "        padded_y_item = torch.zeros(max_seq_len)\n",
    "        padded_y_item[:s-first_non_zero_index] = y_item[first_non_zero_index:s]\n",
    "\n",
    "        # Append padded items to lists\n",
    "        padded_x_data.append(padded_x_item)\n",
    "        padded_y_data.append(padded_y_item)\n",
    "        padded_mask.append(mask)\n",
    "\n",
    "    # Stack all tensors into a batch\n",
    "    x_data = torch.stack(padded_x_data)\n",
    "    y_data = torch.stack(padded_y_data)\n",
    "    padded_mask = torch.stack(padded_mask)\n",
    "\n",
    "    '''\n",
    "    for y_data_mini in y_data:\n",
    "        unique_labels = torch.unique(y_data_mini)\n",
    "        print(f\"Unique labels in batch: {unique_labels}\")\n",
    "    '''\n",
    "\n",
    "    return x_data, y_data, padded_mask, hdf5_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_paths = [os.path.join(base_save_path, \"demo_emb/demo_psg.hdf5\")]\n",
    "label_files = [os.path.join(base_save_path, \"demo_psg.csv\")]\n",
    "test_dataset = SleepEventClassificationDataset(sleep_staging_config, channel_groups, split=\"test\", hdf5_paths=hdf5_paths, label_files=label_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=1, collate_fn=sleep_event_finetune_full_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  6.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation loop at the end of each epoch\n",
    "model.eval()\n",
    "all_targets = []\n",
    "all_logits = []\n",
    "all_outputs = []\n",
    "all_masks = []\n",
    "all_paths = []\n",
    "\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for (x_data, y_data, padded_matrix, hdf5_path_list) in tqdm.tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        x_data, y_data, padded_matrix, hdf5_path_list = x_data.to(device), y_data.to(device), padded_matrix.to(device), list(hdf5_path_list)\n",
    "        outputs, mask = sleep_staging_model(x_data, padded_matrix)\n",
    "        all_targets.append(y_data.cpu().numpy())\n",
    "        all_outputs.append(torch.softmax(outputs, dim=-1).cpu().numpy())\n",
    "        all_logits.append(outputs.cpu().numpy())\n",
    "        all_masks.append(mask.cpu().numpy())\n",
    "        all_paths.append(hdf5_path_list)\n",
    "\n",
    "\n",
    "save_path = os.path.join(base_save_path, \"demo_sleep_staging\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "targets_path = os.path.join(save_path, \"all_targets.pickle\")\n",
    "outputs_path = os.path.join(save_path, \"all_outputs.pickle\")\n",
    "logits_path = os.path.join(save_path, \"all_logits.pickle\")\n",
    "mask_path = os.path.join(save_path, \"all_masks.pickle\")\n",
    "file_paths = os.path.join(save_path, \"all_paths.pickle\")\n",
    "\n",
    "save_data(all_targets, targets_path)\n",
    "save_data(all_outputs, outputs_path)\n",
    "save_data(all_logits, logits_path)\n",
    "save_data(all_masks, mask_path)\n",
    "save_data(all_paths, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1743, 5), (1, 1743))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs[0].shape, all_targets[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 1)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_logits), len(all_outputs), len(all_targets), len(all_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1743, 5), (1, 1743, 5), (1, 1743), (1, 1743))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits[0].shape, all_outputs[0].shape, all_targets[0].shape, all_masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logits_flat = [logits.reshape(-1, logits.shape[-1]) for logits in all_logits]\n",
    "all_outputs_flat = [outputs.reshape(-1, outputs.shape[-1]) for outputs in all_outputs]\n",
    "all_targets_flat = [targets.reshape(-1) for targets in all_targets]\n",
    "all_masks_flat = [mask.reshape(-1) for mask in all_masks]\n",
    "\n",
    "# Convert lists of flattened arrays to single concatenated arrays if desired\n",
    "all_logits_flat = np.concatenate(all_logits_flat, axis=0)\n",
    "all_outputs_flat = np.concatenate(all_outputs_flat, axis=0)\n",
    "all_targets_flat = np.concatenate(all_targets_flat, axis=0)\n",
    "all_masks_flat = np.concatenate(all_masks_flat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1743, 5), (1743, 5), (1743,), (1743,))"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits_flat.shape, all_outputs_flat.shape, all_targets_flat.shape, all_masks_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filter = all_masks_flat == 0\n",
    "\n",
    "# Apply the mask to each flattened array\n",
    "all_logits_filtered = all_logits_flat[mask_filter]\n",
    "all_outputs_filtered = all_outputs_flat[mask_filter]\n",
    "all_targets_filtered = all_targets_flat[mask_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.38611589213998854,\n",
       " 2.0: 0.1474469305794607,\n",
       " 3.0: 0.1399885255306942,\n",
       " 1.0: 0.168100975329891,\n",
       " 4.0: 0.15834767641996558}"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter(all_targets_filtered)\n",
    "total = sum(counts.values())\n",
    "prevalence_dict = {cls: count / total for cls, count in counts.items()}\n",
    "prevalence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Wake\", \"Stage 1\", \"Stage 2\", \"Stage 3\", \"REM\"]\n",
    "# class_labels = [\"No-Apnea\", \"Apnea\"]\n",
    "class_mapping = {label: idx for idx, label in enumerate(class_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Wake: 0.569\n",
      "F1 Score for Stage 1: 0.146\n",
      "F1 Score for Stage 2: 0.118\n",
      "F1 Score for Stage 3: 0.000\n",
      "F1 Score for REM: 0.000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Get predicted labels (argmax on probabilities)\n",
    "predicted_labels = np.argmax(all_outputs_filtered, axis=1)\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "# Step 2: Compute F1 score for each class\n",
    "f1_scores = f1_score(all_targets_filtered, predicted_labels, average=None, labels=range(len(class_labels)))\n",
    "for idx, label in enumerate(class_labels):\n",
    "    print(f\"F1 Score for {label}: {f1_scores[idx]:.3f}\")\n",
    "\n",
    "# Step 3: Create a confusion matrix and normalize it by row to get percentages\n",
    "conf_matrix = confusion_matrix(all_targets_filtered, predicted_labels, labels=range(len(class_labels)))\n",
    "conf_matrix_percent = conf_matrix / conf_matrix.sum(axis=1, keepdims=True) * 100\n",
    "\n",
    "# Plotting the confusion matrix with percentages\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    conf_matrix_percent,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_labels,\n",
    "    yticklabels=class_labels,\n",
    "    annot_kws={\"size\": fontsize},  # Font size for numbers inside the heatmap\n",
    "    cbar_kws={\"shrink\": 1},  # Adjust colorbar size\n",
    ")\n",
    "\n",
    "# Customizing axis labels and ticks\n",
    "plt.xlabel(\"Predicted Labels\", fontsize=fontsize)\n",
    "plt.ylabel(\"True Labels\", fontsize=fontsize)\n",
    "plt.xticks(fontsize=12, ha=\"center\")  # Font size for x-axis tick labels with rotation\n",
    "plt.yticks(fontsize=12)  # Font size for y-axis tick labels\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Disease Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_model_path = \"../sleepfm/checkpoints/model_diagnosis\"\n",
    "config = load_data(os.path.join(disease_model_path, \"config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"model_params\"][\"dropout\"] = 0.0\n",
    "model_params = config['model_params']\n",
    "model_class = getattr(sys.modules[__name__], config['model'])\n",
    "model = model_class(**model_params).to(device)\n",
    "model_name = type(model).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: DiagnosisFinetuneFullLSTMCOXPHWithDemo\n",
      "Trainable parameters: 0.91 million\n",
      "Number of layers: 15\n"
     ]
    }
   ],
   "source": [
    "model = nn.DataParallel(model)\n",
    "print(f\"Model initialized: {model_name}\")\n",
    "total_layers, total_params = count_parameters(model)\n",
    "print(f'Trainable parameters: {total_params / 1e6:.2f} million')\n",
    "print(f'Number of layers: {total_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(disease_model_path, \"best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisFinetuneFullCOXPHWithDemoDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 config,\n",
    "                 channel_groups,\n",
    "                 hdf5_paths=None,\n",
    "                 demo_labels_path=None,\n",
    "                 split=\"train\"):\n",
    "\n",
    "        self.config = config\n",
    "        self.channel_groups = channel_groups\n",
    "        self.max_channels = self.config[\"max_channels\"]\n",
    "\n",
    "        # --- Load demographic features ---\n",
    "        if not demo_labels_path:\n",
    "            demo_labels_path = config[\"demo_labels_path\"]\n",
    "\n",
    "        demo_labels_df = pd.read_csv(demo_labels_path)\n",
    "        demo_labels_df = demo_labels_df.set_index(\"Study ID\")\n",
    "        study_ids = set(demo_labels_df.index)\n",
    "\n",
    "        is_event_df = pd.read_csv(os.path.join(self.config[\"labels_path\"], \"is_event.csv\"))\n",
    "        event_time_df = pd.read_csv(os.path.join(self.config[\"labels_path\"], \"time_to_event.csv\"))\n",
    "\n",
    "        is_event_df = is_event_df.set_index('Study ID')\n",
    "        event_time_df = event_time_df.set_index('Study ID')\n",
    "\n",
    "        # --- Resolve HDF5 paths (explicit precedence) ---\n",
    "        if hdf5_paths:\n",
    "            # Use provided paths directly\n",
    "            hdf5_paths = [f for f in hdf5_paths if os.path.exists(f)]\n",
    "        else:\n",
    "            # Load from split file\n",
    "            split_paths = load_data(config[\"split_path\"])[split]\n",
    "            hdf5_paths = [f for f in split_paths if os.path.exists(f)]\n",
    "\n",
    "        # Filter by available demo labels\n",
    "        hdf5_paths = [\n",
    "            f for f in hdf5_paths\n",
    "            if os.path.basename(f).split(\".\")[0] in study_ids\n",
    "        ]\n",
    "\n",
    "        # Optional truncation\n",
    "        if config.get(\"max_files\"):\n",
    "            hdf5_paths = hdf5_paths[:config[\"max_files\"]]\n",
    "\n",
    "        labels_dict = {}\n",
    "        # Loop over each study_id\n",
    "        for study_id in tqdm.tqdm(study_ids):\n",
    "            # Extract the row as a whole for both dataframes (faster than iterating over columns)\n",
    "            is_event_row = list(is_event_df.loc[study_id].values)\n",
    "            event_time_row = list(event_time_df.loc[study_id].values)\n",
    "            demo_feats = list(demo_labels_df.loc[study_id].values)\n",
    "\n",
    "            # values = [[event_time, is_event] for is_event, event_time in zip(is_event_row, event_time_row)]\n",
    "            labels_dict[study_id] = {\n",
    "                \"is_event\": is_event_row,\n",
    "                \"event_time\": event_time_row, \n",
    "                \"demo_feats\": demo_feats\n",
    "            }\n",
    "\n",
    "        # --- Build index map ---\n",
    "        self.index_map = [\n",
    "            (path, labels_dict[os.path.basename(path).split(\".\")[0]])\n",
    "            for path in hdf5_paths\n",
    "        ]\n",
    "\n",
    "        print(f\"Number of files in {split} set: {len(hdf5_paths)}\")\n",
    "        print(f\"Number of files to be processed in {split} set: {len(self.index_map)}\")\n",
    "\n",
    "        self.total_len = len(self.index_map)\n",
    "        self.max_seq_len = config[\"model_params\"][\"max_seq_length\"]\n",
    "\n",
    "        if self.total_len == 0:\n",
    "            raise ValueError(f\"No valid HDF5 files found for split='{split}'.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hdf5_path, tte_event = self.index_map[idx]\n",
    "\n",
    "        event_time = tte_event[\"event_time\"]\n",
    "        is_event = tte_event[\"is_event\"]\n",
    "        demo_feats = tte_event[\"demo_feats\"]\n",
    "\n",
    "        x_data = []\n",
    "        with h5py.File(hdf5_path, 'r') as hf:\n",
    "            dset_names = []\n",
    "            for dset_name in hf.keys():\n",
    "                if isinstance(hf[dset_name], h5py.Dataset) and dset_name in self.config[\"modality_types\"]:\n",
    "                    dset_names.append(dset_name)\n",
    "            \n",
    "            random.shuffle(dset_names)\n",
    "            for dataset_name in dset_names:\n",
    "                x_data.append(hf[dataset_name][:])\n",
    "\n",
    "        if not x_data:\n",
    "            # Skip this data point if x_data is empty\n",
    "            return self.__getitem__((idx + 1) % self.total_len)\n",
    "\n",
    "        # Convert x_data list to a single numpy array\n",
    "        x_data = np.array(x_data)\n",
    "\n",
    "        # Convert x_data to tensor\n",
    "        x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "\n",
    "        event_time = torch.tensor(event_time, dtype=torch.float32)\n",
    "        is_event = torch.tensor(is_event) \n",
    "\n",
    "        demo_feats = torch.tensor(demo_feats, dtype=torch.float32)\n",
    "\n",
    "        return x_data, event_time, is_event, demo_feats, self.max_channels, self.max_seq_len, hdf5_path\n",
    "\n",
    "\n",
    "def diagnosis_finetune_full_coxph_with_demo_collate_fn(batch):\n",
    "    x_data, event_time, is_event, demo_feats, max_channels_list, max_seq_len_list, hdf5_path_list = zip(*batch)\n",
    "\n",
    "    num_channels = max(max_channels_list)\n",
    "\n",
    "    if max_seq_len_list[0] == None:\n",
    "        max_seq_len = max([item.size(1) for item in x_data])\n",
    "    else:\n",
    "        max_seq_len = max_seq_len_list[0]\n",
    "\n",
    "    padded_x_data = []\n",
    "    padded_mask = []\n",
    "    for item in x_data:\n",
    "        c, s, e = item.size()\n",
    "        c = min(c, num_channels)\n",
    "        s = min(s, max_seq_len)  # Ensure the sequence length doesn't exceed max_seq_len\n",
    "\n",
    "        # Create a padded tensor and a mask tensor\n",
    "        padded_item = torch.zeros((num_channels, max_seq_len, e))\n",
    "        mask = torch.ones((num_channels, max_seq_len))\n",
    "\n",
    "        # Copy the actual data to the padded tensor and set the mask for real data\n",
    "        padded_item[:c, :s, :e] = item[:c, :s, :e]\n",
    "        mask[:c, :s] = 0  # 0 for real data, 1 for padding\n",
    "\n",
    "        padded_x_data.append(padded_item)\n",
    "        padded_mask.append(mask)\n",
    "    \n",
    "    # Stack all tensors into a batch\n",
    "    x_data = torch.stack(padded_x_data)\n",
    "    event_time = torch.stack(event_time)\n",
    "    is_event = torch.stack(is_event)\n",
    "    demo_feats = torch.stack(demo_feats)\n",
    "    padded_mask = torch.stack(padded_mask)\n",
    "    \n",
    "    return x_data, event_time, is_event, demo_feats, padded_mask, hdf5_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(base_save_path, \"demo_diagnosis\")\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2475.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in test set: 1\n",
      "Number of files to be processed in test set: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hdf5_paths = [os.path.join(base_save_path, \"demo_emb/demo_psg.hdf5\")]\n",
    "demo_labels_path = os.path.join(base_save_path, \"demo_age_gender.csv\")\n",
    "config[\"labels_path\"] = base_save_path\n",
    "\n",
    "test_dataset = DiagnosisFinetuneFullCOXPHWithDemoDataset(config, channel_groups, split=\"test\", hdf5_paths=hdf5_paths, demo_labels_path=demo_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=1, collate_fn=diagnosis_finetune_full_coxph_with_demo_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  3.18it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_event_times = []\n",
    "all_is_event = []\n",
    "all_outputs = []\n",
    "all_paths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for item in tqdm.tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        x_data, event_times, is_event, demo_feats, padded_matrix, hdf5_path_list = item\n",
    "        x_data, event_times, is_event, demo_feats, padded_matrix, hdf5_path_list = x_data.to(device), event_times.to(device), is_event.to(device), demo_feats.to(device), padded_matrix.to(device), list(hdf5_path_list)\n",
    "        outputs = model(x_data, padded_matrix, demo_feats)\n",
    "    \n",
    "        logits = outputs.cpu().numpy()\n",
    "        all_outputs.append(logits)\n",
    "        all_event_times.append(event_times.cpu().numpy())\n",
    "        all_is_event.append(is_event.cpu().numpy())\n",
    "        all_paths.append(hdf5_path_list)\n",
    "\n",
    "all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "all_event_times = np.concatenate(all_event_times, axis=0)\n",
    "all_is_event = np.concatenate(all_is_event, axis=0)\n",
    "all_paths = np.concatenate(all_paths)\n",
    "\n",
    "outputs_path = os.path.join(save_path, \"all_outputs.pickle\")\n",
    "event_times_path = os.path.join(save_path, \"all_event_times.pickle\")\n",
    "is_event_path = os.path.join(save_path, \"all_is_event.pickle\")\n",
    "file_paths = os.path.join(save_path, \"all_paths.pickle\")\n",
    "\n",
    "save_data(all_outputs, outputs_path)\n",
    "save_data(all_event_times, event_times_path)\n",
    "save_data(all_is_event, is_event_path)\n",
    "save_data(all_paths, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1065), (1, 1065), (1, 1065))"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs.shape, all_event_times.shape, all_is_event.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you get the model outputs, which you can then use to look for specific disease diagnosis. Nope that the shape of the output above is 1065, meaning, this model gives logprobs for 1065 conditions. We provide information about each disease index and its corresponding phecode here `sleepfm/configs/label_mapping.csv`. You can map it as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"../sleepfm/configs/label_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[\"output\"] = all_outputs[0]\n",
    "labels_df[\"is_event\"] = all_is_event[0]\n",
    "labels_df[\"event_time\"] = all_event_times[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_idx</th>\n",
       "      <th>phecode</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>output</th>\n",
       "      <th>is_event</th>\n",
       "      <th>event_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Intestinal infection</td>\n",
       "      <td>1.838776</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Bacterial enteritis</td>\n",
       "      <td>2.605937</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Viral Enteritis</td>\n",
       "      <td>1.971087</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Septicemia</td>\n",
       "      <td>4.495085</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>38.3</td>\n",
       "      <td>Bacteremia</td>\n",
       "      <td>4.594444</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_idx phecode             phenotype    output  is_event  event_time\n",
       "0          0     8.0  Intestinal infection  1.838776         0      3845.0\n",
       "1          1     8.5   Bacterial enteritis  2.605937         0      3845.0\n",
       "2          2     8.6       Viral Enteritis  1.971087         0      3845.0\n",
       "3          3    38.0            Septicemia  4.495085         0      3845.0\n",
       "4          4    38.3            Bacteremia  4.594444         0      3845.0"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you get the output hazards from our model, and also your labels for is_event and event_times. Is_event is an indicator for if the event occured and event_time is the time to event"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleepfm_clinical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
