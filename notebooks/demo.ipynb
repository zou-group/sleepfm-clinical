{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing Details\n",
    "\n",
    "\n",
    "Before running this notebook, please preprocess your PSG files using the scripts provided in `sleepfm/preprocessing`. Note that PSG recordings may contain different sets of channels across datasets. The predefined channel–modality mappings used in this project are specified in `sleepfm/configs/channel_groups.json`.\n",
    "\n",
    "Although we have attempted to make this mapping as comprehensive as possible, we strongly recommend reviewing the channels present in your specific PSG data. In consultation with domain experts, you should group any additional or dataset-specific channels into the appropriate modality categories and update `channel_groups.json` accordingly. This step is critical to ensure that all channels are correctly aligned with their intended modalities during preprocessing and downstream modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import os\n",
    "import tqdm\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../sleepfm\")\n",
    "from preprocessing.preprocessing import EDFToHDF5Converter\n",
    "from models.dataset import SetTransformerDataset, collate_fn\n",
    "from models.models import SetTransformer, SleepEventLSTMClassifier, DiagnosisFinetuneFullLSTMCOXPHWithDemo\n",
    "import h5py\n",
    "from utils import load_config, load_data, save_data, count_parameters\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 0: Preprocessing EDF files\n",
    "\n",
    "Note: This is just a demo notebook that preprocesses a single, specific file. run `sleepfm/preprocessing/preprocessing.sh` with appropriate folders to generate multiple preprocessed files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_save_path = \"demo_data\"\n",
    "os.makedirs(base_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 21:41:07.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.preprocessing\u001b[0m:\u001b[36mread_edf\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mreading edf\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /oak/stanford/groups/mignot/psg/SSC_Stanford/all/SSC_2004_1006994706.EDF...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 8937983  =      0.000 ... 34913.996 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 21:41:26.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.preprocessing\u001b[0m:\u001b[36mresample_signals\u001b[0m:\u001b[36m184\u001b[0m - \u001b[1mresampling signals\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n",
      "Filtering signal\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2026-01-05 21:41:35.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mpreprocessing.preprocessing\u001b[0m:\u001b[36msave_to_hdf5\u001b[0m:\u001b[36m219\u001b[0m - \u001b[1msaving hdf5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/edf_root\"      # dummy root not used for a single file conversion\n",
    "target_dir = \"/note\"    # dummy target not used for a single file conversion\n",
    "\n",
    "#edf_path = \"/path/to/demo_psg.edf\"\n",
    "# edf_path = \"/oak/stanford/groups/mignot/psg/SSC_Stanford/ssc/2015/SSC_2015_0002.edf\"\n",
    "edf_path = \"/oak/stanford/groups/mignot/psg/SSC_Stanford/all/SSC_2004_1006994706.EDF\"\n",
    "hdf5_path = os.path.join(base_save_path, \"demo_psg.hdf5\")\n",
    "\n",
    "converter = EDFToHDF5Converter(\n",
    "    root_dir=root_dir,\n",
    "    target_dir=target_dir,\n",
    "    resample_rate=128\n",
    ")\n",
    "\n",
    "# run for single file conversion\n",
    "converter.convert(edf_path, hdf5_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 1: Generating embeddings from SleepFM pretrained model\n",
    "\n",
    "Here we show generating embedding for 1 demno PSG. To see full script, please check `sleepfm/pipeline/generate_embeddings.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../sleepfm/checkpoints/model_base\"\n",
    "channel_groups_path = \"../sleepfm/configs/channel_groups.json\"\n",
    "config_path = os.path.join(model_path, \"config.json\")\n",
    "\n",
    "config = load_config(config_path)\n",
    "channel_groups = load_data(channel_groups_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modality_types = config[\"modality_types\"]\n",
    "in_channels = config[\"in_channels\"]\n",
    "patch_size = config[\"patch_size\"]\n",
    "embed_dim = config[\"embed_dim\"]\n",
    "num_heads = config[\"num_heads\"]\n",
    "num_layers = config[\"num_layers\"]\n",
    "pooling_head = config[\"pooling_head\"]\n",
    "dropout = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/mignot/magnusrk/miniconda3/miniconda3/envs/psg_fm/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 4.44 million\n",
      "Number of layers: 93\n"
     ]
    }
   ],
   "source": [
    "model_class = getattr(sys.modules[__name__], config['model'])\n",
    "model = model_class(in_channels, patch_size, embed_dim, num_heads, num_layers, pooling_head=pooling_head, dropout=dropout)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "if device.type == \"cuda\":\n",
    "    model = torch.nn.DataParallel(model)\n",
    "\n",
    "model.to(device)\n",
    "total_layers, total_params = count_parameters(model)\n",
    "print(f'Trainable parameters: {total_params / 1e6:.2f} million')\n",
    "print(f'Number of layers: {total_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): SetTransformer(\n",
       "    (patch_embedding): Tokenizer(\n",
       "      (tokenizer): Sequential(\n",
       "        (0): Conv1d(1, 4, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (1): BatchNorm1d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "        (3): LayerNorm((4, 320), eps=1e-05, elementwise_affine=True)\n",
       "        (4): Conv1d(4, 8, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (5): BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (6): ELU(alpha=1.0)\n",
       "        (7): LayerNorm((8, 160), eps=1e-05, elementwise_affine=True)\n",
       "        (8): Conv1d(8, 16, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (9): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (10): ELU(alpha=1.0)\n",
       "        (11): LayerNorm((16, 80), eps=1e-05, elementwise_affine=True)\n",
       "        (12): Conv1d(16, 32, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (13): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (14): ELU(alpha=1.0)\n",
       "        (15): LayerNorm((32, 40), eps=1e-05, elementwise_affine=True)\n",
       "        (16): Conv1d(32, 64, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (17): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (18): ELU(alpha=1.0)\n",
       "        (19): LayerNorm((64, 20), eps=1e-05, elementwise_affine=True)\n",
       "        (20): Conv1d(64, 128, kernel_size=(5,), stride=(2,), padding=(2,))\n",
       "        (21): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (22): ELU(alpha=1.0)\n",
       "        (23): LayerNorm((128, 10), eps=1e-05, elementwise_affine=True)\n",
       "        (24): AdaptiveAvgPool1d(output_size=1)\n",
       "        (25): Flatten(start_dim=1, end_dim=-1)\n",
       "        (26): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (spatial_pooling): AttentionPooling(\n",
       "      (transformer_layer): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (positional_encoding): PositionalEncoding()\n",
       "    (layer_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer_encoder): TransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TransformerEncoderLayer(\n",
       "          (self_attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "          )\n",
       "          (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "          (dropout): Dropout(p=0.0, inplace=False)\n",
       "          (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout1): Dropout(p=0.0, inplace=False)\n",
       "          (dropout2): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (temporal_pooling): AttentionPooling(\n",
       "      (transformer_layer): TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=128, out_features=2048, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=2048, out_features=128, bias=True)\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(os.path.join(model_path, \"best.pt\"))\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'seed': 42,\n",
       " 'model': 'SetTransformer',\n",
       " 'in_channels': 1,\n",
       " 'batch_size': 128,\n",
       " 'epochs': 1,\n",
       " 'lr': 0.001,\n",
       " 'lr_step_period': 2,\n",
       " 'gamma': 0.1,\n",
       " 'temperature': 0.0,\n",
       " 'momentum': 0.9,\n",
       " 'num_workers': 16,\n",
       " 'embed_dim': 128,\n",
       " 'num_heads': 8,\n",
       " 'num_layers': 6,\n",
       " 'pooling_head': 8,\n",
       " 'dropout': 0.3,\n",
       " 'split_path': 'path_to_/dataset_split.json',\n",
       " 'save_path': 'path_to_/models',\n",
       " 'weight_decay': 0.0,\n",
       " 'mode': 'leave_one_out',\n",
       " 'save_iter': 5000,\n",
       " 'eval_iter': 5000,\n",
       " 'log_interval': 100,\n",
       " 'use_wandb': True,\n",
       " 'BAS_CHANNELS': 10,\n",
       " 'RESP_CHANNELS': 7,\n",
       " 'EKG_CHANNELS': 2,\n",
       " 'EMG_CHANNELS': 4,\n",
       " 'max_files': None,\n",
       " 'val_size': 100,\n",
       " 'sampling_duration': 5,\n",
       " 'sampling_freq': 128,\n",
       " 'patch_size': 640,\n",
       " 'modality_types': ['BAS', 'RESP', 'EKG', 'EMG']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Indexing files: 100%|██████████| 1/1 [00:00<00:00, 180.63it/s]\n"
     ]
    }
   ],
   "source": [
    "hdf5_paths = [os.path.join(base_save_path, \"demo_psg.hdf5\")]\n",
    "dataset = SetTransformerDataset(config, channel_groups, hdf5_paths=hdf5_paths, split=\"test\")\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(dataset, \n",
    "                                            batch_size=16, \n",
    "                                            num_workers=1, \n",
    "                                            shuffle=False, \n",
    "                                            collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = os.path.join(base_save_path, \"demo_emb\")\n",
    "output_5min_agg = os.path.join(base_save_path, \"demo_5min_agg_emb\")\n",
    "os.makedirs(output, exist_ok=True)\n",
    "os.makedirs(output_5min_agg, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:29<00:00,  3.71s/it]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    with tqdm.tqdm(total=len(dataloader)) as pbar:\n",
    "        for batch in dataloader:\n",
    "            batch_data, mask_list, file_paths, dset_names_list, chunk_starts = batch\n",
    "            (bas, resp, ekg, emg) = batch_data\n",
    "            (mask_bas, mask_resp, mask_ekg, mask_emg) = mask_list\n",
    "\n",
    "            bas = bas.to(device, dtype=torch.float)\n",
    "            resp = resp.to(device, dtype=torch.float)\n",
    "            ekg = ekg.to(device, dtype=torch.float)\n",
    "            emg = emg.to(device, dtype=torch.float)\n",
    "\n",
    "            mask_bas = mask_bas.to(device, dtype=torch.bool)\n",
    "            mask_resp = mask_resp.to(device, dtype=torch.bool)\n",
    "            mask_ekg = mask_ekg.to(device, dtype=torch.bool)\n",
    "            mask_emg = mask_emg.to(device, dtype=torch.bool)\n",
    "\n",
    "            embeddings = [\n",
    "                model(bas, mask_bas),\n",
    "                model(resp, mask_resp),\n",
    "                model(ekg, mask_ekg),\n",
    "                model(emg, mask_emg),\n",
    "            ]\n",
    "\n",
    "            # Model gives two kinds of embeddings. Granular 5 second-level embeddings and aggregated 5 minute-level embeddings. We save both of them below. \n",
    "\n",
    "            embeddings_new = [e[0].unsqueeze(1) for e in embeddings]\n",
    "\n",
    "            for i in range(len(file_paths)):\n",
    "                file_path = file_paths[i]\n",
    "                chunk_start = chunk_starts[i]\n",
    "                subject_id = os.path.basename(file_path).split('.')[0]\n",
    "                output_path = os.path.join(output_5min_agg, f\"{subject_id}.hdf5\")\n",
    "\n",
    "                with h5py.File(output_path, 'a') as hdf5_file:\n",
    "                    for modality_idx, modality_type in enumerate(config[\"modality_types\"]):\n",
    "                        if modality_type in hdf5_file:\n",
    "                            dset = hdf5_file[modality_type]\n",
    "                            chunk_start_correct = chunk_start // (embed_dim * 5 * 60)\n",
    "                            chunk_end = chunk_start_correct + embeddings_new[modality_idx][i].shape[0]\n",
    "                            if dset.shape[0] < chunk_end:\n",
    "                                dset.resize((chunk_end,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "                            dset[chunk_start_correct:chunk_end] = embeddings_new[modality_idx][i].cpu().numpy()\n",
    "                        else:\n",
    "                            hdf5_file.create_dataset(modality_type, data=embeddings_new[modality_idx][i].cpu().numpy(), chunks=(embed_dim,) + embeddings_new[modality_idx][i].shape[1:], maxshape=(None,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "\n",
    "            embeddings_new = [e[1] for e in embeddings]\n",
    "\n",
    "            for i in range(len(file_paths)):\n",
    "                file_path = file_paths[i]\n",
    "                chunk_start = chunk_starts[i]\n",
    "                subject_id = os.path.basename(file_path).split('.')[0]\n",
    "                output_path = os.path.join(output, f\"{subject_id}.hdf5\")\n",
    "\n",
    "                with h5py.File(output_path, 'a') as hdf5_file:\n",
    "                    for modality_idx, modality_type in enumerate(config[\"modality_types\"]):\n",
    "                        if modality_type in hdf5_file:\n",
    "                            dset = hdf5_file[modality_type]\n",
    "                            chunk_start_correct = chunk_start // (embed_dim * 5)\n",
    "                            chunk_end = chunk_start_correct + embeddings_new[modality_idx][i].shape[0]\n",
    "                            if dset.shape[0] < chunk_end:\n",
    "                                dset.resize((chunk_end,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "                            dset[chunk_start_correct:chunk_end] = embeddings_new[modality_idx][i].cpu().numpy()\n",
    "                        else:\n",
    "                            hdf5_file.create_dataset(modality_type, data=embeddings_new[modality_idx][i].cpu().numpy(), chunks=(embed_dim,) + embeddings_new[modality_idx][i].shape[1:], maxshape=(None,) + embeddings_new[modality_idx][i].shape[1:])\n",
    "            pbar.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 2: Sleep Staging\n",
    "\n",
    "Note that below, we are using our finetuned sleep staging model. It is always a good idea to finetune our model on your specific data, even if you only have a handful of sample, so that the model can adapt to your specific data distribution. Script to finetune your sleep staging model head is given in `sleepfm/pipeline/finetune_sleep_staging.py`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/groups/mignot/magnusrk/miniconda3/miniconda3/envs/psg_fm/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sleep_staging_model_path = \"../sleepfm/checkpoints/model_sleep_staging\"\n",
    "sleep_staging_config = load_data(os.path.join(sleep_staging_model_path, \"config.json\"))\n",
    "\n",
    "sleep_staging_model_params = sleep_staging_config['model_params']\n",
    "sleep_staging_model_class = getattr(sys.modules[__name__], sleep_staging_config['model'])\n",
    "\n",
    "sleep_staging_model = sleep_staging_model_class(**sleep_staging_model_params).to(device)\n",
    "sleep_staging_model_name = type(sleep_staging_model).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPUs\n"
     ]
    }
   ],
   "source": [
    "sleep_staging_model = nn.DataParallel(sleep_staging_model)\n",
    "print(f\"Using {torch.cuda.device_count()} GPUs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: SleepEventLSTMClassifier\n",
      "Trainable parameters: 1.19 million\n",
      "Number of layers: 20\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model initialized: {sleep_staging_model_name}\")\n",
    "total_layers, total_params = count_parameters(sleep_staging_model)\n",
    "print(f'Trainable parameters: {total_params / 1e6:.2f} million')\n",
    "print(f'Number of layers: {total_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sleep_staging_checkpoint_path = os.path.join(sleep_staging_model_path, \"best.pth\")\n",
    "sleep_staging_checkpoint = torch.load(sleep_staging_checkpoint_path)\n",
    "sleep_staging_model.load_state_dict(sleep_staging_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are some helper functions for loading data for sleep staging. You can find similar functions within `sleepfm/models/dataset.py`. You may need to modify it slightly based on your usecase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SleepEventClassificationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config,\n",
    "        channel_groups,\n",
    "        hdf5_paths,\n",
    "        label_files,\n",
    "        split=\"train\",\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.max_channels = self.config[\"max_channels\"]\n",
    "        self.context = int(self.config[\"context\"])\n",
    "        self.channel_like = self.config[\"channel_like\"]\n",
    "\n",
    "        self.max_seq_len = config[\"model_params\"][\"max_seq_length\"]\n",
    "\n",
    "        # --- Build label lookup: {study_id: label_csv_path} ---\n",
    "        # study_id = filename without extension, e.g. \"SSC_12345\"\n",
    "        labels_dict = {\n",
    "            os.path.basename(p).rsplit(\".\", 1)[0]: p\n",
    "            for p in label_files\n",
    "            if os.path.exists(p)\n",
    "        }\n",
    "\n",
    "        # --- Filter to HDF5s that exist and have a matching label file ---\n",
    "        hdf5_paths = [p for p in hdf5_paths if os.path.exists(p)]\n",
    "        hdf5_paths = [\n",
    "            p for p in hdf5_paths\n",
    "            if os.path.basename(p).rsplit(\".\", 1)[0] in labels_dict\n",
    "        ]\n",
    "\n",
    "        if config.get(\"max_files\"):\n",
    "            hdf5_paths = hdf5_paths[: config[\"max_files\"]]\n",
    "\n",
    "        self.hdf5_paths = hdf5_paths\n",
    "        self.labels_dict = labels_dict\n",
    "\n",
    "        # --- Build index map ---\n",
    "        # Each item is (hdf5_path, label_path, start_index)\n",
    "        if self.context == -1:\n",
    "            self.index_map = [\n",
    "                (p, labels_dict[os.path.basename(p).rsplit(\".\", 1)[0]], -1)\n",
    "                for p in self.hdf5_paths\n",
    "            ]\n",
    "        else:\n",
    "            self.index_map = []\n",
    "            loop = tqdm(self.hdf5_paths, total=len(self.hdf5_paths), desc=f\"Indexing {split} data\")\n",
    "            for hdf5_file_path in loop:\n",
    "                file_prefix = os.path.basename(hdf5_file_path).rsplit(\".\", 1)[0]\n",
    "                label_path = labels_dict[file_prefix]\n",
    "\n",
    "                with h5py.File(hdf5_file_path, \"r\") as hf:\n",
    "                    dset_names = list(hf.keys())\n",
    "                    if len(dset_names) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Use first dataset to define length (same as your original behavior)\n",
    "                    first_name = dset_names[0]\n",
    "                    dataset_length = hf[first_name].shape[0]\n",
    "\n",
    "                for i in range(0, dataset_length, self.context):\n",
    "                    self.index_map.append((hdf5_file_path, label_path, i))\n",
    "\n",
    "        # If you have logger, keep; otherwise you can remove these.\n",
    "        # logger.info(f\"Number of files in {split} set: {len(self.hdf5_paths)}\")\n",
    "        # logger.info(f\"Number of files to be processed in {split} set: {len(self.index_map)}\")\n",
    "\n",
    "        self.total_len = len(self.index_map)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def get_index_map(self):\n",
    "        return self.index_map\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hdf5_path, label_path, start_index = self.index_map[idx]\n",
    "\n",
    "        labels_df = pd.read_csv(label_path)\n",
    "        labels_df[\"StageNumber\"] = labels_df[\"StageNumber\"].replace(-1, 0)\n",
    "\n",
    "        y_data = labels_df[\"StageNumber\"].to_numpy()\n",
    "        if self.context != -1:\n",
    "            y_data = y_data[start_index : start_index + self.context]\n",
    "\n",
    "        x_data = []\n",
    "        with h5py.File(hdf5_path, \"r\") as hf:\n",
    "            dset_names = list(hf.keys())\n",
    "\n",
    "            for dataset_name in dset_names:\n",
    "                if dataset_name in self.channel_like:\n",
    "                    if self.context == -1:\n",
    "                        x_data.append(hf[dataset_name][:])\n",
    "                    else:\n",
    "                        x_data.append(hf[dataset_name][start_index : start_index + self.context])\n",
    "\n",
    "        if not x_data:\n",
    "            # Skip this data point if x_data is empty\n",
    "            return self.__getitem__((idx + 1) % self.total_len)\n",
    "\n",
    "        x_data = np.array(x_data)  # (C, T, F) assuming each channel returns (T, F)\n",
    "        x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "        y_data = torch.tensor(y_data, dtype=torch.float32)\n",
    "\n",
    "        min_length = min(x_data.shape[1], len(y_data))\n",
    "        x_data = x_data[:, :min_length, :]\n",
    "        y_data = y_data[:min_length]\n",
    "\n",
    "        return x_data, y_data, self.max_channels, self.max_seq_len, hdf5_path\n",
    "\n",
    "\n",
    "def sleep_event_finetune_full_collate_fn(batch):\n",
    "    x_data, y_data, max_channels_list, max_seq_len_list, hdf5_path_list = zip(*batch)\n",
    "\n",
    "    num_channels = max(max_channels_list)\n",
    "\n",
    "    max_seq_len_temp = max([item.size(1) for item in x_data])\n",
    "    # Determine the max sequence length for padding\n",
    "    if max_seq_len_list[0] is None:\n",
    "        max_seq_len = max_seq_len_temp\n",
    "    else:\n",
    "        max_seq_len = min(max_seq_len_temp, max_seq_len_list[0])\n",
    "\n",
    "    padded_x_data = []\n",
    "    padded_y_data = []\n",
    "    padded_mask = []\n",
    "\n",
    "    for x_item, y_item in zip(x_data, y_data):\n",
    "\n",
    "        # first non-zero index of y_data\n",
    "        #print(y_item.shape)\n",
    "\n",
    "\n",
    "        tgt_sleep_no_sleep = np.where(y_item > 0, 1, 0)\n",
    "        moving_avg_tgt_sleep_no_sleep = np.convolve(tgt_sleep_no_sleep, np.ones(1080)/1080, mode='valid')\n",
    "        try:\n",
    "            first_non_zero_index = np.where(moving_avg_tgt_sleep_no_sleep > 0.5)[0][0]\n",
    "        except IndexError:\n",
    "            first_non_zero_index = 0\n",
    "\n",
    "\n",
    "\n",
    "        #non_zero_indices = (y_item != 0).nonzero(as_tuple=True)[0]\n",
    "        #first_non_zero_index = non_zero_indices[0].item() - 20\n",
    "        if first_non_zero_index < 0:\n",
    "            first_non_zero_index = 0\n",
    "\n",
    "        #first_non_zero_index = 0\n",
    "\n",
    "        #print(f\"First non-zero index of y_data: {first_non_zero_index}\")\n",
    "        # Get the shape of x_item\n",
    "        c, s, e = x_item.size()\n",
    "        c = min(c, num_channels)\n",
    "        s = min(s, max_seq_len + first_non_zero_index)  # Ensure the sequence length doesn't exceed max_seq_len\n",
    "\n",
    "        # Create a padded tensor and a mask tensor for x_data\n",
    "        padded_x_item = torch.zeros((num_channels, max_seq_len, e))\n",
    "        mask = torch.ones((num_channels, max_seq_len))\n",
    "\n",
    "        # Copy the actual data to the padded tensor and set the mask for real data\n",
    "        #print(f\"Shape of x_item: {x_item[:c, first_non_zero_index:s, :e].shape}\")\n",
    "        padded_x_item[:c, :s-first_non_zero_index, :e] = x_item[:c, first_non_zero_index:s, :e]\n",
    "        mask[:c, :s-first_non_zero_index] = 0  # 0 for real data, 1 for padding\n",
    "\n",
    "        # Pad y_data with zeros to match max_seq_len\n",
    "        padded_y_item = torch.zeros(max_seq_len)\n",
    "        padded_y_item[:s-first_non_zero_index] = y_item[first_non_zero_index:s]\n",
    "\n",
    "        # Append padded items to lists\n",
    "        padded_x_data.append(padded_x_item)\n",
    "        padded_y_data.append(padded_y_item)\n",
    "        padded_mask.append(mask)\n",
    "\n",
    "    # Stack all tensors into a batch\n",
    "    x_data = torch.stack(padded_x_data)\n",
    "    y_data = torch.stack(padded_y_data)\n",
    "    padded_mask = torch.stack(padded_mask)\n",
    "\n",
    "    '''\n",
    "    for y_data_mini in y_data:\n",
    "        unique_labels = torch.unique(y_data_mini)\n",
    "        print(f\"Unique labels in batch: {unique_labels}\")\n",
    "    '''\n",
    "\n",
    "    return x_data, y_data, padded_mask, hdf5_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_paths = [os.path.join(base_save_path, \"demo_emb/demo_psg.hdf5\")]\n",
    "label_files = [os.path.join(base_save_path, \"demo_psg.csv\")]\n",
    "test_dataset = SleepEventClassificationDataset(sleep_staging_config, channel_groups, split=\"test\", hdf5_paths=hdf5_paths, label_files=label_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=1, collate_fn=sleep_event_finetune_full_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Validation loop at the end of each epoch\n",
    "model.eval()\n",
    "all_targets = []\n",
    "all_logits = []\n",
    "all_outputs = []\n",
    "all_masks = []\n",
    "all_paths = []\n",
    "\n",
    "count = 0\n",
    "with torch.no_grad():\n",
    "    for (x_data, y_data, padded_matrix, hdf5_path_list) in tqdm.tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        x_data, y_data, padded_matrix, hdf5_path_list = x_data.to(device), y_data.to(device), padded_matrix.to(device), list(hdf5_path_list)\n",
    "        outputs, mask = sleep_staging_model(x_data, padded_matrix)\n",
    "        all_targets.append(y_data.cpu().numpy())\n",
    "        all_outputs.append(torch.softmax(outputs, dim=-1).cpu().numpy())\n",
    "        all_logits.append(outputs.cpu().numpy())\n",
    "        all_masks.append(mask.cpu().numpy())\n",
    "        all_paths.append(hdf5_path_list)\n",
    "\n",
    "\n",
    "save_path = os.path.join(base_save_path, \"demo_sleep_staging\")\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "targets_path = os.path.join(save_path, \"all_targets.pickle\")\n",
    "outputs_path = os.path.join(save_path, \"all_outputs.pickle\")\n",
    "logits_path = os.path.join(save_path, \"all_logits.pickle\")\n",
    "mask_path = os.path.join(save_path, \"all_masks.pickle\")\n",
    "file_paths = os.path.join(save_path, \"all_paths.pickle\")\n",
    "\n",
    "save_data(all_targets, targets_path)\n",
    "save_data(all_outputs, outputs_path)\n",
    "save_data(all_logits, logits_path)\n",
    "save_data(all_masks, mask_path)\n",
    "save_data(all_paths, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 6960, 5), (1, 6960))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs[0].shape, all_targets[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_logits), len(all_outputs), len(all_targets), len(all_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 6960, 5), (1, 6960, 5), (1, 6960), (1, 6960))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits[0].shape, all_outputs[0].shape, all_targets[0].shape, all_masks[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_logits_flat = [logits.reshape(-1, logits.shape[-1]) for logits in all_logits]\n",
    "all_outputs_flat = [outputs.reshape(-1, outputs.shape[-1]) for outputs in all_outputs]\n",
    "all_targets_flat = [targets.reshape(-1) for targets in all_targets]\n",
    "all_masks_flat = [mask.reshape(-1) for mask in all_masks]\n",
    "\n",
    "# Convert lists of flattened arrays to single concatenated arrays if desired\n",
    "all_logits_flat = np.concatenate(all_logits_flat, axis=0)\n",
    "all_outputs_flat = np.concatenate(all_outputs_flat, axis=0)\n",
    "all_targets_flat = np.concatenate(all_targets_flat, axis=0)\n",
    "all_masks_flat = np.concatenate(all_masks_flat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6960, 5), (6960, 5), (6960,), (6960,))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_logits_flat.shape, all_outputs_flat.shape, all_targets_flat.shape, all_masks_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_filter = all_masks_flat == 0\n",
    "\n",
    "# Apply the mask to each flattened array\n",
    "all_logits_filtered = all_logits_flat[mask_filter]\n",
    "all_outputs_filtered = all_outputs_flat[mask_filter]\n",
    "all_targets_filtered = all_targets_flat[mask_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0.0: 0.26814031715521386,\n",
       " 1.0: 0.028351753964440174,\n",
       " 2.0: 0.2715040845747237,\n",
       " 3.0: 0.15281114848630467,\n",
       " 4.0: 0.27919269581931766}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts = Counter(all_targets_filtered)\n",
    "total = sum(counts.values())\n",
    "prevalence_dict = {cls: count / total for cls, count in counts.items()}\n",
    "prevalence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_labels = [\"Wake\", \"Stage 1\", \"Stage 2\", \"Stage 3\", \"REM\"]\n",
    "# class_labels = [\"No-Apnea\", \"Apnea\"]\n",
    "class_mapping = {label: idx for idx, label in enumerate(class_labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score for Wake: 0.964\n",
      "F1 Score for Stage 1: 0.346\n",
      "F1 Score for Stage 2: 0.650\n",
      "F1 Score for Stage 3: 0.691\n",
      "F1 Score for REM: 0.977\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 1: Get predicted labels (argmax on probabilities)\n",
    "predicted_labels = np.argmax(all_outputs_filtered, axis=1)\n",
    "\n",
    "fontsize = 12\n",
    "\n",
    "# Step 2: Compute F1 score for each class\n",
    "f1_scores = f1_score(all_targets_filtered, predicted_labels, average=None, labels=range(len(class_labels)))\n",
    "for idx, label in enumerate(class_labels):\n",
    "    print(f\"F1 Score for {label}: {f1_scores[idx]:.3f}\")\n",
    "\n",
    "# Step 3: Create a confusion matrix and normalize it by row to get percentages\n",
    "conf_matrix = confusion_matrix(all_targets_filtered, predicted_labels, labels=range(len(class_labels)))\n",
    "conf_matrix_percent = conf_matrix / conf_matrix.sum(axis=1, keepdims=True) * 100\n",
    "\n",
    "# Plotting the confusion matrix with percentages\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    conf_matrix_percent,\n",
    "    annot=True,\n",
    "    fmt=\".1f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_labels,\n",
    "    yticklabels=class_labels,\n",
    "    annot_kws={\"size\": fontsize},  # Font size for numbers inside the heatmap\n",
    "    cbar_kws={\"shrink\": 1},  # Adjust colorbar size\n",
    ")\n",
    "\n",
    "# Customizing axis labels and ticks\n",
    "plt.xlabel(\"Predicted Labels\", fontsize=fontsize)\n",
    "plt.ylabel(\"True Labels\", fontsize=fontsize)\n",
    "plt.xticks(fontsize=12, ha=\"center\")  # Font size for x-axis tick labels with rotation\n",
    "plt.yticks(fontsize=12)  # Font size for y-axis tick labels\n",
    "\n",
    "# Adjust layout and save the figure\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Disease Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_model_path = \"../sleepfm/checkpoints/model_diagnosis\"\n",
    "config = load_data(os.path.join(disease_model_path, \"config.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"model_params\"][\"dropout\"] = 0.0\n",
    "model_params = config['model_params']\n",
    "model_class = getattr(sys.modules[__name__], config['model'])\n",
    "model = model_class(**model_params).to(device)\n",
    "model_name = type(model).__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: DiagnosisFinetuneFullLSTMCOXPHWithDemo\n",
      "Trainable parameters: 0.91 million\n",
      "Number of layers: 15\n"
     ]
    }
   ],
   "source": [
    "model = nn.DataParallel(model)\n",
    "print(f\"Model initialized: {model_name}\")\n",
    "total_layers, total_params = count_parameters(model)\n",
    "print(f'Trainable parameters: {total_params / 1e6:.2f} million')\n",
    "print(f'Number of layers: {total_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = os.path.join(disease_model_path, \"best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiagnosisFinetuneFullCOXPHWithDemoDataset(Dataset):\n",
    "    def __init__(self, \n",
    "                 config,\n",
    "                 channel_groups,\n",
    "                 hdf5_paths=None,\n",
    "                 demo_labels_path=None,\n",
    "                 split=\"train\"):\n",
    "\n",
    "        self.config = config\n",
    "        self.channel_groups = channel_groups\n",
    "        self.max_channels = self.config[\"max_channels\"]\n",
    "\n",
    "        # --- Load demographic features ---\n",
    "        if not demo_labels_path:\n",
    "            demo_labels_path = config[\"demo_labels_path\"]\n",
    "\n",
    "        demo_labels_df = pd.read_csv(demo_labels_path)\n",
    "        demo_labels_df = demo_labels_df.set_index(\"Study ID\")\n",
    "        study_ids = set(demo_labels_df.index)\n",
    "\n",
    "        is_event_df = pd.read_csv(os.path.join(self.config[\"labels_path\"], \"is_event.csv\"))\n",
    "        event_time_df = pd.read_csv(os.path.join(self.config[\"labels_path\"], \"time_to_event.csv\"))\n",
    "\n",
    "        is_event_df = is_event_df.set_index('Study ID')\n",
    "        event_time_df = event_time_df.set_index('Study ID')\n",
    "\n",
    "        # --- Resolve HDF5 paths (explicit precedence) ---\n",
    "        if hdf5_paths:\n",
    "            # Use provided paths directly\n",
    "            hdf5_paths = [f for f in hdf5_paths if os.path.exists(f)]\n",
    "        else:\n",
    "            # Load from split file\n",
    "            split_paths = load_data(config[\"split_path\"])[split]\n",
    "            hdf5_paths = [f for f in split_paths if os.path.exists(f)]\n",
    "\n",
    "        # Filter by available demo labels\n",
    "        hdf5_paths = [\n",
    "            f for f in hdf5_paths\n",
    "            if os.path.basename(f).split(\".\")[0] in study_ids\n",
    "        ]\n",
    "\n",
    "        # Optional truncation\n",
    "        if config.get(\"max_files\"):\n",
    "            hdf5_paths = hdf5_paths[:config[\"max_files\"]]\n",
    "\n",
    "        labels_dict = {}\n",
    "        # Loop over each study_id\n",
    "        for study_id in tqdm.tqdm(study_ids):\n",
    "            # Extract the row as a whole for both dataframes (faster than iterating over columns)\n",
    "            is_event_row = list(is_event_df.loc[study_id].values)\n",
    "            event_time_row = list(event_time_df.loc[study_id].values)\n",
    "            demo_feats = list(demo_labels_df.loc[study_id].values)\n",
    "\n",
    "            # values = [[event_time, is_event] for is_event, event_time in zip(is_event_row, event_time_row)]\n",
    "            labels_dict[study_id] = {\n",
    "                \"is_event\": is_event_row,\n",
    "                \"event_time\": event_time_row, \n",
    "                \"demo_feats\": demo_feats\n",
    "            }\n",
    "\n",
    "        # --- Build index map ---\n",
    "        self.index_map = [\n",
    "            (path, labels_dict[os.path.basename(path).split(\".\")[0]])\n",
    "            for path in hdf5_paths\n",
    "        ]\n",
    "\n",
    "        print(f\"Number of files in {split} set: {len(hdf5_paths)}\")\n",
    "        print(f\"Number of files to be processed in {split} set: {len(self.index_map)}\")\n",
    "\n",
    "        self.total_len = len(self.index_map)\n",
    "        self.max_seq_len = config[\"model_params\"][\"max_seq_length\"]\n",
    "\n",
    "        if self.total_len == 0:\n",
    "            raise ValueError(f\"No valid HDF5 files found for split='{split}'.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        hdf5_path, tte_event = self.index_map[idx]\n",
    "\n",
    "        event_time = tte_event[\"event_time\"]\n",
    "        is_event = tte_event[\"is_event\"]\n",
    "        demo_feats = tte_event[\"demo_feats\"]\n",
    "\n",
    "        x_data = []\n",
    "        with h5py.File(hdf5_path, 'r') as hf:\n",
    "            dset_names = []\n",
    "            for dset_name in hf.keys():\n",
    "                if isinstance(hf[dset_name], h5py.Dataset) and dset_name in self.config[\"modality_types\"]:\n",
    "                    dset_names.append(dset_name)\n",
    "            \n",
    "            random.shuffle(dset_names)\n",
    "            for dataset_name in dset_names:\n",
    "                x_data.append(hf[dataset_name][:])\n",
    "\n",
    "        if not x_data:\n",
    "            # Skip this data point if x_data is empty\n",
    "            return self.__getitem__((idx + 1) % self.total_len)\n",
    "\n",
    "        # Convert x_data list to a single numpy array\n",
    "        x_data = np.array(x_data)\n",
    "\n",
    "        # Convert x_data to tensor\n",
    "        x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "\n",
    "        event_time = torch.tensor(event_time, dtype=torch.float32)\n",
    "        is_event = torch.tensor(is_event) \n",
    "\n",
    "        demo_feats = torch.tensor(demo_feats, dtype=torch.float32)\n",
    "\n",
    "        return x_data, event_time, is_event, demo_feats, self.max_channels, self.max_seq_len, hdf5_path\n",
    "\n",
    "\n",
    "def diagnosis_finetune_full_coxph_with_demo_collate_fn(batch):\n",
    "    x_data, event_time, is_event, demo_feats, max_channels_list, max_seq_len_list, hdf5_path_list = zip(*batch)\n",
    "\n",
    "    num_channels = max(max_channels_list)\n",
    "\n",
    "    if max_seq_len_list[0] == None:\n",
    "        max_seq_len = max([item.size(1) for item in x_data])\n",
    "    else:\n",
    "        max_seq_len = max_seq_len_list[0]\n",
    "\n",
    "    padded_x_data = []\n",
    "    padded_mask = []\n",
    "    for item in x_data:\n",
    "        c, s, e = item.size()\n",
    "        c = min(c, num_channels)\n",
    "        s = min(s, max_seq_len)  # Ensure the sequence length doesn't exceed max_seq_len\n",
    "\n",
    "        # Create a padded tensor and a mask tensor\n",
    "        padded_item = torch.zeros((num_channels, max_seq_len, e))\n",
    "        mask = torch.ones((num_channels, max_seq_len))\n",
    "\n",
    "        # Copy the actual data to the padded tensor and set the mask for real data\n",
    "        padded_item[:c, :s, :e] = item[:c, :s, :e]\n",
    "        mask[:c, :s] = 0  # 0 for real data, 1 for padding\n",
    "\n",
    "        padded_x_data.append(padded_item)\n",
    "        padded_mask.append(mask)\n",
    "    \n",
    "    # Stack all tensors into a batch\n",
    "    x_data = torch.stack(padded_x_data)\n",
    "    event_time = torch.stack(event_time)\n",
    "    is_event = torch.stack(is_event)\n",
    "    demo_feats = torch.stack(demo_feats)\n",
    "    padded_mask = torch.stack(padded_mask)\n",
    "    \n",
    "    return x_data, event_time, is_event, demo_feats, padded_mask, hdf5_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(base_save_path, \"demo_diagnosis\")\n",
    "os.makedirs(save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 2970.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files in test set: 1\n",
      "Number of files to be processed in test set: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "hdf5_paths = [os.path.join(base_save_path, \"demo_emb/demo_psg.hdf5\")]\n",
    "demo_labels_path = os.path.join(base_save_path, \"demo_age_gender.csv\")\n",
    "config[\"labels_path\"] = base_save_path\n",
    "\n",
    "test_dataset = DiagnosisFinetuneFullCOXPHWithDemoDataset(config, channel_groups, split=\"test\", hdf5_paths=hdf5_paths, demo_labels_path=demo_labels_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=1, collate_fn=diagnosis_finetune_full_coxph_with_demo_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_event_times = []\n",
    "all_is_event = []\n",
    "all_outputs = []\n",
    "all_paths = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for item in tqdm.tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        x_data, event_times, is_event, demo_feats, padded_matrix, hdf5_path_list = item\n",
    "        x_data, event_times, is_event, demo_feats, padded_matrix, hdf5_path_list = x_data.to(device), event_times.to(device), is_event.to(device), demo_feats.to(device), padded_matrix.to(device), list(hdf5_path_list)\n",
    "        outputs = model(x_data, padded_matrix, demo_feats)\n",
    "    \n",
    "        logits = outputs.cpu().numpy()\n",
    "        all_outputs.append(logits)\n",
    "        all_event_times.append(event_times.cpu().numpy())\n",
    "        all_is_event.append(is_event.cpu().numpy())\n",
    "        all_paths.append(hdf5_path_list)\n",
    "\n",
    "all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "all_event_times = np.concatenate(all_event_times, axis=0)\n",
    "all_is_event = np.concatenate(all_is_event, axis=0)\n",
    "all_paths = np.concatenate(all_paths)\n",
    "\n",
    "outputs_path = os.path.join(save_path, \"all_outputs.pickle\")\n",
    "event_times_path = os.path.join(save_path, \"all_event_times.pickle\")\n",
    "is_event_path = os.path.join(save_path, \"all_is_event.pickle\")\n",
    "file_paths = os.path.join(save_path, \"all_paths.pickle\")\n",
    "\n",
    "save_data(all_outputs, outputs_path)\n",
    "save_data(all_event_times, event_times_path)\n",
    "save_data(all_is_event, is_event_path)\n",
    "save_data(all_paths, file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 1065), (1, 1065), (1, 1065))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_outputs.shape, all_event_times.shape, all_is_event.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you get the model outputs, which you can then use to look for specific disease diagnosis. Nope that the shape of the output above is 1065, meaning, this model gives logprobs for 1065 conditions. We provide information about each disease index and its corresponding phecode here `sleepfm/configs/label_mapping.csv`. You can map it as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df = pd.read_csv(\"../sleepfm/configs/label_mapping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_df[\"output\"] = all_outputs[0]\n",
    "labels_df[\"is_event\"] = all_is_event[0]\n",
    "labels_df[\"event_time\"] = all_event_times[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_idx</th>\n",
       "      <th>phecode</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>output</th>\n",
       "      <th>is_event</th>\n",
       "      <th>event_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Intestinal infection</td>\n",
       "      <td>1.838776</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Bacterial enteritis</td>\n",
       "      <td>2.605937</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>Viral Enteritis</td>\n",
       "      <td>1.971087</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Septicemia</td>\n",
       "      <td>4.495085</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>38.3</td>\n",
       "      <td>Bacteremia</td>\n",
       "      <td>4.594444</td>\n",
       "      <td>0</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_idx phecode             phenotype    output  is_event  event_time\n",
       "0          0     8.0  Intestinal infection  1.838776         0      3845.0\n",
       "1          1     8.5   Bacterial enteritis  2.605937         0      3845.0\n",
       "2          2     8.6       Viral Enteritis  1.971087         0      3845.0\n",
       "3          3    38.0            Septicemia  4.495085         0      3845.0\n",
       "4          4    38.3            Bacteremia  4.594444         0      3845.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_idx</th>\n",
       "      <th>phecode</th>\n",
       "      <th>phenotype</th>\n",
       "      <th>output</th>\n",
       "      <th>is_event</th>\n",
       "      <th>event_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>272</td>\n",
       "      <td>327.32</td>\n",
       "      <td>Obstructive sleep apnea</td>\n",
       "      <td>1.151709</td>\n",
       "      <td>1</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>268</td>\n",
       "      <td>327.0</td>\n",
       "      <td>Sleep disorders</td>\n",
       "      <td>1.124998</td>\n",
       "      <td>1</td>\n",
       "      <td>3845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>270</td>\n",
       "      <td>327.3</td>\n",
       "      <td>Sleep apnea</td>\n",
       "      <td>0.235396</td>\n",
       "      <td>1</td>\n",
       "      <td>1814.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label_idx phecode                phenotype    output  is_event  \\\n",
       "272        272  327.32  Obstructive sleep apnea  1.151709         1   \n",
       "268        268   327.0          Sleep disorders  1.124998         1   \n",
       "270        270   327.3              Sleep apnea  0.235396         1   \n",
       "\n",
       "     event_time  \n",
       "272      3845.0  \n",
       "268      3845.0  \n",
       "270      1814.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the top rows where is event = 1\n",
    "labels_event = labels_df[labels_df[\"is_event\"] == 1]\n",
    "labels_event = labels_event.sort_values(by=\"output\", ascending=False)\n",
    "labels_event.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, you get the output hazards from our model, and also your labels for is_event and event_times. Is_event is an indicator for if the event occured and event_time is the time to event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sleepfm_clinical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
